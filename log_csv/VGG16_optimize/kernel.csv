ph,shared memory,grid,correlation,block,blocks per SM,stream,name,context,queued,cat,pid,est. achieved occupancy %,registers per thread,ts,External id,dur,device,tid,warps per SM
X,0,"[1, 1, 1]",35694,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",1,0,kernel,0,0,16,6784357203240.737,5638,1.504,0,7,0.047619
X,0,"[4, 1, 1]",35720,"[128, 1, 1]",0.047619,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",1,0,kernel,0,0,16,6784357205577.274,6158,2.176,0,7,0.190476
X,2304,"[64, 1, 1]",35733,"[64, 8, 1]",0.761905,7,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, false, false, 9, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,kernel,0,25,128,6784357205580.282,6154,33.696,0,7,12.190476
X,0,"[4, 1, 1]",35751,"[128, 1, 1]",0.047619,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",1,0,kernel,0,0,16,6784357205614.746,6166,1.6,0,7,0.190476
X,1024,"[128, 32, 1]",35764,"[256, 1, 1]",48.761906,7,"void gemmk1_kernel<int, float, 256, 5, false, false, false, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<float, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, biasType<cublasGemvTensorStridedBatched<float>::value_type, float>::type>)",1,0,kernel,0,100,20,6784357205617.114,6162,27.84,0,7,390.095245
X,16,"[2, 1, 1]",35777,"[512, 1, 1]",0.02381,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,1,32,6784357205645.722,6170,4.512,0,7,0.380952
X,0,"[8, 1, 1]",35806,"[128, 1, 1]",0.095238,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,1,22,6784357205651.002,6187,1.984,0,7,0.380952
X,2304,"[64, 1, 4]",35827,"[64, 8, 1]",3.047619,7,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, false, false, 9, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,kernel,0,33,128,6784357205653.786,6195,129.248,0,7,48.761906
X,0,"[1, 256, 1]",35829,"[32, 16, 1]",3.047619,7,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",1,0,kernel,0,67,44,6784357205783.738,6195,2.72,0,7,48.761906
X,16384,"[32, 128, 1]",35846,"[256, 1, 1]",48.761906,7,ampere_sgemm_128x32_nn,1,0,kernel,0,67,57,6784357205787.162,6199,116.287,0,7,390.095245
X,16,"[8, 1, 1]",35859,"[128, 1, 1]",0.095238,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,1,48,6784357205904.282,6203,4.799,0,7,0.380952
X,0,"[8, 1, 1]",35888,"[128, 1, 1]",0.095238,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,1,22,6784357205909.818,6220,1.535,0,7,0.380952
X,16384,"[196, 1, 5]",35910,"[256, 1, 1]",11.666667,7,ampere_sgemm_128x32_nn,1,0,kernel,0,67,57,6784357205913.753,6228,694.878,0,7,93.333336
X,16384,"[196, 128, 1]",35927,"[256, 1, 1]",298.666656,7,ampere_sgemm_128x32_nn,1,0,kernel,0,67,57,6784357206609.432,6232,722.206,0,7,2389.333252
X,16,"[8, 1, 1]",35940,"[128, 1, 1]",0.095238,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,1,48,6784357207332.342,6236,2.88,0,7,0.380952
X,0,"[196, 1, 1]",35972,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",1,0,kernel,0,19,16,6784357207336.022,6259,1.344,0,7,9.333333
X,0,"[1, 1, 512]",35981,"[256, 1, 1]",6.095238,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",1,0,kernel,0,100,40,6784357207338.166,6257,5.184,0,7,48.761906
X,0,"[196, 1, 1]",35998,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,19,23,6784357207344.086,6262,2.432,0,7,9.333333
X,4368,"[512, 1, 1]",36042,"[512, 1, 1]",6.095238,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357207347.222,6266,10.527,0,7,97.523811
X,4224,"[1, 16, 512]",36073,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357207358.486,6282,33.376,0,7,780.190491
X,4224,"[7, 16, 1]",36075,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357207392.694,6282,3.967,0,7,10.666667
X,65536,"[4, 2, 8]",36081,"[128, 1, 1]",0.761905,7,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,250,6784357207399.126,6282,44.127,0,7,3.047619
X,4224,"[7, 16, 1]",36084,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6784357207443.989,6282,2.624,0,7,10.666667
X,4224,"[7, 16, 1]",36104,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357207447.413,6282,3.393,0,7,10.666667
X,4224,"[7, 16, 1]",36106,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357207451.573,6282,2.784,0,7,10.666667
X,73728,"[8, 9, 1]",36110,"[256, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),1,0,kernel,0,0,229,6784357207455.093,6282,37.28,0,7,6.857143
X,4224,"[1, 16, 512]",36114,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357207493.141,6282,32.96,0,7,780.190491
X,16,"[32, 1, 1]",36128,"[32, 16, 1]",0.380952,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,13,32,6784357207526.869,6285,5.664,0,7,6.095238
X,0,"[196, 1, 1]",36155,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,19,23,6784357209876.526,6297,3.52,0,7,9.333333
X,4368,"[512, 1, 1]",36199,"[512, 1, 1]",6.095238,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357209880.782,6301,10.849,0,7,97.523811
X,4224,"[1, 16, 512]",36230,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357209892.398,6317,33.536,0,7,780.190491
X,4224,"[7, 16, 1]",36232,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357209926.734,6317,3.904,0,7,10.666667
X,65536,"[4, 2, 8]",36238,"[128, 1, 1]",0.761905,7,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,250,6784357209933.55,6317,44.0,0,7,3.047619
X,4224,"[7, 16, 1]",36241,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6784357209978.414,6317,2.56,0,7,10.666667
X,4224,"[7, 16, 1]",36261,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357209981.742,6317,3.616,0,7,10.666667
X,4224,"[7, 16, 1]",36263,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357209986.094,6317,3.36,0,7,10.666667
X,73728,"[8, 9, 1]",36267,"[256, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),1,0,kernel,0,0,229,6784357209990.222,6317,36.768,0,7,6.857143
X,4224,"[1, 16, 512]",36271,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357210027.79,6317,33.056,0,7,780.190491
X,16,"[32, 1, 1]",36285,"[32, 16, 1]",0.380952,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,13,32,6784357210061.678,6320,5.472,0,7,6.095238
X,0,"[196, 1, 1]",36312,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,19,23,6784357210068.014,6332,3.584,0,7,9.333333
X,4368,"[512, 1, 1]",36356,"[512, 1, 1]",6.095238,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357210072.334,6336,10.56,0,7,97.523811
X,4224,"[1, 16, 512]",36387,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357210083.726,6352,33.151,0,7,780.190491
X,4224,"[7, 16, 1]",36389,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357210118.126,6352,3.679,0,7,10.666667
X,65536,"[4, 2, 8]",36395,"[128, 1, 1]",0.761905,7,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,250,6784357210124.974,6352,43.936,0,7,3.047619
X,4224,"[7, 16, 1]",36398,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6784357210169.742,6352,2.624,0,7,10.666667
X,4224,"[7, 16, 1]",36418,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357210173.101,6352,3.36,0,7,10.666667
X,4224,"[7, 16, 1]",36420,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784357210177.23,6352,2.911,0,7,10.666667
X,73728,"[8, 9, 1]",36424,"[256, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),1,0,kernel,0,0,229,6784357210180.973,6352,37.216,0,7,6.857143
X,4224,"[1, 16, 512]",36428,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357210218.957,6352,33.12,0,7,780.190491
X,16,"[32, 1, 1]",36442,"[32, 16, 1]",0.380952,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,13,32,6784357210252.845,6355,5.536,0,7,6.095238
X,0,"[784, 1, 1]",36468,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",1,0,kernel,0,78,16,6784357210259.213,6369,2.24,0,7,37.333332
X,0,"[4, 1, 512]",36477,"[256, 1, 1]",24.380953,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",1,0,kernel,0,100,40,6784357210263.405,6367,11.585,0,7,195.047623
X,0,"[784, 1, 1]",36494,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,78,23,6784357210275.854,6372,5.952,0,7,37.333332
X,8464,"[512, 1, 1]",36538,"[512, 1, 1]",6.095238,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357210282.574,6376,13.92,0,7,97.523811
X,4224,"[1, 16, 512]",36569,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357212658.887,6392,33.824,0,7,780.190491
X,4224,"[25, 16, 1]",36571,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357212693.511,6392,7.296,0,7,38.095238
X,73728,"[7, 8, 1]",36575,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),1,0,kernel,0,0,180,6784357212701.606,6392,100.256,0,7,2.666667
X,4224,"[25, 16, 1]",36579,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6784357212802.63,6392,3.168,0,7,38.095238
X,4224,"[25, 16, 1]",36599,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357212806.566,6392,7.521,0,7,38.095238
X,4224,"[25, 16, 1]",36601,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357212814.854,6392,7.104,0,7,38.095238
X,73728,"[8, 9, 1]",36605,"[256, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4::Params),1,0,kernel,0,0,251,6784357212822.758,6392,85.856,0,7,6.857143
X,4224,"[1, 16, 512]",36609,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357212909.414,6392,33.056,0,7,780.190491
X,16,"[32, 1, 1]",36623,"[32, 16, 1]",0.380952,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,13,32,6784357212943.238,6395,8.64,0,7,6.095238
X,0,"[784, 1, 1]",36650,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,78,23,6784357212952.646,6407,9.376,0,7,37.333332
X,8464,"[512, 1, 1]",36694,"[512, 1, 1]",6.095238,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357212962.79,6411,13.536,0,7,97.523811
X,4224,"[1, 16, 512]",36725,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357212977.062,6427,33.376,0,7,780.190491
X,4224,"[25, 16, 1]",36727,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357213011.11,6427,7.52,0,7,38.095238
X,73728,"[7, 8, 1]",36731,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),1,0,kernel,0,0,180,6784357213019.494,6427,100.096,0,7,2.666667
X,4224,"[25, 16, 1]",36735,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6784357213120.709,6427,2.945,0,7,38.095238
X,4224,"[25, 16, 1]",36755,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357213124.517,6427,6.432,0,7,38.095238
X,4224,"[25, 16, 1]",36757,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357213131.781,6427,6.848,0,7,38.095238
X,73728,"[8, 9, 1]",36761,"[256, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4::Params),1,0,kernel,0,0,251,6784357213139.333,6427,86.112,0,7,6.857143
X,4224,"[1, 16, 512]",36765,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357213226.245,6427,33.184,0,7,780.190491
X,16,"[32, 1, 1]",36779,"[32, 16, 1]",0.380952,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,13,32,6784357213260.229,6430,8.8,0,7,6.095238
X,0,"[784, 1, 1]",36806,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,78,23,6784357213269.733,6442,9.76,0,7,37.333332
X,8464,"[512, 1, 1]",36850,"[512, 1, 1]",6.095238,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357213280.325,6446,13.472,0,7,97.523811
X,4224,"[1, 8, 512]",36881,"[256, 1, 1]",48.761906,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357213294.565,6462,17.76,0,7,390.095245
X,4224,"[25, 16, 1]",36883,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357213313.029,6462,7.712,0,7,38.095238
X,81920,"[52, 1, 1]",36887,"[128, 1, 1]",0.619048,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params),1,0,kernel,0,0,118,6784357213321.445,6462,53.824,0,7,2.476191
X,4224,"[25, 8, 1]",36891,"[256, 1, 1]",2.380952,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,40,40,6784357213376.133,6462,2.72,0,7,19.047619
X,4224,"[25, 8, 1]",36911,"[256, 1, 1]",2.380952,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,40,38,6784357213379.621,6462,4.32,0,7,19.047619
X,4224,"[25, 16, 1]",36913,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784357213384.772,6462,7.105,0,7,38.095238
X,81920,"[8, 9, 1]",36917,"[128, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),1,0,kernel,0,0,234,6784357213392.613,6462,46.239,0,7,3.428571
X,4224,"[1, 8, 512]",36921,"[256, 1, 1]",48.761906,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357213439.684,6462,15.136,0,7,390.095245
X,16,"[32, 1, 1]",36935,"[32, 16, 1]",0.380952,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,13,32,6784357213455.589,6465,8.415,0,7,6.095238
X,0,"[1568, 1, 1]",36961,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",1,0,kernel,0,100,16,6784357213464.836,6479,3.489,0,7,74.666664
X,0,"[13, 1, 256]",36970,"[256, 1, 1]",39.619049,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",1,0,kernel,0,100,40,6784357213469.093,6477,19.136,0,7,316.952393
X,0,"[1568, 1, 1]",36987,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357213488.933,6482,12.0,0,7,74.666664
X,28944,"[256, 1, 1]",37031,"[512, 1, 1]",3.047619,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357215834.046,6486,21.312,0,7,48.761906
X,4224,"[1, 8, 256]",37062,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357215856.126,6502,10.464,0,7,195.047623
X,4224,"[98, 8, 1]",37064,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357215868.606,6502,11.776,0,7,74.666664
X,73728,"[100, 1, 1]",37068,"[128, 1, 1]",1.190476,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),1,0,kernel,0,0,161,6784357215881.63,6502,100.736,0,7,4.761905
X,4224,"[98, 8, 1]",37072,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357215983.454,6502,7.807,0,7,74.666664
X,4224,"[98, 8, 1]",37092,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357215992.03,6502,13.248,0,7,74.666664
X,4224,"[98, 8, 1]",37094,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216007.358,6502,13.151,0,7,74.666664
X,81920,"[4, 9, 2]",37099,"[128, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),1,0,kernel,0,0,234,6784357216026.557,6502,78.944,0,7,3.428571
X,4224,"[1, 8, 256]",37103,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357216106.237,6502,7.328,0,7,195.047623
X,16,"[16, 1, 1]",37117,"[32, 16, 1]",0.190476,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,6,32,6784357216114.365,6505,14.4,0,7,3.047619
X,0,"[1568, 1, 1]",37144,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357216129.597,6517,16.352,0,7,74.666664
X,28944,"[256, 1, 1]",37188,"[512, 1, 1]",3.047619,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357216146.621,6521,17.12,0,7,48.761906
X,4224,"[1, 8, 256]",37219,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216164.445,6537,10.464,0,7,195.047623
X,4224,"[98, 8, 1]",37221,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216175.741,6537,12.032,0,7,74.666664
X,73728,"[100, 1, 1]",37225,"[128, 1, 1]",1.190476,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),1,0,kernel,0,0,161,6784357216188.541,6537,100.256,0,7,4.761905
X,4224,"[98, 8, 1]",37229,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357216289.629,6537,8.0,0,7,74.666664
X,4224,"[98, 8, 1]",37249,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216298.749,6537,13.344,0,7,74.666664
X,4224,"[98, 8, 1]",37251,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216312.829,6537,12.48,0,7,74.666664
X,81920,"[4, 9, 2]",37256,"[128, 1, 1]",0.857143,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),1,0,kernel,0,0,234,6784357216329.597,6537,78.623,0,7,3.428571
X,4224,"[1, 8, 256]",37260,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357216409.021,6537,7.264,0,7,195.047623
X,16,"[16, 1, 1]",37274,"[32, 16, 1]",0.190476,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,6,32,6784357216417.084,6540,14.176,0,7,3.047619
X,0,"[1568, 1, 1]",37301,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357216431.996,6552,16.608,0,7,74.666664
X,28944,"[256, 1, 1]",37345,"[512, 1, 1]",3.047619,7,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",1,0,kernel,0,67,45,6784357216449.372,6556,17.472,0,7,48.761906
X,4224,"[1, 4, 256]",37376,"[256, 1, 1]",12.190476,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216467.964,6572,6.656,0,7,97.523811
X,4224,"[98, 8, 1]",37378,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216475.388,6572,8.192,0,7,74.666664
X,73728,"[50, 1, 1]",37382,"[128, 1, 1]",0.595238,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4::Params),1,0,kernel,0,0,167,6784357216484.444,6572,49.184,0,7,2.380952
X,4224,"[98, 4, 1]",37386,"[256, 1, 1]",4.666667,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,78,40,6784357216534.46,6572,2.784,0,7,37.333332
X,4224,"[98, 4, 1]",37406,"[256, 1, 1]",4.666667,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,78,38,6784357216539.292,6572,6.368,0,7,37.333332
X,4224,"[98, 8, 1]",37408,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216546.46,6572,12.0,0,7,74.666664
X,98304,"[18, 4, 1]",37413,"[128, 1, 1]",0.857143,7,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,128,6784357216559.26,6572,60.832,0,7,3.428571
X,4224,"[1, 4, 256]",37416,"[256, 1, 1]",12.190476,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357216621.788,6572,4.352,0,7,97.523811
X,16,"[16, 1, 1]",37430,"[32, 16, 1]",0.190476,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,6,32,6784357216627.324,6575,13.536,0,7,3.047619
X,0,"[3136, 1, 1]",37456,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",1,0,kernel,0,100,16,6784357216641.66,6589,11.296,0,7,149.333328
X,0,"[49, 1, 128]",37465,"[256, 1, 1]",74.666664,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",1,0,kernel,0,100,40,6784357216654.012,6587,34.848,0,7,597.333313
X,0,"[3136, 1, 1]",37482,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357216689.596,6592,35.2,0,7,149.333328
X,400,"[128, 1, 1]",37525,"[512, 1, 1]",1.52381,7,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",1,0,kernel,0,51,40,6784357216725.564,6596,51.168,0,7,24.380953
X,4224,"[1, 4, 128]",37555,"[256, 1, 1]",6.095238,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216777.5,6612,4.928,0,7,48.761906
X,4224,"[392, 4, 1]",37557,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216783.26,6612,21.984,0,7,149.333328
X,73728,"[196, 1, 1]",37561,"[128, 1, 1]",2.333333,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4::Params),1,0,kernel,0,0,167,6784357216806.012,6612,86.815,0,7,9.333333
X,4224,"[392, 4, 1]",37565,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357216893.596,6612,22.303,0,7,149.333328
X,4224,"[392, 4, 1]",37585,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216916.603,6612,25.152,0,7,149.333328
X,4224,"[392, 4, 1]",37587,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357216942.556,6612,25.055,0,7,149.333328
X,98304,"[18, 1, 4]",37595,"[128, 1, 1]",0.857143,7,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,168,6784357216977.147,6612,99.2,0,7,3.428571
X,9216,"[18, 1, 4]",37597,"[128, 1, 1]",0.857143,7,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_split_k_kernel__5x_cudnn,1,0,kernel,0,7,64,6784357217077.083,6612,3.392,0,7,3.428571
X,4224,"[1, 4, 128]",37600,"[256, 1, 1]",6.095238,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,100,40,6784357217081.307,6612,3.328,0,7,48.761906
X,2064,"[128, 1, 1]",37613,"[32, 16, 1]",1.52381,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,51,32,6784357217085.467,6615,15.744,0,7,24.380953
X,0,"[3136, 1, 1]",37640,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357217102.011,6627,30.432,0,7,149.333328
X,400,"[128, 1, 1]",37683,"[512, 1, 1]",1.52381,7,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",1,0,kernel,0,51,40,6784357217133.179,6631,51.456,0,7,24.380953
X,8704,"[2, 32, 1]",37714,"[32, 4, 1]",0.761905,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",1,0,kernel,0,6,40,6784357217185.467,6647,3.104,0,7,3.047619
X,49152,"[2, 14, 7]",37716,"[256, 1, 1]",2.333333,7,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,1,0,kernel,0,33,126,6784357217189.307,6647,76.127,0,7,18.666666
X,4224,"[392, 2, 1]",37736,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357217266.234,6647,10.784,0,7,74.666664
X,4224,"[392, 4, 1]",37738,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357217277.786,6647,25.632,0,7,149.333328
X,98304,"[9, 2, 4]",37746,"[128, 1, 1]",0.857143,7,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,128,6784357217309.466,6647,67.04,0,7,3.428571
X,4224,"[1, 2, 128]",37749,"[256, 1, 1]",3.047619,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,51,40,6784357217377.338,6647,2.848,0,7,24.380953
X,2064,"[128, 1, 1]",37762,"[32, 16, 1]",1.52381,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,51,32,6784357217380.954,6650,15.456,0,7,24.380953
X,0,"[6272, 1, 1]",37788,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",1,0,kernel,0,100,16,6784357217397.242,6664,19.04,0,7,298.666656
X,0,"[196, 1, 64]",37797,"[256, 1, 1]",149.333328,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",1,0,kernel,0,100,40,6784357217417.018,6662,66.176,0,7,1194.666626
X,0,"[6272, 1, 1]",37814,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357217483.994,6667,69.696,0,7,298.666656
X,400,"[64, 1, 1]",37857,"[512, 1, 1]",0.761905,7,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",1,0,kernel,0,25,40,6784357217554.457,6671,119.648,0,7,12.190476
X,8704,"[2, 16, 1]",37888,"[32, 4, 1]",0.380952,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",1,0,kernel,0,3,40,6784357217674.937,6687,2.784,0,7,1.52381
X,49152,"[2, 28, 14]",37890,"[256, 1, 1]",9.333333,7,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,1,0,kernel,0,33,126,6784357217678.553,6687,141.44,0,7,74.666664
X,4224,"[1568, 2, 1]",37910,"[256, 1, 1]",37.333332,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357217820.729,6687,47.232,0,7,298.666656
X,4224,"[1568, 2, 1]",37912,"[256, 1, 1]",37.333332,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784357217868.665,6687,48.703,0,7,298.666656
X,98304,"[9, 1, 8]",37920,"[128, 1, 1]",0.857143,7,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,128,6784357217923.576,6687,2569.529,0,7,3.428571
X,4224,"[1, 2, 64]",37923,"[256, 1, 1]",1.52381,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,25,40,6784357220494.258,6687,2.656,0,7,12.190476
X,2064,"[64, 1, 1]",37936,"[32, 16, 1]",0.761905,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,25,32,6784357220497.682,6690,27.808,0,7,12.190476
X,0,"[6272, 1, 1]",37963,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",1,0,kernel,0,100,23,6784357220526.257,6702,62.913,0,7,298.666656
X,400,"[64, 1, 1]",38006,"[512, 1, 1]",0.761905,7,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",1,0,kernel,0,25,40,6784357220590.001,6706,118.912,0,7,12.190476
X,2304,"[1, 2, 98]",38040,"[8, 8, 1]",2.333333,7,"void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",1,0,kernel,0,10,80,6784357220712.273,6722,71.712,0,7,4.666667
X,2064,"[64, 1, 1]",38053,"[32, 16, 1]",0.761905,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",1,0,kernel,0,25,32,6784357220784.689,6725,21.6,0,7,12.190476
X,0,"[320, 1, 1]",38071,"[512, 1, 1]",3.809524,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,100,40,6784357220807.025,5640,390.975,0,7,60.952381
X,0,"[320, 1, 1]",38074,"[512, 1, 1]",3.809524,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,100,40,6784357221198.8,5640,457.342,0,7,60.952381
X,0,"[320, 1, 1]",38077,"[512, 1, 1]",3.809524,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,100,40,6784357221656.846,5640,458.783,0,7,60.952381
X,0,"[320, 1, 1]",38080,"[512, 1, 1]",3.809524,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,100,40,6784357222116.397,5640,3030.328,0,7,60.952381
X,0,"[320, 1, 1]",38083,"[512, 1, 1]",3.809524,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,100,40,6784357225147.652,5640,458.719,0,7,60.952381
X,0,"[320, 1, 1]",38086,"[512, 1, 1]",3.809524,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,100,40,6784357225607.171,5640,453.951,0,7,60.952381
X,0,"[237, 1, 1]",38089,"[512, 1, 1]",2.821429,7,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",1,0,kernel,0,94,40,6784357226061.922,5640,338.303,0,7,45.142857
