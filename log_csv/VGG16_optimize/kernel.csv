pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.344,0,6936340956302.924,1,7,16,0,9953,7,kernel,0,"[1, 1, 1]",0.011905,2054
0,0.190476,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6936340960877.257,1,7,16,0,9979,7,kernel,0,"[4, 1, 1]",0.047619,2574
0,12.190476,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, false, false, 9, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,"[64, 8, 1]",33.728,2304,6936340960880.233,1,7,128,25,9992,7,kernel,0,"[64, 1, 1]",0.761905,2570
0,0.190476,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.696,0,6936340960914.696,1,7,16,0,10010,7,kernel,0,"[4, 1, 1]",0.047619,2582
0,390.095245,X,"void gemmk1_kernel<int, float, 256, 5, false, false, false, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<float, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, biasType<cublasGemvTensorStridedBatched<float>::value_type, float>::type>)",0,"[256, 1, 1]",28.288,1024,6936340960917.129,1,7,20,100,10023,7,kernel,0,"[128, 32, 1]",48.761906,2578
0,0.380952,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[512, 1, 1]",4.48,16,6936340960946.152,1,7,32,1,10036,7,kernel,0,"[2, 1, 1]",0.02381,2586
0,0.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6936340960951.433,1,7,22,1,10065,7,kernel,0,"[8, 1, 1]",0.095238,2603
0,48.761906,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, false, false, 9, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,"[64, 8, 1]",128.096,2304,6936340960954.248,1,7,128,33,10086,7,kernel,0,"[64, 1, 4]",3.047619,2611
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6936340961083.113,1,7,44,67,10088,7,kernel,0,"[1, 256, 1]",3.047619,2611
0,390.095245,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",116.959,16384,6936340961086.665,1,7,57,67,10105,7,kernel,0,"[32, 128, 1]",48.761906,2615
0,0.380952,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[128, 1, 1]",5.12,16,6936340961204.488,1,7,48,1,10118,7,kernel,0,"[8, 1, 1]",0.095238,2619
0,0.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6936340961210.376,1,7,22,1,10147,7,kernel,0,"[8, 1, 1]",0.095238,2636
0,93.333336,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",698.271,16384,6936340961215.209,1,7,57,67,10169,7,kernel,0,"[196, 1, 5]",11.666667,2644
0,2389.333252,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",724.896,16384,6936340961914.216,1,7,57,67,10186,7,kernel,0,"[196, 128, 1]",298.666656,2648
0,0.380952,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[128, 1, 1]",2.944,16,6936340962639.847,1,7,48,1,10199,7,kernel,0,"[8, 1, 1]",0.095238,2652
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.377,0,6936340962643.527,1,7,16,19,10231,7,kernel,0,"[196, 1, 1]",2.333333,2675
0,48.761906,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,"[256, 1, 1]",5.312,0,6936340962645.639,1,7,40,100,10240,7,kernel,0,"[1, 1, 512]",6.095238,2673
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.463,0,6936340962651.752,1,7,23,19,10257,7,kernel,0,"[196, 1, 1]",2.333333,2678
0,97.523811,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",11.136,4368,6936340962654.983,1,7,45,67,10301,7,kernel,0,"[512, 1, 1]",6.095238,2682
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.792,4224,6936340962666.888,1,7,38,100,10332,7,kernel,0,"[1, 16, 512]",97.523811,2698
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.064,4224,6936340962701.927,1,7,38,22,10334,7,kernel,0,"[7, 16, 1]",1.333333,2698
0,3.047619,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",45.441,65536,6936340962709.127,1,7,250,0,10340,7,kernel,0,"[4, 2, 8]",0.761905,2698
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.72,4224,6936340962755.463,1,7,40,22,10343,7,kernel,0,"[7, 16, 1]",1.333333,2698
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.424,4224,6936340962758.887,1,7,38,22,10363,7,kernel,0,"[7, 16, 1]",1.333333,2698
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.008,4224,6936340962763.015,1,7,38,22,10365,7,kernel,0,"[7, 16, 1]",1.333333,2698
0,6.857143,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),0,"[256, 1, 1]",38.111,73728,6936340962766.792,1,7,229,0,10369,7,kernel,0,"[8, 9, 1]",0.857143,2698
0,780.190491,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.504,4224,6936340962805.639,1,7,40,100,10373,7,kernel,0,"[1, 16, 512]",97.523811,2698
0,6.095238,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",5.407,16,6936340962839.88,1,7,32,13,10387,7,kernel,0,"[32, 1, 1]",0.380952,2701
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.584,0,6936340962846.055,1,7,23,19,10414,7,kernel,0,"[196, 1, 1]",2.333333,2713
0,97.523811,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",11.424,4368,6936340962850.471,1,7,45,67,10458,7,kernel,0,"[512, 1, 1]",6.095238,2717
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.408,4224,6936340962862.663,1,7,38,100,10489,7,kernel,0,"[1, 16, 512]",97.523811,2733
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.777,4224,6936340962896.839,1,7,38,22,10491,7,kernel,0,"[7, 16, 1]",1.333333,2733
0,3.047619,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",45.792,65536,6936340962904.199,1,7,250,0,10497,7,kernel,0,"[4, 2, 8]",0.761905,2733
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.56,4224,6936340962950.823,1,7,40,22,10500,7,kernel,0,"[7, 16, 1]",1.333333,2733
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.488,4224,6936340962954.215,1,7,38,22,10520,7,kernel,0,"[7, 16, 1]",1.333333,2733
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.944,4224,6936340962958.503,1,7,38,22,10522,7,kernel,0,"[7, 16, 1]",1.333333,2733
0,6.857143,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),0,"[256, 1, 1]",4714.557,73728,6936340962962.215,1,7,229,0,10526,7,kernel,0,"[8, 9, 1]",0.857143,2733
0,780.190491,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.056,4224,6936340967677.988,1,7,40,100,10530,7,kernel,0,"[1, 16, 512]",97.523811,2733
0,6.095238,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",5.76,16,6936340967711.78,1,7,32,13,10544,7,kernel,0,"[32, 1, 1]",0.380952,2736
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.488,0,6936340967718.276,1,7,23,19,10571,7,kernel,0,"[196, 1, 1]",2.333333,2748
0,97.523811,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",11.232,4368,6936340967722.564,1,7,45,67,10615,7,kernel,0,"[512, 1, 1]",6.095238,2752
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.792,4224,6936340967734.596,1,7,38,100,10646,7,kernel,0,"[1, 16, 512]",97.523811,2768
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.192,4224,6936340967769.188,1,7,38,22,10648,7,kernel,0,"[7, 16, 1]",1.333333,2768
0,3.047619,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",46.112,65536,6936340967776.644,1,7,250,0,10654,7,kernel,0,"[4, 2, 8]",0.761905,2768
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.688,4224,6936340967823.492,1,7,40,22,10657,7,kernel,0,"[7, 16, 1]",1.333333,2768
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.488,4224,6936340967827.012,1,7,38,22,10677,7,kernel,0,"[7, 16, 1]",1.333333,2768
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.584,4224,6936340967831.3,1,7,38,22,10679,7,kernel,0,"[7, 16, 1]",1.333333,2768
0,6.857143,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),0,"[256, 1, 1]",38.24,73728,6936340967835.652,1,7,229,0,10683,7,kernel,0,"[8, 9, 1]",0.857143,2768
0,780.190491,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.408,4224,6936340967874.724,1,7,40,100,10687,7,kernel,0,"[1, 16, 512]",97.523811,2768
0,6.095238,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",5.472,16,6936340967908.9,1,7,32,13,10701,7,kernel,0,"[32, 1, 1]",0.380952,2771
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",2.304,0,6936340967915.268,1,7,16,78,10727,7,kernel,0,"[784, 1, 1]",9.333333,2785
0,195.047623,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,"[256, 1, 1]",12.032,0,6936340967918.596,1,7,40,100,10736,7,kernel,0,"[4, 1, 512]",24.380953,2783
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",5.824,0,6936340967931.428,1,7,23,78,10753,7,kernel,0,"[784, 1, 1]",9.333333,2788
0,97.523811,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",14.24,8464,6936340967938.052,1,7,45,67,10797,7,kernel,0,"[512, 1, 1]",6.095238,2792
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.536,4224,6936340967953.028,1,7,38,100,10828,7,kernel,0,"[1, 16, 512]",97.523811,2808
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.776,4224,6936340967987.396,1,7,38,79,10830,7,kernel,0,"[25, 16, 1]",4.761905,2808
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,"[128, 1, 1]",104.287,73728,6936340967995.876,1,7,180,0,10834,7,kernel,0,"[7, 8, 1]",0.666667,2808
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.072,4224,6936340968101.284,1,7,40,79,10838,7,kernel,0,"[25, 16, 1]",4.761905,2808
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.552,4224,6936340968105.156,1,7,38,79,10858,7,kernel,0,"[25, 16, 1]",4.761905,2808
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.072,4224,6936340968113.508,1,7,38,79,10860,7,kernel,0,"[25, 16, 1]",4.761905,2808
0,6.857143,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4::Params),0,"[256, 1, 1]",88.927,73728,6936340968121.38,1,7,251,0,10864,7,kernel,0,"[8, 9, 1]",0.857143,2808
0,780.190491,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.089,4224,6936340968211.139,1,7,40,100,10868,7,kernel,0,"[1, 16, 512]",97.523811,2808
0,6.095238,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",8.736,16,6936340968245.028,1,7,32,13,10882,7,kernel,0,"[32, 1, 1]",0.380952,2811
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",9.312,0,6936340968254.596,1,7,23,78,10909,7,kernel,0,"[784, 1, 1]",9.333333,2823
0,97.523811,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",14.4,8464,6936340968264.708,1,7,45,67,10953,7,kernel,0,"[512, 1, 1]",6.095238,2827
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.503,4224,6936340968279.876,1,7,38,100,10984,7,kernel,0,"[1, 16, 512]",97.523811,2843
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.551,4224,6936340968314.148,1,7,38,79,10986,7,kernel,0,"[25, 16, 1]",4.761905,2843
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,"[128, 1, 1]",104.288,73728,6936340968322.563,1,7,180,0,10990,7,kernel,0,"[7, 8, 1]",0.666667,2843
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.04,4224,6936340968428.036,1,7,40,79,10994,7,kernel,0,"[25, 16, 1]",4.761905,2843
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.296,4224,6936340968431.811,1,7,38,79,11014,7,kernel,0,"[25, 16, 1]",4.761905,2843
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.913,4224,6936340968439.939,1,7,38,79,11016,7,kernel,0,"[25, 16, 1]",4.761905,2843
0,6.857143,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4::Params),0,"[256, 1, 1]",89.28,73728,6936340968447.587,1,7,251,0,11020,7,kernel,0,"[8, 9, 1]",0.857143,2843
0,780.190491,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.248,4224,6936340968537.603,1,7,40,100,11024,7,kernel,0,"[1, 16, 512]",97.523811,2843
0,6.095238,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",8.512,16,6936340968571.651,1,7,32,13,11038,7,kernel,0,"[32, 1, 1]",0.380952,2846
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",9.408,0,6936340968580.964,1,7,23,78,11065,7,kernel,0,"[784, 1, 1]",9.333333,2858
0,97.523811,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",14.08,8464,6936340968591.075,1,7,45,67,11109,7,kernel,0,"[512, 1, 1]",6.095238,2862
0,390.095245,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",18.049,4224,6936340968605.891,1,7,38,100,11140,7,kernel,0,"[1, 8, 512]",48.761906,2878
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.648,4224,6936340968624.771,1,7,38,79,11142,7,kernel,0,"[25, 16, 1]",4.761905,2878
0,2.476191,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params),0,"[128, 1, 1]",56.032,81920,6936340968633.219,1,7,118,0,11146,7,kernel,0,"[52, 1, 1]",0.619048,2878
0,19.047619,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.784,4224,6936340968690.115,1,7,40,40,11150,7,kernel,0,"[25, 8, 1]",2.380952,2878
0,19.047619,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.16,4224,6936340968693.635,1,7,38,40,11170,7,kernel,0,"[25, 8, 1]",2.380952,2878
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",5.984,4224,6936340968698.627,1,7,38,79,11172,7,kernel,0,"[25, 16, 1]",4.761905,2878
0,3.428571,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,"[128, 1, 1]",47.552,81920,6936340968705.379,1,7,234,0,11176,7,kernel,0,"[8, 9, 1]",0.857143,2878
0,390.095245,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",15.519,4224,6936340968753.732,1,7,40,100,11180,7,kernel,0,"[1, 8, 512]",48.761906,2878
0,6.095238,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",8.32,16,6936340968770.019,1,7,32,13,11194,7,kernel,0,"[32, 1, 1]",0.380952,2881
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",3.648,0,6936340968779.203,1,7,16,100,11220,7,kernel,0,"[1568, 1, 1]",18.666666,2895
0,316.952393,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,"[256, 1, 1]",19.808,0,6936340968784.067,1,7,40,100,11229,7,kernel,0,"[13, 1, 256]",39.619049,2893
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",11.776,0,6936340968804.707,1,7,23,100,11246,7,kernel,0,"[1568, 1, 1]",18.666666,2898
0,48.761906,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",17.248,28944,6936340968817.251,1,7,45,67,11290,7,kernel,0,"[256, 1, 1]",3.047619,2902
0,195.047623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",10.592,4224,6936340968835.331,1,7,38,100,11321,7,kernel,0,"[1, 8, 256]",24.380953,2918
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",11.168,4224,6936340968846.723,1,7,38,100,11323,7,kernel,0,"[98, 8, 1]",9.333333,2918
0,4.761905,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,"[128, 1, 1]",103.488,73728,6936340968858.627,1,7,161,0,11327,7,kernel,0,"[100, 1, 1]",1.190476,2918
0,74.666664,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.232,4224,6936340968962.915,1,7,40,100,11331,7,kernel,0,"[98, 8, 1]",9.333333,2918
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",13.472,4224,6936340968970.947,1,7,38,100,11351,7,kernel,0,"[98, 8, 1]",9.333333,2918
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",13.408,4224,6936340968985.187,1,7,38,100,11353,7,kernel,0,"[98, 8, 1]",9.333333,2918
0,3.428571,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,"[128, 1, 1]",81.056,81920,6936340969001.635,1,7,234,0,11358,7,kernel,0,"[4, 9, 2]",0.857143,2918
0,195.047623,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.584,4224,6936340969083.427,1,7,40,100,11362,7,kernel,0,"[1, 8, 256]",24.380953,2918
0,3.047619,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",14.816,16,6936340969092.003,1,7,32,6,11376,7,kernel,0,"[16, 1, 1]",0.190476,2921
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",16.832,0,6936340969107.651,1,7,23,100,11403,7,kernel,0,"[1568, 1, 1]",18.666666,2933
0,48.761906,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",17.856,28944,6936340969125.251,1,7,45,67,11447,7,kernel,0,"[256, 1, 1]",3.047619,2937
0,195.047623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",10.688,4224,6936340969143.843,1,7,38,100,11478,7,kernel,0,"[1, 8, 256]",24.380953,2953
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",11.776,4224,6936340969155.363,1,7,38,100,11480,7,kernel,0,"[98, 8, 1]",9.333333,2953
0,4.761905,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,"[128, 1, 1]",103.904,73728,6936340969167.907,1,7,161,0,11484,7,kernel,0,"[100, 1, 1]",1.190476,2953
0,74.666664,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",8.48,4224,6936340969272.611,1,7,40,100,11488,7,kernel,0,"[98, 8, 1]",9.333333,2953
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",13.472,4224,6936340969281.891,1,7,38,100,11508,7,kernel,0,"[98, 8, 1]",9.333333,2953
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",12.704,4224,6936340969296.195,1,7,38,100,11510,7,kernel,0,"[98, 8, 1]",9.333333,2953
0,3.428571,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,"[128, 1, 1]",80.64,81920,6936340969311.779,1,7,234,0,11515,7,kernel,0,"[4, 9, 2]",0.857143,2953
0,195.047623,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.552,4224,6936340969393.283,1,7,40,100,11519,7,kernel,0,"[1, 8, 256]",24.380953,2953
0,3.047619,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",14.144,16,6936340969401.635,1,7,32,6,11533,7,kernel,0,"[16, 1, 1]",0.190476,2956
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",16.448,0,6936340969416.611,1,7,23,100,11560,7,kernel,0,"[1568, 1, 1]",18.666666,2968
0,48.761906,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,"[512, 1, 1]",17.664,28944,6936340969433.795,1,7,45,67,11604,7,kernel,0,"[256, 1, 1]",3.047619,2972
0,97.523811,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.688,4224,6936340969452.323,1,7,38,100,11635,7,kernel,0,"[1, 4, 256]",12.190476,2988
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",8.224,4224,6936340969459.907,1,7,38,100,11637,7,kernel,0,"[98, 8, 1]",9.333333,2988
0,2.380952,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4::Params),0,"[128, 1, 1]",51.232,73728,6936340969468.899,1,7,167,0,11641,7,kernel,0,"[50, 1, 1]",0.595238,2988
0,37.333332,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.328,4224,6936340969520.899,1,7,40,78,11645,7,kernel,0,"[98, 4, 1]",4.666667,2988
0,37.333332,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.432,4224,6936340969525.027,1,7,38,78,11665,7,kernel,0,"[98, 4, 1]",4.666667,2988
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",12.096,4224,6936340969532.291,1,7,38,100,11667,7,kernel,0,"[98, 8, 1]",9.333333,2988
0,3.428571,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",63.104,98304,6936340969545.123,1,7,128,0,11672,7,kernel,0,"[18, 4, 1]",0.857143,2988
0,97.523811,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",5.088,4224,6936340969609.027,1,7,40,100,11675,7,kernel,0,"[1, 4, 256]",12.190476,2988
0,3.047619,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",13.761,16,6936340969614.914,1,7,32,6,11689,7,kernel,0,"[16, 1, 1]",0.190476,2991
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",9.344,0,6936340969629.411,1,7,16,100,11715,7,kernel,0,"[3136, 1, 1]",37.333332,3005
0,597.333313,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,"[256, 1, 1]",36.224,0,6936340969639.555,1,7,40,100,11724,7,kernel,0,"[49, 1, 128]",74.666664,3003
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",4782.524,0,6936340969676.611,1,7,23,100,11741,7,kernel,0,"[3136, 1, 1]",37.333332,3008
0,24.380953,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,"[512, 1, 1]",51.936,400,6936340974460.031,1,7,40,51,11784,7,kernel,0,"[128, 1, 1]",1.52381,3012
0,48.761906,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.896,4224,6936340974512.831,1,7,38,100,11814,7,kernel,0,"[1, 4, 128]",6.095238,3028
0,149.333328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",22.303,4224,6936340974518.528,1,7,38,100,11816,7,kernel,0,"[392, 4, 1]",18.666666,3028
0,9.333333,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4::Params),0,"[128, 1, 1]",88.928,73728,6936340974541.599,1,7,167,0,11820,7,kernel,0,"[196, 1, 1]",2.333333,3028
0,149.333328,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",21.728,4224,6936340974631.231,1,7,40,100,11824,7,kernel,0,"[392, 4, 1]",18.666666,3028
0,149.333328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",25.216,4224,6936340974653.727,1,7,38,100,11844,7,kernel,0,"[392, 4, 1]",18.666666,3028
0,149.333328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",24.768,4224,6936340974679.711,1,7,38,100,11846,7,kernel,0,"[392, 4, 1]",18.666666,3028
0,3.428571,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",102.56,98304,6936340974710.751,1,7,168,0,11854,7,kernel,0,"[18, 1, 4]",0.857143,3028
0,3.428571,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_split_k_kernel__5x_cudnn,0,"[128, 1, 1]",3.552,9216,6936340974814.175,1,7,64,7,11856,7,kernel,0,"[18, 1, 4]",0.857143,3028
0,48.761906,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.52,4224,6936340974818.495,1,7,40,100,11859,7,kernel,0,"[1, 4, 128]",6.095238,3028
0,24.380953,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",16.096,2064,6936340974822.815,1,7,32,51,11872,7,kernel,0,"[128, 1, 1]",1.52381,3031
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",29.792,0,6936340974839.775,1,7,23,100,11899,7,kernel,0,"[3136, 1, 1]",37.333332,3043
0,24.380953,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,"[512, 1, 1]",51.872,400,6936340974870.303,1,7,40,51,11942,7,kernel,0,"[128, 1, 1]",1.52381,3047
0,3.047619,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,"[32, 4, 1]",3.424,8704,6936340974923.039,1,7,40,6,11973,7,kernel,0,"[2, 32, 1]",0.761905,3063
0,18.666666,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,"[256, 1, 1]",78.496,49152,6936340974927.167,1,7,126,33,11975,7,kernel,0,"[2, 14, 7]",2.333333,3063
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",11.04,4224,6936340975006.527,1,7,38,100,11995,7,kernel,0,"[392, 2, 1]",9.333333,3063
0,149.333328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",24.8,4224,6936340975018.463,1,7,38,100,11997,7,kernel,0,"[392, 4, 1]",18.666666,3063
0,3.428571,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",69.216,98304,6936340975049.183,1,7,128,0,12005,7,kernel,0,"[9, 2, 4]",0.857143,3063
0,24.380953,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.944,4224,6936340975119.135,1,7,40,51,12008,7,kernel,0,"[1, 2, 128]",3.047619,3063
0,24.380953,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",15.552,2064,6936340975122.815,1,7,32,51,12021,7,kernel,0,"[128, 1, 1]",1.52381,3066
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",19.072,0,6936340975139.167,1,7,16,100,12047,7,kernel,0,"[6272, 1, 1]",74.666664,3080
0,1194.666626,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,"[256, 1, 1]",68.576,0,6936340975159.039,1,7,40,100,12056,7,kernel,0,"[196, 1, 64]",149.333328,3078
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",68.896,0,6936340975228.415,1,7,23,100,12073,7,kernel,0,"[6272, 1, 1]",74.666664,3083
0,12.190476,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,"[512, 1, 1]",120.384,400,6936340975298.143,1,7,40,25,12116,7,kernel,0,"[64, 1, 1]",0.761905,3087
0,1.52381,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,"[32, 4, 1]",2.848,8704,6936340975419.327,1,7,40,3,12147,7,kernel,0,"[2, 16, 1]",0.380952,3103
0,74.666664,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,"[256, 1, 1]",144.032,49152,6936340975422.911,1,7,126,33,12149,7,kernel,0,"[2, 28, 14]",9.333333,3103
0,298.666656,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",47.521,4224,6936340975567.678,1,7,38,100,12169,7,kernel,0,"[1568, 2, 1]",37.333332,3103
0,298.666656,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",48.607,4224,6936340975615.967,1,7,38,100,12171,7,kernel,0,"[1568, 2, 1]",37.333332,3103
0,3.428571,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",126.4,98304,6936340975671.871,1,7,128,0,12179,7,kernel,0,"[9, 1, 8]",0.857143,3103
0,12.190476,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.721,4224,6936340975799.006,1,7,40,25,12182,7,kernel,0,"[1, 2, 64]",1.52381,3103
0,12.190476,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",27.808,2064,6936340975802.559,1,7,32,25,12195,7,kernel,0,"[64, 1, 1]",0.761905,3106
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",63.552,0,6936340975831.134,1,7,23,100,12222,7,kernel,0,"[6272, 1, 1]",74.666664,3118
0,12.190476,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,"[512, 1, 1]",122.527,400,6936340975895.391,1,7,40,25,12265,7,kernel,0,"[64, 1, 1]",0.761905,3122
0,4.666667,X,"void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",0,"[8, 8, 1]",79.584,2304,6936340976021.406,1,7,80,10,12299,7,kernel,0,"[1, 2, 98]",2.333333,3138
0,12.190476,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",22.304,2064,6936340976101.694,1,7,32,25,12312,7,kernel,0,"[64, 1, 1]",0.761905,3141
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",397.856,0,6936341002145.58,1,7,40,100,12330,7,kernel,0,"[320, 1, 1]",3.809524,2056
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",457.792,0,6936341002544.268,1,7,40,100,12333,7,kernel,0,"[320, 1, 1]",3.809524,2056
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",456.159,0,6936341003002.796,1,7,40,100,12336,7,kernel,0,"[320, 1, 1]",3.809524,2056
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",459.808,0,6936341003459.787,1,7,40,100,12339,7,kernel,0,"[320, 1, 1]",3.809524,2056
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",3021.758,0,6936341003920.427,1,7,40,100,12342,7,kernel,0,"[320, 1, 1]",3.809524,2056
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",456.768,0,6936341006943.049,1,7,40,100,12345,7,kernel,0,"[320, 1, 1]",3.809524,2056
0,45.142857,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",336.896,0,6936341007400.521,1,7,40,94,12348,7,kernel,0,"[237, 1, 1]",2.821429,2056
