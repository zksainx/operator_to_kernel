shared memory,pid,dur,stream,ts,est. achieved occupancy %,tid,cat,warps per SM,grid,registers per thread,correlation,ph,name,device,External id,queued,blocks per SM,context,block
2064,0,3.296,7,6928969296052.974,0,7,kernel,0.190476,"[1, 1, 1]",32,4072,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,515,0,0.011905,1,"[512, 1, 1]"
0,0,1.28,7,6928969304178.369,0,7,kernel,0.047619,"[1, 1, 1]",16,4085,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,520,0,0.011905,1,"[128, 1, 1]"
0,0,1.824,7,6928969326106.846,2,7,kernel,0.952381,"[20, 1, 1]",16,4111,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,1038,0,0.238095,1,"[128, 1, 1]"
25600,0,7.232,7,6928969328837.21,5,7,kernel,2.285714,"[4, 1, 12]",80,4155,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,1034,0,0.571429,1,"[128, 1, 1]"
0,0,1.857,7,6928969338452.49,6,7,kernel,3.047619,"[16, 1, 1]",44,4156,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,1034,0,0.190476,1,"[32, 16, 1]"
0,0,1.856,7,6928969338665.674,2,7,kernel,0.952381,"[20, 1, 1]",16,4174,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,1046,0,0.238095,1,"[128, 1, 1]"
16384,0,4.351,7,6928969344843.681,25,7,kernel,12.190476,"[16, 8, 1]",57,4188,X,ampere_sgemm_32x128_nn,0,1042,0,1.52381,1,"[256, 1, 1]"
16,0,3.392,7,6928969345000.96,1,7,kernel,0.380952,"[2, 1, 1]",32,4201,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1050,0,0.02381,1,"[128, 4, 1]"
0,0,2.24,7,6928969356683.821,49,7,kernel,23.333334,"[490, 1, 1]",16,4231,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",0,1074,0,5.833333,1,"[128, 1, 1]"
0,0,1.983,7,6928969370213.464,24,7,kernel,11.666667,"[245, 1, 1]",22,4245,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1077,0,2.916667,1,"[128, 1, 1]"
4368,0,10.752,7,6928969385810.623,67,7,kernel,97.523811,"[512, 1, 1]",45,4342,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1082,0,6.095238,1,"[512, 1, 1]"
4224,0,33.536,7,6928969398270.443,100,7,kernel,780.190491,"[1, 16, 512]",38,4533,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1098,0,97.523811,1,"[256, 1, 1]"
4224,0,4.224,7,6928969398304.683,32,7,kernel,15.238095,"[2, 16, 5]",38,4535,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1098,0,1.904762,1,"[256, 1, 1]"
65536,0,43.456,7,6928969402055.909,0,7,kernel,3.047619,"[4, 2, 8]",250,4541,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1098,0,0.761905,1,"[128, 1, 1]"
4224,0,2.464,7,6928969402100.197,32,7,kernel,15.238095,"[2, 16, 5]",40,4544,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1098,0,1.904762,1,"[256, 1, 1]"
4224,0,4.096,7,6928969413845.362,32,7,kernel,15.238095,"[2, 16, 5]",38,4653,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1098,0,1.904762,1,"[256, 1, 1]"
4224,0,3.744,7,6928969413859.058,32,7,kernel,15.238095,"[2, 16, 5]",38,4655,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1098,0,1.904762,1,"[256, 1, 1]"
49152,0,37.6,7,6928969414470.609,14,7,kernel,6.857143,"[36, 4, 1]",230,4658,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1098,0,1.714286,1,"[128, 1, 1]"
4224,0,34.4,7,6928969414509.041,100,7,kernel,780.190491,"[1, 16, 512]",40,4661,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1098,0,97.523811,1,"[256, 1, 1]"
0,0,4.191,7,6928969414789.713,24,7,kernel,11.666667,"[245, 1, 1]",22,4681,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1107,0,2.916667,1,"[128, 1, 1]"
4368,0,11.232,7,6928969414966.736,67,7,kernel,97.523811,"[512, 1, 1]",45,4725,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1110,0,6.095238,1,"[512, 1, 1]"
4224,0,33.088,7,6928969415147.44,100,7,kernel,780.190491,"[1, 16, 512]",38,4756,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1126,0,97.523811,1,"[256, 1, 1]"
4224,0,4.352,7,6928969415181.328,32,7,kernel,15.238095,"[2, 16, 5]",38,4758,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1126,0,1.904762,1,"[256, 1, 1]"
65536,0,44.287,7,6928969415195.12,0,7,kernel,3.047619,"[4, 2, 8]",250,4764,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1126,0,0.761905,1,"[128, 1, 1]"
4224,0,2.56,7,6928969415240.144,32,7,kernel,15.238095,"[2, 16, 5]",40,4767,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1126,0,1.904762,1,"[256, 1, 1]"
4224,0,3.84,7,6928969415254.032,32,7,kernel,15.238095,"[2, 16, 5]",38,4787,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1126,0,1.904762,1,"[256, 1, 1]"
4224,0,3.232,7,6928969415262.576,32,7,kernel,15.238095,"[2, 16, 5]",38,4789,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1126,0,1.904762,1,"[256, 1, 1]"
49152,0,37.343,7,6928969415276.304,14,7,kernel,6.857143,"[36, 4, 1]",230,4792,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1126,0,1.714286,1,"[128, 1, 1]"
4224,0,34.111,7,6928969415314.384,100,7,kernel,780.190491,"[1, 16, 512]",40,4795,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1126,0,97.523811,1,"[256, 1, 1]"
0,0,4.288,7,6928969415353.776,24,7,kernel,11.666667,"[245, 1, 1]",22,4804,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1129,0,2.916667,1,"[128, 1, 1]"
0,0,3.456,7,6928969415438.0,24,7,kernel,11.666667,"[245, 1, 1]",22,4824,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1136,0,2.916667,1,"[128, 1, 1]"
4368,0,11.168,7,6928969415572.143,67,7,kernel,97.523811,"[512, 1, 1]",45,4872,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1141,0,6.095238,1,"[512, 1, 1]"
4224,0,11.936,7,6928969417052.877,100,7,kernel,390.095245,"[1, 8, 512]",38,5076,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1157,0,48.761906,1,"[256, 1, 1]"
4224,0,2.144,7,6928969417065.741,32,7,kernel,15.238095,"[2, 16, 5]",38,5078,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1157,0,1.904762,1,"[256, 1, 1]"
81920,0,12.448,7,6928969417081.997,0,7,kernel,3.047619,"[16, 4, 1]",128,5082,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1157,0,0.761905,1,"[128, 1, 1]"
4224,0,2.56,7,6928969417095.277,56,7,kernel,26.666666,"[7, 8, 5]",40,5086,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1157,0,3.333333,1,"[256, 1, 1]"
4224,0,4.287,7,6928969418569.515,56,7,kernel,26.666666,"[7, 8, 5]",38,5207,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1157,0,3.333333,1,"[256, 1, 1]"
4224,0,2.176,7,6928969418580.811,32,7,kernel,15.238095,"[2, 16, 5]",38,5209,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1157,0,1.904762,1,"[256, 1, 1]"
73728,0,12.064,7,6928969418611.466,0,7,kernel,1.52381,"[16, 1, 2]",166,5214,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,1157,0,0.380952,1,"[128, 1, 1]"
4368,0,10.88,7,6928969418876.042,67,7,kernel,97.523811,"[512, 1, 1]",45,5266,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1166,0,6.095238,1,"[512, 1, 1]"
4224,0,33.12,7,6928969419031.242,100,7,kernel,780.190491,"[1, 16, 512]",38,5297,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1182,0,97.523811,1,"[256, 1, 1]"
4224,0,4.351,7,6928969419065.738,32,7,kernel,15.238095,"[2, 16, 5]",38,5299,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1182,0,1.904762,1,"[256, 1, 1]"
65536,0,43.935,7,6928969419073.642,0,7,kernel,3.047619,"[4, 2, 8]",250,5305,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1182,0,0.761905,1,"[128, 1, 1]"
4224,0,2.687,7,6928969419118.314,32,7,kernel,15.238095,"[2, 16, 5]",40,5308,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1182,0,1.904762,1,"[256, 1, 1]"
4224,0,3.872,7,6928969419127.914,32,7,kernel,15.238095,"[2, 16, 5]",38,5328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1182,0,1.904762,1,"[256, 1, 1]"
4224,0,3.84,7,6928969419135.945,32,7,kernel,15.238095,"[2, 16, 5]",38,5330,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1182,0,1.904762,1,"[256, 1, 1]"
49152,0,38.08,7,6928969419149.738,14,7,kernel,6.857143,"[36, 4, 1]",230,5333,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1182,0,1.714286,1,"[128, 1, 1]"
4224,0,34.432,7,6928969419188.585,100,7,kernel,780.190491,"[1, 16, 512]",40,5336,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1182,0,97.523811,1,"[256, 1, 1]"
0,0,4.32,7,6928969419255.977,24,7,kernel,11.666667,"[245, 1, 1]",22,5356,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1191,0,2.916667,1,"[128, 1, 1]"
4368,0,11.296,7,6928969419383.241,67,7,kernel,97.523811,"[512, 1, 1]",45,5400,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1194,0,6.095238,1,"[512, 1, 1]"
4224,0,17.728,7,6928969421200.71,100,7,kernel,390.095245,"[1, 8, 512]",38,5604,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1210,0,48.761906,1,"[256, 1, 1]"
4224,0,4.0,7,6928969421219.206,32,7,kernel,15.238095,"[2, 16, 5]",38,5606,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1210,0,1.904762,1,"[256, 1, 1]"
81920,0,29.184,7,6928969421230.79,0,7,kernel,3.047619,"[16, 4, 1]",128,5610,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1210,0,0.761905,1,"[128, 1, 1]"
4224,0,2.784,7,6928969421260.806,56,7,kernel,26.666666,"[7, 8, 5]",40,5614,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1210,0,3.333333,1,"[256, 1, 1]"
4224,0,5.12,7,6928969423106.051,56,7,kernel,26.666666,"[7, 8, 5]",38,5739,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1210,0,3.333333,1,"[256, 1, 1]"
4224,0,3.872,7,6928969423119.619,32,7,kernel,15.238095,"[2, 16, 5]",38,5741,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1210,0,1.904762,1,"[256, 1, 1]"
81920,0,23.456,7,6928969423140.163,0,7,kernel,3.428571,"[8, 9, 1]",234,5745,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,1210,0,0.857143,1,"[128, 1, 1]"
4224,0,14.464,7,6928969423164.355,100,7,kernel,390.095245,"[1, 8, 512]",40,5749,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1210,0,48.761906,1,"[256, 1, 1]"
0,0,6.912,7,6928969423297.731,49,7,kernel,23.333334,"[490, 1, 1]",22,5758,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1213,0,5.833333,1,"[128, 1, 1]"
0,0,4.992,7,6928969423433.155,49,7,kernel,23.333334,"[490, 1, 1]",22,5778,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1220,0,5.833333,1,"[128, 1, 1]"
8464,0,8.704,7,6928969423615.138,67,7,kernel,48.761906,"[256, 1, 1]",45,5826,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1225,0,3.047619,1,"[512, 1, 1]"
4224,0,9.952,7,6928969425689.439,100,7,kernel,195.047623,"[1, 8, 256]",38,6031,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1241,0,24.380953,1,"[256, 1, 1]"
4224,0,3.776,7,6928969425704.703,56,7,kernel,26.666666,"[7, 8, 5]",38,6033,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1241,0,3.333333,1,"[256, 1, 1]"
81920,0,32.576,7,6928969425720.351,0,7,kernel,3.047619,"[16, 4, 1]",128,6037,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1241,0,0.761905,1,"[128, 1, 1]"
4224,0,2.688,7,6928969425753.727,56,7,kernel,26.666666,"[7, 8, 5]",40,6041,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1241,0,3.333333,1,"[256, 1, 1]"
4224,0,4.736,7,6928969427355.357,56,7,kernel,26.666666,"[7, 8, 5]",38,6165,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1241,0,3.333333,1,"[256, 1, 1]"
4224,0,5.057,7,6928969427369.18,56,7,kernel,26.666666,"[7, 8, 5]",38,6167,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1241,0,3.333333,1,"[256, 1, 1]"
73728,0,37.056,7,6928969427385.692,0,7,kernel,3.809524,"[16, 5, 1]",166,6171,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,1241,0,0.952381,1,"[128, 1, 1]"
4224,0,6.688,7,6928969427423.484,100,7,kernel,195.047623,"[1, 8, 256]",40,6175,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1241,0,24.380953,1,"[256, 1, 1]"
0,0,6.88,7,6928969427620.06,49,7,kernel,23.333334,"[490, 1, 1]",22,6195,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1250,0,5.833333,1,"[128, 1, 1]"
8464,0,8.832,7,6928969427780.06,67,7,kernel,48.761906,"[256, 1, 1]",45,6239,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1253,0,3.047619,1,"[512, 1, 1]"
4224,0,9.919,7,6928969427952.828,100,7,kernel,195.047623,"[1, 8, 256]",38,6270,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1269,0,24.380953,1,"[256, 1, 1]"
4224,0,3.807,7,6928969427965.564,56,7,kernel,26.666666,"[7, 8, 5]",38,6272,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1269,0,3.333333,1,"[256, 1, 1]"
81920,0,32.32,7,6928969427983.388,0,7,kernel,3.047619,"[16, 4, 1]",128,6276,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1269,0,0.761905,1,"[128, 1, 1]"
4224,0,2.784,7,6928969428016.475,56,7,kernel,26.666666,"[7, 8, 5]",40,6280,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1269,0,3.333333,1,"[256, 1, 1]"
4224,0,4.769,7,6928969428043.163,56,7,kernel,26.666666,"[7, 8, 5]",38,6300,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1269,0,3.333333,1,"[256, 1, 1]"
4224,0,4.704,7,6928969428052.795,56,7,kernel,26.666666,"[7, 8, 5]",38,6302,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1269,0,3.333333,1,"[256, 1, 1]"
73728,0,37.056,7,6928969428068.027,0,7,kernel,3.809524,"[16, 5, 1]",166,6306,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,1269,0,0.952381,1,"[128, 1, 1]"
4224,0,6.751,7,6928969428105.916,100,7,kernel,195.047623,"[1, 8, 256]",40,6310,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1269,0,24.380953,1,"[256, 1, 1]"
0,0,6.72,7,6928969428127.131,49,7,kernel,23.333334,"[490, 1, 1]",22,6319,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1272,0,5.833333,1,"[128, 1, 1]"
0,0,4.928,7,6928969428215.643,49,7,kernel,23.333334,"[490, 1, 1]",22,6339,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1279,0,5.833333,1,"[128, 1, 1]"
8464,0,8.768,7,6928969428369.723,67,7,kernel,48.761906,"[256, 1, 1]",45,6387,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1284,0,3.047619,1,"[512, 1, 1]"
4224,0,4.544,7,6928969430094.776,100,7,kernel,97.523811,"[1, 4, 256]",38,6591,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1300,0,12.190476,1,"[256, 1, 1]"
4224,0,2.592,7,6928969430107.256,56,7,kernel,26.666666,"[7, 8, 5]",38,6593,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1300,0,3.333333,1,"[256, 1, 1]"
81920,0,9.728,7,6928969430123.832,0,7,kernel,6.095238,"[64, 2, 1]",128,6597,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1300,0,1.52381,1,"[128, 1, 1]"
4224,0,2.944,7,6928969430138.68,99,7,kernel,47.619049,"[25, 4, 5]",40,6601,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1300,0,5.952381,1,"[256, 1, 1]"
10496,0,39.425,7,6928969433016.627,2,7,kernel,0.952381,"[2, 1, 5]",123,6706,X,"void wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",0,1300,0,0.119048,1,"[8, 32, 1]"
8464,0,10.624,7,6928969433365.875,67,7,kernel,48.761906,"[256, 1, 1]",45,6756,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1309,0,3.047619,1,"[512, 1, 1]"
4224,0,9.825,7,6928969433590.418,100,7,kernel,195.047623,"[1, 8, 256]",38,6787,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1325,0,24.380953,1,"[256, 1, 1]"
4224,0,3.233,7,6928969433605.01,56,7,kernel,26.666666,"[7, 8, 5]",38,6789,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1325,0,3.333333,1,"[256, 1, 1]"
81920,0,32.928,7,6928969433625.683,0,7,kernel,3.047619,"[16, 4, 1]",128,6793,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1325,0,0.761905,1,"[128, 1, 1]"
4224,0,2.72,7,6928969433659.346,56,7,kernel,26.666666,"[7, 8, 5]",40,6797,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1325,0,3.333333,1,"[256, 1, 1]"
4224,0,4.609,7,6928969433692.69,56,7,kernel,26.666666,"[7, 8, 5]",38,6817,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1325,0,3.333333,1,"[256, 1, 1]"
4224,0,4.769,7,6928969433702.962,56,7,kernel,26.666666,"[7, 8, 5]",38,6819,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1325,0,3.333333,1,"[256, 1, 1]"
73728,0,37.216,7,6928969433719.378,0,7,kernel,3.809524,"[16, 5, 1]",166,6823,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,1325,0,0.952381,1,"[128, 1, 1]"
4224,0,6.751,7,6928969433757.363,100,7,kernel,195.047623,"[1, 8, 256]",40,6827,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1325,0,24.380953,1,"[256, 1, 1]"
0,0,6.88,7,6928969433846.45,49,7,kernel,23.333334,"[490, 1, 1]",22,6847,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1334,0,5.833333,1,"[128, 1, 1]"
8464,0,8.96,7,6928969433979.89,67,7,kernel,48.761906,"[256, 1, 1]",45,6891,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1337,0,3.047619,1,"[512, 1, 1]"
4224,0,5.792,7,6928969435447.76,100,7,kernel,97.523811,"[1, 4, 256]",38,7096,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1353,0,12.190476,1,"[256, 1, 1]"
4224,0,2.529,7,6928969435459.151,56,7,kernel,26.666666,"[7, 8, 5]",38,7098,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1353,0,3.333333,1,"[256, 1, 1]"
81920,0,22.784,7,6928969435471.184,0,7,kernel,6.095238,"[64, 2, 1]",128,7102,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,1353,0,1.52381,1,"[128, 1, 1]"
4224,0,3.328,7,6928969435494.8,99,7,kernel,47.619049,"[25, 4, 5]",40,7106,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1353,0,5.952381,1,"[256, 1, 1]"
4224,0,8.32,7,6928969436882.509,99,7,kernel,47.619049,"[25, 4, 5]",38,7227,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1353,0,5.952381,1,"[256, 1, 1]"
4224,0,5.728,7,6928969436892.781,56,7,kernel,26.666666,"[7, 8, 5]",38,7229,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1353,0,3.333333,1,"[256, 1, 1]"
81920,0,23.52,7,6928969436909.069,0,7,kernel,3.809524,"[16, 5, 1]",96,7233,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi64ELi32EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi64ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi64ELi32EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi32ELi64EEESC_SI_SK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESI_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi32ELi32ELi32EEESC_SQ_SC_SZ_fNSO_8RowMajorENS13_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSO_11ColumnMajorEfS16_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi5EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi4ELi1ELi1ELi4EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1U_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS24_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,1353,0,0.952381,1,"[128, 1, 1]"
0,0,2.271,7,6928969436950.67,57,7,kernel,27.428572,"[64, 9, 1]",36,7236,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,1353,0,6.857143,1,"[32, 4, 1]"
4224,0,4.544,7,6928969436966.669,100,7,kernel,97.523811,"[1, 4, 256]",40,7240,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1353,0,12.190476,1,"[256, 1, 1]"
0,0,12.032,7,6928969437092.365,97,7,kernel,46.666668,"[980, 1, 1]",22,7249,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1356,0,11.666667,1,"[128, 1, 1]"
0,0,7.904,7,6928969437206.765,97,7,kernel,46.666668,"[980, 1, 1]",22,7269,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1363,0,11.666667,1,"[128, 1, 1]"
33040,0,9.249,7,6928969437354.796,51,7,kernel,24.380953,"[128, 1, 1]",45,7317,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1368,0,1.52381,1,"[512, 1, 1]"
4224,0,4.352,7,6928969438976.842,100,7,kernel,48.761906,"[1, 4, 128]",38,7524,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1384,0,6.095238,1,"[256, 1, 1]"
4224,0,3.264,7,6928969438987.498,99,7,kernel,47.619049,"[25, 4, 5]",38,7526,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1384,0,5.952381,1,"[256, 1, 1]"
73728,0,27.072,7,6928969439002.122,0,7,kernel,2.952381,"[62, 1, 1]",161,7530,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,1384,0,0.738095,1,"[128, 1, 1]"
4224,0,3.008,7,6928969439029.994,99,7,kernel,47.619049,"[25, 4, 5]",40,7534,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1384,0,5.952381,1,"[256, 1, 1]"
4224,0,8.576,7,6928969440447.752,99,7,kernel,47.619049,"[25, 4, 5]",38,7657,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1384,0,5.952381,1,"[256, 1, 1]"
4224,0,8.575,7,6928969440460.168,99,7,kernel,47.619049,"[25, 4, 5]",38,7659,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1384,0,5.952381,1,"[256, 1, 1]"
73728,0,32.991,7,6928969440587.592,0,7,kernel,3.809524,"[4, 5, 4]",148,7664,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi16EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi16ELi64EEESC_NSE_INSF_ILi64ELi16EEELi128ESH_Li4EEESK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESY_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SQ_SC_S11_fNSO_8RowMajorENS15_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S18_SC_NSO_11ColumnMajorEfS18_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1I_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1H_Li1ENS1M_22PredicatedTileIteratorINS1M_26OutputTileOptimalThreadMapINS1M_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1Q_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1L_4warp24FragmentIteratorTensorOpIS17_S1B_fNS_5ArrayIfLi4ELb1EEES18_EENS1W_20TileIteratorTensorOpIS17_S1B_fS18_EENS1M_18SharedLoadIteratorINS1T_18CompactedThreadMapEfLi16EEENS1L_6thread17LinearCombinationIfLi4EffLNS26_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS13_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,1384,0,0.952381,1,"[128, 1, 1]"
0,0,2.815,7,6928969440621.384,29,7,kernel,13.714286,"[32, 9, 1]",36,7667,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,1384,0,3.428571,1,"[32, 4, 1]"
4224,0,3.105,7,6928969440624.903,100,7,kernel,48.761906,"[1, 4, 128]",40,7671,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1384,0,6.095238,1,"[256, 1, 1]"
0,0,11.616,7,6928969440828.039,97,7,kernel,46.666668,"[980, 1, 1]",22,7691,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1393,0,11.666667,1,"[128, 1, 1]"
33040,0,9.376,7,6928969440961.159,51,7,kernel,24.380953,"[128, 1, 1]",45,7735,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1396,0,1.52381,1,"[512, 1, 1]"
4224,0,4.385,7,6928969441110.822,100,7,kernel,48.761906,"[1, 4, 128]",38,7766,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1412,0,6.095238,1,"[256, 1, 1]"
4224,0,3.584,7,6928969441119.943,99,7,kernel,47.619049,"[25, 4, 5]",38,7768,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1412,0,5.952381,1,"[256, 1, 1]"
73728,0,27.168,7,6928969441133.863,0,7,kernel,2.952381,"[62, 1, 1]",161,7772,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,1412,0,0.738095,1,"[128, 1, 1]"
4224,0,2.976,7,6928969441161.799,99,7,kernel,47.619049,"[25, 4, 5]",40,7776,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1412,0,5.952381,1,"[256, 1, 1]"
4224,0,9.087,7,6928969441186.631,99,7,kernel,47.619049,"[25, 4, 5]",38,7796,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1412,0,5.952381,1,"[256, 1, 1]"
4224,0,8.479,7,6928969441196.487,99,7,kernel,47.619049,"[25, 4, 5]",38,7798,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1412,0,5.952381,1,"[256, 1, 1]"
73728,0,32.831,7,6928969441221.031,0,7,kernel,3.809524,"[4, 5, 4]",148,7803,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi16EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi16ELi64EEESC_NSE_INSF_ILi64ELi16EEELi128ESH_Li4EEESK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESY_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SQ_SC_S11_fNSO_8RowMajorENS15_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S18_SC_NSO_11ColumnMajorEfS18_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1I_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1H_Li1ENS1M_22PredicatedTileIteratorINS1M_26OutputTileOptimalThreadMapINS1M_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1Q_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1L_4warp24FragmentIteratorTensorOpIS17_S1B_fNS_5ArrayIfLi4ELb1EEES18_EENS1W_20TileIteratorTensorOpIS17_S1B_fS18_EENS1M_18SharedLoadIteratorINS1T_18CompactedThreadMapEfLi16EEENS1L_6thread17LinearCombinationIfLi4EffLNS26_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS13_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,1412,0,0.952381,1,"[128, 1, 1]"
0,0,2.784,7,6928969441254.598,29,7,kernel,13.714286,"[32, 9, 1]",36,7806,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,1412,0,3.428571,1,"[32, 4, 1]"
4224,0,2.944,7,6928969441258.119,100,7,kernel,48.761906,"[1, 4, 128]",40,7810,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1412,0,6.095238,1,"[256, 1, 1]"
0,0,11.807,7,6928969441287.591,97,7,kernel,46.666668,"[980, 1, 1]",22,7819,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1415,0,11.666667,1,"[128, 1, 1]"
0,0,7.519,7,6928969441366.311,97,7,kernel,46.666668,"[980, 1, 1]",22,7839,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1422,0,11.666667,1,"[128, 1, 1]"
33040,0,9.184,7,6928969441495.174,51,7,kernel,24.380953,"[128, 1, 1]",45,7887,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1427,0,1.52381,1,"[512, 1, 1]"
0,0,7.008,7,6928969454489.905,100,7,kernel,373.333344,"[3920, 1, 1]",24,8074,X,"void cudnn::engines_precompiled::scalePackedTensor_kernel<float, float>(long, float*, float)",0,1443,0,46.666668,1,"[256, 1, 1]"
3328,0,16.928,7,6928969455420.784,6,7,kernel,2.976191,"[1, 25, 5]",96,8076,X,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)",0,1443,0,1.488095,1,"[8, 8, 1]"
4224,0,14.272,7,6928969457248.269,100,7,kernel,93.333336,"[98, 2, 5]",38,8183,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1443,0,11.666667,1,"[256, 1, 1]"
4224,0,8.736,7,6928969457264.109,99,7,kernel,47.619049,"[25, 4, 5]",38,8185,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1443,0,5.952381,1,"[256, 1, 1]"
2048,0,14.368,7,6928969458989.162,20,7,kernel,9.523809,"[1, 8, 25]",108,8189,X,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize16x64x64_stage1_warpsize1x4x1_g1_tensor16x8x8_aligna8_alignc8_execute_kernel__5x_cudnn,0,1443,0,2.380952,1,"[128, 1, 1]"
33040,0,12.672,7,6928969459347.338,51,7,kernel,24.380953,"[128, 1, 1]",45,8240,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1452,0,1.52381,1,"[512, 1, 1]"
4224,0,4.384,7,6928969459540.297,100,7,kernel,48.761906,"[1, 4, 128]",38,8271,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1468,0,6.095238,1,"[256, 1, 1]"
4224,0,2.976,7,6928969459552.297,99,7,kernel,47.619049,"[25, 4, 5]",38,8273,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1468,0,5.952381,1,"[256, 1, 1]"
73728,0,27.233,7,6928969459570.985,0,7,kernel,2.952381,"[62, 1, 1]",161,8277,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,1468,0,0.738095,1,"[128, 1, 1]"
4224,0,3.168,7,6928969459598.985,99,7,kernel,47.619049,"[25, 4, 5]",40,8281,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1468,0,5.952381,1,"[256, 1, 1]"
4224,0,8.64,7,6928969459639.977,99,7,kernel,47.619049,"[25, 4, 5]",38,8301,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1468,0,5.952381,1,"[256, 1, 1]"
4224,0,8.512,7,6928969459650.377,99,7,kernel,47.619049,"[25, 4, 5]",38,8303,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1468,0,5.952381,1,"[256, 1, 1]"
73728,0,33.216,7,6928969459683.273,0,7,kernel,3.809524,"[4, 5, 4]",148,8308,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi16EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi16ELi64EEESC_NSE_INSF_ILi64ELi16EEELi128ESH_Li4EEESK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESY_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SQ_SC_S11_fNSO_8RowMajorENS15_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S18_SC_NSO_11ColumnMajorEfS18_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1I_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1H_Li1ENS1M_22PredicatedTileIteratorINS1M_26OutputTileOptimalThreadMapINS1M_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1Q_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1L_4warp24FragmentIteratorTensorOpIS17_S1B_fNS_5ArrayIfLi4ELb1EEES18_EENS1W_20TileIteratorTensorOpIS17_S1B_fS18_EENS1M_18SharedLoadIteratorINS1T_18CompactedThreadMapEfLi16EEENS1L_6thread17LinearCombinationIfLi4EffLNS26_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS13_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,1468,0,0.952381,1,"[128, 1, 1]"
0,0,2.816,7,6928969459717.321,29,7,kernel,13.714286,"[32, 9, 1]",36,8311,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,1468,0,3.428571,1,"[32, 4, 1]"
4224,0,3.008,7,6928969459721.033,100,7,kernel,48.761906,"[1, 4, 128]",40,8315,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1468,0,6.095238,1,"[256, 1, 1]"
0,0,11.872,7,6928969459826.569,97,7,kernel,46.666668,"[980, 1, 1]",22,8335,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1477,0,11.666667,1,"[128, 1, 1]"
33040,0,9.408,7,6928969459958.825,51,7,kernel,24.380953,"[128, 1, 1]",45,8379,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1480,0,1.52381,1,"[512, 1, 1]"
4224,0,3.456,7,6928969461791.878,51,7,kernel,24.380953,"[1, 2, 128]",38,8585,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1496,0,3.047619,1,"[256, 1, 1]"
4224,0,2.976,7,6928969461804.614,99,7,kernel,47.619049,"[25, 4, 5]",38,8587,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1496,0,5.952381,1,"[256, 1, 1]"
73728,0,26.752,7,6928969461823.75,0,7,kernel,5.904762,"[124, 1, 1]",180,8591,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,1496,0,1.47619,1,"[128, 1, 1]"
4224,0,9.44,7,6928969461851.366,100,7,kernel,93.333336,"[98, 2, 5]",40,8595,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1496,0,11.666667,1,"[256, 1, 1]"
4224,0,16.32,7,6928969463510.019,100,7,kernel,93.333336,"[98, 2, 5]",38,8704,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1496,0,11.666667,1,"[256, 1, 1]"
4224,0,8.352,7,6928969463527.107,99,7,kernel,47.619049,"[25, 4, 5]",38,8706,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1496,0,5.952381,1,"[256, 1, 1]"
98304,0,31.552,7,6928969463677.251,0,7,kernel,2.571429,"[9, 2, 3]",128,8714,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1496,0,0.642857,1,"[128, 1, 1]"
4224,0,2.4,7,6928969463709.635,51,7,kernel,24.380953,"[1, 2, 128]",40,8717,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1496,0,3.047619,1,"[256, 1, 1]"
0,0,21.088,7,6928969463823.619,100,7,kernel,93.333336,"[1960, 1, 1]",22,8726,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1499,0,23.333334,1,"[128, 1, 1]"
0,0,16.64,7,6928969463942.627,100,7,kernel,93.333336,"[1960, 1, 1]",22,8746,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1506,0,23.333334,1,"[128, 1, 1]"
400,0,35.936,7,6928969464157.026,25,7,kernel,12.190476,"[64, 1, 1]",40,8793,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1511,0,0.761905,1,"[512, 1, 1]"
8704,0,2.528,7,6928969465946.079,3,7,kernel,1.52381,"[2, 16, 1]",40,8985,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1527,0,0.380952,1,"[32, 4, 1]"
49152,0,55.712,7,6928969466041.023,33,7,kernel,26.666666,"[10, 7, 4]",126,8987,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,1527,0,3.333333,1,"[256, 1, 1]"
4224,0,13.76,7,6928969467470.141,100,7,kernel,93.333336,"[98, 2, 5]",38,9096,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1527,0,11.666667,1,"[256, 1, 1]"
4224,0,15.936,7,6928969467485.501,100,7,kernel,93.333336,"[98, 2, 5]",38,9098,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1527,0,11.666667,1,"[256, 1, 1]"
98304,0,49.856,7,6928969467523.485,0,7,kernel,3.0,"[9, 1, 7]",128,9106,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1527,0,0.75,1,"[128, 1, 1]"
4224,0,2.592,7,6928969467574.141,25,7,kernel,12.190476,"[1, 2, 64]",40,9109,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1527,0,1.52381,1,"[256, 1, 1]"
0,0,19.264,7,6928969467740.957,100,7,kernel,93.333336,"[1960, 1, 1]",22,9129,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1536,0,23.333334,1,"[128, 1, 1]"
400,0,35.488,7,6928969467891.068,25,7,kernel,12.190476,"[64, 1, 1]",40,9172,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1539,0,0.761905,1,"[512, 1, 1]"
8704,0,2.496,7,6928969468040.764,3,7,kernel,1.52381,"[2, 16, 1]",40,9203,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1555,0,0.380952,1,"[32, 4, 1]"
49152,0,55.776,7,6928969468051.868,33,7,kernel,26.666666,"[10, 7, 4]",126,9205,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,1555,0,3.333333,1,"[256, 1, 1]"
4224,0,14.112,7,6928969468108.38,100,7,kernel,93.333336,"[98, 2, 5]",38,9225,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1555,0,11.666667,1,"[256, 1, 1]"
4224,0,16.096,7,6928969468123.196,100,7,kernel,93.333336,"[98, 2, 5]",38,9227,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1555,0,11.666667,1,"[256, 1, 1]"
98304,0,49.12,7,6928969468145.308,0,7,kernel,3.0,"[9, 1, 7]",128,9235,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1555,0,0.75,1,"[128, 1, 1]"
4224,0,2.688,7,6928969468195.26,25,7,kernel,12.190476,"[1, 2, 64]",40,9238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1555,0,1.52381,1,"[256, 1, 1]"
0,0,19.007,7,6928969468203.1,100,7,kernel,93.333336,"[1960, 1, 1]",22,9247,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1558,0,23.333334,1,"[128, 1, 1]"
0,0,16.705,7,6928969468281.371,100,7,kernel,93.333336,"[1960, 1, 1]",22,9267,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1565,0,23.333334,1,"[128, 1, 1]"
400,0,36.895,7,6928969468403.388,25,7,kernel,12.190476,"[64, 1, 1]",40,9314,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1570,0,0.761905,1,"[512, 1, 1]"
8704,0,2.656,7,6928969468535.387,3,7,kernel,1.52381,"[2, 16, 1]",40,9345,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1586,0,0.380952,1,"[32, 4, 1]"
49152,0,55.712,7,6928969468544.731,33,7,kernel,26.666666,"[10, 7, 4]",126,9347,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,1586,0,3.333333,1,"[256, 1, 1]"
4224,0,14.208,7,6928969468601.179,100,7,kernel,93.333336,"[98, 2, 5]",38,9367,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1586,0,11.666667,1,"[256, 1, 1]"
4224,0,16.16,7,6928969468616.187,100,7,kernel,93.333336,"[98, 2, 5]",38,9369,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1586,0,11.666667,1,"[256, 1, 1]"
98304,0,49.376,7,6928969468638.139,0,7,kernel,3.0,"[9, 1, 7]",128,9377,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1586,0,0.75,1,"[128, 1, 1]"
4224,0,2.688,7,6928969468688.283,25,7,kernel,12.190476,"[1, 2, 64]",40,9380,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1586,0,1.52381,1,"[256, 1, 1]"
0,0,19.104,7,6928969468725.851,100,7,kernel,93.333336,"[1960, 1, 1]",22,9400,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1595,0,23.333334,1,"[128, 1, 1]"
400,0,35.008,7,6928969468828.507,25,7,kernel,12.190476,"[64, 1, 1]",40,9443,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1598,0,0.761905,1,"[512, 1, 1]"
8704,0,2.528,7,6928969468953.467,3,7,kernel,1.52381,"[2, 16, 1]",40,9474,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1614,0,0.380952,1,"[32, 4, 1]"
49152,0,55.616,7,6928969468963.258,33,7,kernel,26.666666,"[10, 7, 4]",126,9476,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,1614,0,3.333333,1,"[256, 1, 1]"
4224,0,13.951,7,6928969469019.611,100,7,kernel,93.333336,"[98, 2, 5]",38,9496,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1614,0,11.666667,1,"[256, 1, 1]"
4224,0,15.776,7,6928969469034.266,100,7,kernel,93.333336,"[98, 2, 5]",38,9498,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1614,0,11.666667,1,"[256, 1, 1]"
98304,0,49.44,7,6928969469055.61,0,7,kernel,3.0,"[9, 1, 7]",128,9506,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1614,0,0.75,1,"[128, 1, 1]"
4224,0,2.624,7,6928969469105.882,25,7,kernel,12.190476,"[1, 2, 64]",40,9509,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1614,0,1.52381,1,"[256, 1, 1]"
0,0,19.328,7,6928969469109.338,100,7,kernel,93.333336,"[1960, 1, 1]",22,9518,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,1617,0,23.333334,1,"[128, 1, 1]"
0,0,28.64,7,6928969469254.842,100,7,kernel,373.333344,"[7840, 1, 1]",16,9540,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,1626,0,93.333336,1,"[128, 1, 1]"
0,0,96.96,7,6928969469331.194,100,7,kernel,1493.333374,"[49, 5, 64]",40,9549,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,1624,0,186.666672,1,"[256, 1, 1]"
0,0,85.215,7,6928969469428.954,100,7,kernel,373.333344,"[7840, 1, 1]",22,9563,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,1629,0,93.333336,1,"[128, 1, 1]"
400,0,149.344,7,6928969469549.722,25,7,kernel,12.190476,"[64, 1, 1]",40,9606,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1632,0,0.761905,1,"[512, 1, 1]"
2304,0,144.479,7,6928969470805.752,50,7,kernel,29.761906,"[5, 2, 125]",80,9724,X,"void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",0,1648,0,14.880953,1,"[8, 8, 1]"
