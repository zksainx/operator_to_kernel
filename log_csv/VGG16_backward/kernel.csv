shared memory,pid,dur,stream,ts,est. achieved occupancy %,tid,cat,warps per SM,grid,registers per thread,correlation,ph,name,device,External id,queued,blocks per SM,context,block
528,0,4.192,7,6940680715155.497,0,7,kernel,0.047619,"[1, 1, 1]",32,3514,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,515,0,0.011905,1,"[128, 1, 1]"
0,0,1.536,7,6940680723774.624,0,7,kernel,0.047619,"[1, 1, 1]",16,3527,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,520,0,0.011905,1,"[128, 1, 1]"
0,0,2.496,7,6940680744734.245,0,7,kernel,0.190476,"[4, 1, 1]",16,3553,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,1038,0,0.047619,1,"[128, 1, 1]"
2304,0,34.144,7,6940680744740.901,25,7,kernel,12.190476,"[64, 1, 1]",128,3592,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, false, false, 9, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,1034,0,0.761905,1,"[64, 8, 1]"
0,0,1.791,7,6940680744775.814,0,7,kernel,0.190476,"[4, 1, 1]",16,3610,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,1046,0,0.047619,1,"[128, 1, 1]"
1024,0,29.184,7,6940680747085.844,100,7,kernel,390.095245,"[128, 32, 1]",20,3624,X,"void gemmk1_kernel<int, float, 256, 5, false, false, false, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<float, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, biasType<cublasGemvTensorStridedBatched<float>::value_type, float>::type>)",0,1042,0,48.761906,1,"[256, 1, 1]"
16,0,4.544,7,6940680747115.828,1,7,kernel,0.380952,"[2, 1, 1]",32,3637,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1050,0,0.02381,1,"[512, 1, 1]"
0,0,1.888,7,6940680747371.158,1,7,kernel,0.380952,"[8, 1, 1]",22,3666,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,1067,0,0.095238,1,"[128, 1, 1]"
2304,0,127.009,7,6940680747905.241,33,7,kernel,48.761906,"[64, 1, 4]",128,3688,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, false, false, 9, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,1075,0,3.047619,1,"[64, 8, 1]"
0,0,3.456,7,6940680755018.79,67,7,kernel,48.761906,"[1, 256, 1]",44,3690,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,1075,0,3.047619,1,"[32, 16, 1]"
16384,0,123.713,7,6940680762867.096,67,7,kernel,390.095245,"[32, 128, 1]",57,3712,X,ampere_sgemm_128x32_nn,0,1079,0,48.761906,1,"[256, 1, 1]"
16,0,4.799,7,6940680765331.112,1,7,kernel,0.380952,"[8, 1, 1]",48,3725,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1083,0,0.095238,1,"[128, 1, 1]"
0,0,1.888,7,6940680765336.616,1,7,kernel,0.380952,"[8, 1, 1]",22,3754,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,1100,0,0.095238,1,"[128, 1, 1]"
16384,0,694.148,7,6940680765342.024,67,7,kernel,93.333336,"[196, 1, 5]",57,3777,X,ampere_sgemm_128x32_nn,0,1108,0,11.666667,1,"[256, 1, 1]"
16384,0,722.213,7,6940680766036.908,67,7,kernel,2389.333252,"[196, 128, 1]",57,3799,X,ampere_sgemm_128x32_nn,0,1112,0,298.666656,1,"[256, 1, 1]"
16,0,2.848,7,6940680766759.825,1,7,kernel,0.380952,"[8, 1, 1]",48,3812,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1116,0,0.095238,1,"[128, 1, 1]"
0,0,1.632,7,6940680766763.473,19,7,kernel,9.333333,"[196, 1, 1]",16,3844,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,1139,0,2.333333,1,"[128, 1, 1]"
0,0,5.152,7,6940680766769.041,100,7,kernel,48.761906,"[1, 1, 512]",40,3853,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,1137,0,6.095238,1,"[256, 1, 1]"
0,0,3.68,7,6940680769149.696,19,7,kernel,9.333333,"[196, 1, 1]",23,3870,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1142,0,2.333333,1,"[128, 1, 1]"
4368,0,10.912,7,6940680781008.715,67,7,kernel,97.523811,"[512, 1, 1]",45,3963,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1146,0,6.095238,1,"[512, 1, 1]"
4224,0,34.016,7,6940680809774.946,100,7,kernel,780.190491,"[1, 16, 512]",38,4154,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1162,0,97.523811,1,"[256, 1, 1]"
4224,0,3.872,7,6940680809809.666,22,7,kernel,10.666667,"[7, 16, 1]",38,4156,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1162,0,1.333333,1,"[256, 1, 1]"
65536,0,44.288,7,6940680816604.27,0,7,kernel,3.047619,"[4, 2, 8]",250,4162,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1162,0,0.761905,1,"[128, 1, 1]"
4224,0,2.592,7,6940680816649.23,22,7,kernel,10.666667,"[7, 16, 1]",40,4165,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1162,0,1.333333,1,"[256, 1, 1]"
4224,0,3.424,7,6940680841619.596,22,7,kernel,10.666667,"[7, 16, 1]",38,4289,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1162,0,1.333333,1,"[256, 1, 1]"
4224,0,3.36,7,6940680841623.724,22,7,kernel,10.666667,"[7, 16, 1]",38,4291,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1162,0,1.333333,1,"[256, 1, 1]"
73728,0,36.736,7,6940680841627.852,0,7,kernel,6.857143,"[8, 9, 1]",229,4295,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),0,1162,0,0.857143,1,"[256, 1, 1]"
4224,0,33.088,7,6940680841665.324,100,7,kernel,780.190491,"[1, 16, 512]",40,4299,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1162,0,97.523811,1,"[256, 1, 1]"
16,0,4.064,7,6940680841965.262,13,7,kernel,6.095238,"[32, 1, 1]",32,4313,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1165,0,0.380952,1,"[32, 16, 1]"
0,0,3.776,7,6940680841970.158,19,7,kernel,9.333333,"[196, 1, 1]",23,4340,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1177,0,2.333333,1,"[128, 1, 1]"
4368,0,11.232,7,6940680842211.568,67,7,kernel,97.523811,"[512, 1, 1]",45,4384,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1181,0,6.095238,1,"[512, 1, 1]"
4224,0,33.216,7,6940680842223.568,100,7,kernel,780.190491,"[1, 16, 512]",38,4415,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1197,0,97.523811,1,"[256, 1, 1]"
4224,0,4.032,7,6940680842257.552,22,7,kernel,10.666667,"[7, 16, 1]",38,4417,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1197,0,1.333333,1,"[256, 1, 1]"
65536,0,44.416,7,6940680842264.048,0,7,kernel,3.047619,"[4, 2, 8]",250,4423,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1197,0,0.761905,1,"[128, 1, 1]"
4224,0,2.655,7,6940680842309.201,22,7,kernel,10.666667,"[7, 16, 1]",40,4426,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1197,0,1.333333,1,"[256, 1, 1]"
4224,0,3.617,7,6940680842312.656,22,7,kernel,10.666667,"[7, 16, 1]",38,4446,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1197,0,1.333333,1,"[256, 1, 1]"
4224,0,3.648,7,6940680842317.008,22,7,kernel,10.666667,"[7, 16, 1]",38,4448,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1197,0,1.333333,1,"[256, 1, 1]"
73728,0,37.568,7,6940680842321.361,0,7,kernel,6.857143,"[8, 9, 1]",229,4452,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),0,1197,0,0.857143,1,"[256, 1, 1]"
4224,0,33.025,7,6940680842359.728,100,7,kernel,780.190491,"[1, 16, 512]",40,4456,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1197,0,97.523811,1,"[256, 1, 1]"
16,0,5.44,7,6940680842393.489,13,7,kernel,6.095238,"[32, 1, 1]",32,4470,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1200,0,0.380952,1,"[32, 16, 1]"
0,0,3.808,7,6940680842399.761,19,7,kernel,9.333333,"[196, 1, 1]",23,4497,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1212,0,2.333333,1,"[128, 1, 1]"
4368,0,11.232,7,6940680844762.208,67,7,kernel,97.523811,"[512, 1, 1]",45,4541,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1216,0,6.095238,1,"[512, 1, 1]"
4224,0,33.92,7,6940680844774.24,100,7,kernel,780.190491,"[1, 16, 512]",38,4572,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1232,0,97.523811,1,"[256, 1, 1]"
4224,0,4.096,7,6940680844808.928,22,7,kernel,10.666667,"[7, 16, 1]",38,4574,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1232,0,1.333333,1,"[256, 1, 1]"
65536,0,43.904,7,6940680844815.872,0,7,kernel,3.047619,"[4, 2, 8]",250,4580,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1232,0,0.761905,1,"[128, 1, 1]"
4224,0,2.528,7,6940680844860.64,22,7,kernel,10.666667,"[7, 16, 1]",40,4583,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1232,0,1.333333,1,"[256, 1, 1]"
4224,0,3.457,7,6940680844864.064,22,7,kernel,10.666667,"[7, 16, 1]",38,4603,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1232,0,1.333333,1,"[256, 1, 1]"
4224,0,3.329,7,6940680844868.352,22,7,kernel,10.666667,"[7, 16, 1]",38,4605,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1232,0,1.333333,1,"[256, 1, 1]"
73728,0,37.088,7,6940680844872.481,0,7,kernel,6.857143,"[8, 9, 1]",229,4609,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x128_16x3_nhwc_align4::Params),0,1232,0,0.857143,1,"[256, 1, 1]"
4224,0,32.96,7,6940680844910.401,100,7,kernel,780.190491,"[1, 16, 512]",40,4613,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1232,0,97.523811,1,"[256, 1, 1]"
16,0,5.408,7,6940680844944.097,13,7,kernel,6.095238,"[32, 1, 1]",32,4627,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1235,0,0.380952,1,"[32, 16, 1]"
0,0,2.144,7,6940680844950.305,78,7,kernel,37.333332,"[784, 1, 1]",16,4653,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,1249,0,9.333333,1,"[128, 1, 1]"
0,0,11.584,7,6940680844953.313,100,7,kernel,195.047623,"[4, 1, 512]",40,4662,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,1247,0,24.380953,1,"[256, 1, 1]"
0,0,6.56,7,6940680844965.729,78,7,kernel,37.333332,"[784, 1, 1]",23,4679,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1252,0,9.333333,1,"[128, 1, 1]"
8464,0,14.048,7,6940680844973.089,67,7,kernel,97.523811,"[512, 1, 1]",45,4723,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1256,0,6.095238,1,"[512, 1, 1]"
4224,0,33.601,7,6940680844987.937,100,7,kernel,780.190491,"[1, 16, 512]",38,4929,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1272,0,97.523811,1,"[256, 1, 1]"
4224,0,7.552,7,6940680845022.338,79,7,kernel,38.095238,"[25, 16, 1]",38,4931,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1272,0,4.761905,1,"[256, 1, 1]"
73728,0,100.545,7,6940680845030.593,0,7,kernel,2.666667,"[7, 8, 1]",180,4935,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,1272,0,0.666667,1,"[128, 1, 1]"
4224,0,3.04,7,6940680845132.29,79,7,kernel,38.095238,"[25, 16, 1]",40,4939,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1272,0,4.761905,1,"[256, 1, 1]"
4224,0,7.232,7,6940680847420.401,79,7,kernel,38.095238,"[25, 16, 1]",38,5063,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1272,0,4.761905,1,"[256, 1, 1]"
4224,0,7.968,7,6940680847428.369,79,7,kernel,38.095238,"[25, 16, 1]",38,5065,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1272,0,4.761905,1,"[256, 1, 1]"
73728,0,86.401,7,6940680847437.137,0,7,kernel,6.857143,"[8, 9, 1]",251,5069,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4::Params),0,1272,0,0.857143,1,"[256, 1, 1]"
4224,0,33.089,7,6940680847524.337,100,7,kernel,780.190491,"[1, 16, 512]",40,5073,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1272,0,97.523811,1,"[256, 1, 1]"
16,0,8.416,7,6940680847558.162,13,7,kernel,6.095238,"[32, 1, 1]",32,5087,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1275,0,0.380952,1,"[32, 16, 1]"
0,0,9.504,7,6940680847567.314,78,7,kernel,37.333332,"[784, 1, 1]",23,5114,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1287,0,9.333333,1,"[128, 1, 1]"
8464,0,13.952,7,6940680847577.586,67,7,kernel,97.523811,"[512, 1, 1]",45,5158,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1291,0,6.095238,1,"[512, 1, 1]"
4224,0,33.248,7,6940680847592.37,100,7,kernel,780.190491,"[1, 16, 512]",38,5189,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1307,0,97.523811,1,"[256, 1, 1]"
4224,0,7.456,7,6940680847626.418,79,7,kernel,38.095238,"[25, 16, 1]",38,5191,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1307,0,4.761905,1,"[256, 1, 1]"
73728,0,100.129,7,6940680847634.61,0,7,kernel,2.666667,"[7, 8, 1]",180,5195,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,1307,0,0.666667,1,"[128, 1, 1]"
4224,0,3.008,7,6940680847735.795,79,7,kernel,38.095238,"[25, 16, 1]",40,5199,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1307,0,4.761905,1,"[256, 1, 1]"
4224,0,7.648,7,6940680847739.475,79,7,kernel,38.095238,"[25, 16, 1]",38,5219,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1307,0,4.761905,1,"[256, 1, 1]"
4224,0,6.592,7,6940680847747.891,79,7,kernel,38.095238,"[25, 16, 1]",38,5221,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1307,0,4.761905,1,"[256, 1, 1]"
73728,0,86.593,7,6940680847755.315,0,7,kernel,6.857143,"[8, 9, 1]",251,5225,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3_nhwc_align4::Params),0,1307,0,0.857143,1,"[256, 1, 1]"
4224,0,32.96,7,6940680847842.708,100,7,kernel,780.190491,"[1, 16, 512]",40,5229,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1307,0,97.523811,1,"[256, 1, 1]"
16,0,8.352,7,6940680847876.436,13,7,kernel,6.095238,"[32, 1, 1]",32,5243,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1310,0,0.380952,1,"[32, 16, 1]"
0,0,9.376,7,6940680847885.524,78,7,kernel,37.333332,"[784, 1, 1]",23,5270,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1322,0,9.333333,1,"[128, 1, 1]"
8464,0,13.952,7,6940680847895.636,67,7,kernel,97.523811,"[512, 1, 1]",45,5314,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1326,0,6.095238,1,"[512, 1, 1]"
4224,0,18.144,7,6940680850238.115,100,7,kernel,390.095245,"[1, 8, 512]",38,5519,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1342,0,48.761906,1,"[256, 1, 1]"
4224,0,7.712,7,6940680850257.027,79,7,kernel,38.095238,"[25, 16, 1]",38,5521,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1342,0,4.761905,1,"[256, 1, 1]"
81920,0,54.24,7,6940680850265.539,0,7,kernel,2.476191,"[52, 1, 1]",118,5525,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_unity_stride_align4::Params),0,1342,0,0.619048,1,"[128, 1, 1]"
4224,0,2.848,7,6940680850320.611,40,7,kernel,19.047619,"[25, 8, 1]",40,5529,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1342,0,2.380952,1,"[256, 1, 1]"
4224,0,4.0,7,6940680850324.195,40,7,kernel,19.047619,"[25, 8, 1]",38,5654,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1342,0,2.380952,1,"[256, 1, 1]"
4224,0,6.08,7,6940680850328.899,79,7,kernel,38.095238,"[25, 16, 1]",38,5656,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1342,0,4.761905,1,"[256, 1, 1]"
81920,0,45.888,7,6940680850335.78,0,7,kernel,3.428571,"[8, 9, 1]",234,5660,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,1342,0,0.857143,1,"[128, 1, 1]"
4224,0,15.199,7,6940680850382.404,100,7,kernel,390.095245,"[1, 8, 512]",40,5664,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1342,0,48.761906,1,"[256, 1, 1]"
16,0,8.256,7,6940680850398.34,13,7,kernel,6.095238,"[32, 1, 1]",32,5678,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1345,0,0.380952,1,"[32, 16, 1]"
0,0,4.0,7,6940680850407.428,100,7,kernel,74.666664,"[1568, 1, 1]",16,5704,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,1359,0,18.666666,1,"[128, 1, 1]"
0,0,18.976,7,6940680850412.228,100,7,kernel,316.952393,"[13, 1, 256]",40,5713,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,1357,0,39.619049,1,"[256, 1, 1]"
0,0,10.848,7,6940680850432.004,100,7,kernel,74.666664,"[1568, 1, 1]",23,5730,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1362,0,18.666666,1,"[128, 1, 1]"
28944,0,17.344,7,6940680850443.62,67,7,kernel,48.761906,"[256, 1, 1]",45,5774,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1366,0,3.047619,1,"[512, 1, 1]"
4224,0,9.856,7,6940680852044.462,100,7,kernel,195.047623,"[1, 8, 256]",38,5979,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1382,0,24.380953,1,"[256, 1, 1]"
4224,0,12.832,7,6940680852055.054,100,7,kernel,74.666664,"[98, 8, 1]",38,5981,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1382,0,9.333333,1,"[256, 1, 1]"
73728,0,101.153,7,6940680852068.59,0,7,kernel,4.761905,"[100, 1, 1]",161,5985,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,1382,0,1.190476,1,"[128, 1, 1]"
4224,0,7.808,7,6940680852170.575,100,7,kernel,74.666664,"[98, 8, 1]",40,5989,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1382,0,9.333333,1,"[256, 1, 1]"
4224,0,12.64,7,6940680852428.017,100,7,kernel,74.666664,"[98, 8, 1]",38,6113,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1382,0,9.333333,1,"[256, 1, 1]"
4224,0,13.28,7,6940680852441.329,100,7,kernel,74.666664,"[98, 8, 1]",38,6115,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1382,0,9.333333,1,"[256, 1, 1]"
81920,0,79.168,7,6940680852457.073,0,7,kernel,3.428571,"[4, 9, 2]",234,6120,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,1382,0,0.857143,1,"[128, 1, 1]"
4224,0,7.456,7,6940680852537.041,100,7,kernel,195.047623,"[1, 8, 256]",40,6124,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1382,0,24.380953,1,"[256, 1, 1]"
16,0,14.4,7,6940680852545.297,6,7,kernel,3.047619,"[16, 1, 1]",32,6138,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1385,0,0.190476,1,"[32, 16, 1]"
0,0,16.64,7,6940680852560.402,100,7,kernel,74.666664,"[1568, 1, 1]",23,6165,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1397,0,18.666666,1,"[128, 1, 1]"
28944,0,20.64,7,6940680854849.12,67,7,kernel,48.761906,"[256, 1, 1]",45,6209,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1401,0,3.047619,1,"[512, 1, 1]"
4224,0,10.656,7,6940680854870.56,100,7,kernel,195.047623,"[1, 8, 256]",38,6240,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1417,0,24.380953,1,"[256, 1, 1]"
4224,0,11.712,7,6940680854882.016,100,7,kernel,74.666664,"[98, 8, 1]",38,6242,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1417,0,9.333333,1,"[256, 1, 1]"
73728,0,101.185,7,6940680854894.528,0,7,kernel,4.761905,"[100, 1, 1]",161,6246,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,1417,0,1.190476,1,"[128, 1, 1]"
4224,0,7.936,7,6940680854996.577,100,7,kernel,74.666664,"[98, 8, 1]",40,6250,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1417,0,9.333333,1,"[256, 1, 1]"
4224,0,13.216,7,6940680855005.217,100,7,kernel,74.666664,"[98, 8, 1]",38,6270,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1417,0,9.333333,1,"[256, 1, 1]"
4224,0,13.056,7,6940680855019.297,100,7,kernel,74.666664,"[98, 8, 1]",38,6272,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1417,0,9.333333,1,"[256, 1, 1]"
81920,0,79.489,7,6940680855034.753,0,7,kernel,3.428571,"[4, 9, 2]",234,6277,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,1417,0,0.857143,1,"[128, 1, 1]"
4224,0,7.36,7,6940680855115.01,100,7,kernel,195.047623,"[1, 8, 256]",40,6281,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1417,0,24.380953,1,"[256, 1, 1]"
16,0,14.4,7,6940680855123.106,6,7,kernel,3.047619,"[16, 1, 1]",32,6295,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1420,0,0.190476,1,"[32, 16, 1]"
0,0,16.544,7,6940680855138.242,100,7,kernel,74.666664,"[1568, 1, 1]",23,6322,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1432,0,18.666666,1,"[128, 1, 1]"
28944,0,16.704,7,6940680855155.618,67,7,kernel,48.761906,"[256, 1, 1]",45,6366,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,1436,0,3.047619,1,"[512, 1, 1]"
4224,0,6.816,7,6940680855173.122,100,7,kernel,97.523811,"[1, 4, 256]",38,6572,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1452,0,12.190476,1,"[256, 1, 1]"
4224,0,9.12,7,6940680855180.738,100,7,kernel,74.666664,"[98, 8, 1]",38,6574,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1452,0,9.333333,1,"[256, 1, 1]"
73728,0,49.664,7,6940680855190.562,0,7,kernel,2.380952,"[50, 1, 1]",167,6578,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4::Params),0,1452,0,0.595238,1,"[128, 1, 1]"
4224,0,2.784,7,6940680855240.931,78,7,kernel,37.333332,"[98, 4, 1]",40,6582,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1452,0,4.666667,1,"[256, 1, 1]"
4224,0,6.592,7,6940680857356.976,78,7,kernel,37.333332,"[98, 4, 1]",38,6691,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1452,0,4.666667,1,"[256, 1, 1]"
4224,0,13.44,7,6940680857364.336,100,7,kernel,74.666664,"[98, 8, 1]",38,6693,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1452,0,9.333333,1,"[256, 1, 1]"
98304,0,61.088,7,6940680857612.434,0,7,kernel,3.428571,"[18, 4, 1]",128,6698,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1452,0,0.857143,1,"[128, 1, 1]"
4224,0,4.608,7,6940680857674.354,100,7,kernel,97.523811,"[1, 4, 256]",40,6701,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1452,0,12.190476,1,"[256, 1, 1]"
16,0,13.728,7,6940680857679.666,6,7,kernel,3.047619,"[16, 1, 1]",32,6715,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1455,0,0.190476,1,"[32, 16, 1]"
0,0,12.288,7,6940680858059.956,100,7,kernel,149.333328,"[3136, 1, 1]",16,6741,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,1469,0,37.333332,1,"[128, 1, 1]"
0,0,34.88,7,6940680858073.045,100,7,kernel,597.333313,"[49, 1, 128]",40,6750,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,1467,0,74.666664,1,"[256, 1, 1]"
0,0,35.424,7,6940680858108.693,100,7,kernel,149.333328,"[3136, 1, 1]",23,6767,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1472,0,37.333332,1,"[128, 1, 1]"
400,0,51.616,7,6940680858148.501,51,7,kernel,24.380953,"[128, 1, 1]",40,6810,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1476,0,1.52381,1,"[512, 1, 1]"
4224,0,4.192,7,6940680859438.269,100,7,kernel,48.761906,"[1, 4, 128]",38,7015,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1492,0,6.095238,1,"[256, 1, 1]"
4224,0,24.801,7,6940680859443.165,100,7,kernel,149.333328,"[392, 4, 1]",38,7017,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1492,0,18.666666,1,"[256, 1, 1]"
73728,0,87.073,7,6940680859468.637,0,7,kernel,9.333333,"[196, 1, 1]",167,7021,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_32x3_nhwc_unity_stride_align4::Params),0,1492,0,2.333333,1,"[128, 1, 1]"
4224,0,22.336,7,6940680859556.478,100,7,kernel,149.333328,"[392, 4, 1]",40,7025,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1492,0,18.666666,1,"[256, 1, 1]"
4224,0,24.001,7,6940680860879.686,100,7,kernel,149.333328,"[392, 4, 1]",38,7134,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1492,0,18.666666,1,"[256, 1, 1]"
4224,0,25.216,7,6940680860904.487,100,7,kernel,149.333328,"[392, 4, 1]",38,7136,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1492,0,18.666666,1,"[256, 1, 1]"
98304,0,99.169,7,6940680863212.821,0,7,kernel,3.428571,"[18, 1, 4]",168,7144,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1492,0,0.857143,1,"[128, 1, 1]"
9216,0,2.72,7,6940680863316.022,7,7,kernel,3.428571,"[18, 1, 4]",64,7146,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_split_k_kernel__5x_cudnn,0,1492,0,0.857143,1,"[128, 1, 1]"
4224,0,3.424,7,6940680863319.51,100,7,kernel,48.761906,"[1, 4, 128]",40,7149,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1492,0,6.095238,1,"[256, 1, 1]"
2064,0,15.808,7,6940680863323.734,51,7,kernel,24.380953,"[128, 1, 1]",32,7162,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1495,0,1.52381,1,"[32, 16, 1]"
0,0,30.048,7,6940680863340.342,100,7,kernel,149.333328,"[3136, 1, 1]",23,7189,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1507,0,37.333332,1,"[128, 1, 1]"
400,0,51.52,7,6940680863371.158,51,7,kernel,24.380953,"[128, 1, 1]",40,7232,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1511,0,1.52381,1,"[512, 1, 1]"
8704,0,3.296,7,6940680863423.446,6,7,kernel,3.047619,"[2, 32, 1]",40,7423,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1527,0,0.761905,1,"[32, 4, 1]"
49152,0,76.576,7,6940680863427.479,33,7,kernel,18.666666,"[2, 14, 7]",126,7425,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,1527,0,2.333333,1,"[256, 1, 1]"
4224,0,12.576,7,6940680865873.126,100,7,kernel,74.666664,"[392, 2, 1]",38,7534,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1527,0,9.333333,1,"[256, 1, 1]"
4224,0,25.792,7,6940680865886.438,100,7,kernel,149.333328,"[392, 4, 1]",38,7536,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1527,0,18.666666,1,"[256, 1, 1]"
98304,0,66.977,7,6940680865918.054,0,7,kernel,3.428571,"[9, 2, 4]",128,7544,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1527,0,0.857143,1,"[128, 1, 1]"
4224,0,2.88,7,6940680865985.799,51,7,kernel,24.380953,"[1, 2, 128]",40,7547,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1527,0,3.047619,1,"[256, 1, 1]"
2064,0,15.552,7,6940680865989.511,51,7,kernel,24.380953,"[128, 1, 1]",32,7560,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1530,0,1.52381,1,"[32, 16, 1]"
0,0,18.88,7,6940680866005.831,100,7,kernel,298.666656,"[6272, 1, 1]",16,7586,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,1544,0,74.666664,1,"[128, 1, 1]"
0,0,66.56,7,6940680866025.511,100,7,kernel,1194.666626,"[196, 1, 64]",40,7595,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,1542,0,149.333328,1,"[256, 1, 1]"
0,0,69.793,7,6940680866092.903,100,7,kernel,298.666656,"[6272, 1, 1]",23,7612,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1547,0,74.666664,1,"[128, 1, 1]"
400,0,119.297,7,6940680866163.528,25,7,kernel,12.190476,"[64, 1, 1]",40,7655,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1551,0,0.761905,1,"[512, 1, 1]"
8704,0,2.752,7,6940680866283.689,3,7,kernel,1.52381,"[2, 16, 1]",40,7846,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1567,0,0.380952,1,"[32, 4, 1]"
49152,0,141.537,7,6940680866287.145,33,7,kernel,74.666664,"[2, 28, 14]",126,7848,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,1567,0,9.333333,1,"[256, 1, 1]"
4224,0,47.52,7,6940680868781.145,100,7,kernel,298.666656,"[1568, 2, 1]",38,7961,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1567,0,37.333332,1,"[256, 1, 1]"
4224,0,48.32,7,6940680868829.337,100,7,kernel,298.666656,"[1568, 2, 1]",38,7963,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,1567,0,37.333332,1,"[256, 1, 1]"
98304,0,122.049,7,6940680868884.153,0,7,kernel,3.428571,"[9, 1, 8]",128,7971,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,1567,0,0.857143,1,"[128, 1, 1]"
4224,0,2.72,7,6940680869006.938,25,7,kernel,12.190476,"[1, 2, 64]",40,7974,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,1567,0,1.52381,1,"[256, 1, 1]"
2064,0,27.616,7,6940680869010.49,25,7,kernel,12.190476,"[64, 1, 1]",32,7987,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1570,0,0.761905,1,"[32, 16, 1]"
0,0,63.168,7,6940680869038.81,100,7,kernel,298.666656,"[6272, 1, 1]",23,8014,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::hardtanh_backward_kernel(at::TensorIterator&, c10::Scalar const&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)",0,1582,0,74.666664,1,"[128, 1, 1]"
400,0,120.992,7,6940680869102.715,25,7,kernel,12.190476,"[64, 1, 1]",40,8057,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,1586,0,0.761905,1,"[512, 1, 1]"
2304,0,72.833,7,6940680873773.848,10,7,kernel,4.666667,"[1, 2, 98]",80,8177,X,"void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",0,1602,0,2.333333,1,"[8, 8, 1]"
2064,0,21.92,7,6940680873847.417,25,7,kernel,12.190476,"[64, 1, 1]",32,8190,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,1605,0,0.761905,1,"[32, 16, 1]"
