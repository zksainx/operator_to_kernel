pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,11.809524,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[512, 1, 1]",6.368,2064,6939565488265.648,1,7,32,25,60823,7,kernel,0,"[1, 62, 1]",0.738095,16387
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.472,0,6939565488560.303,1,7,16,0,60836,7,kernel,0,"[1, 1, 1]",0.011905,16392
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.2,0,6939565489698.156,1,7,16,100,60866,7,kernel,0,"[1954, 1, 1]",23.261906,16914
0,6.857143,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params),0,"[128, 1, 1]",50.528,30720,6939565489858.604,1,7,126,14,60884,7,kernel,0,"[4, 1, 36]",1.714286,16910
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.288,0,6939565489909.836,1,7,44,25,60885,7,kernel,0,"[16, 4, 1]",0.761905,16910
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.616,0,6939565489971.884,1,7,16,100,60903,7,kernel,0,"[1954, 1, 1]",23.261906,16922
0,119.238098,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",46.4,16384,6939565490030.251,1,7,57,67,60917,7,kernel,0,"[4, 313, 1]",14.904762,16918
0,3.809524,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.775,16,6939565490105.164,1,7,32,8,60930,7,kernel,0,"[20, 1, 1]",0.238095,16926
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939565490463.755,1,7,40,5,60983,7,kernel,0,"[50, 1, 1]",0.595238,16951
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565490487.018,1,7,38,0,60985,7,kernel,0,"[2, 1, 1]",0.02381,16951
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.656,16,6939565490637.418,1,7,40,5,61026,7,kernel,0,"[50, 1, 1]",0.595238,16965
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565490649.29,1,7,38,0,61028,7,kernel,0,"[2, 1, 1]",0.02381,16965
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565490822.058,1,7,22,5,61057,7,kernel,0,"[50, 1, 1]",0.595238,16981
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.199,16384,6939565490956.746,1,7,57,25,61083,7,kernel,0,"[16, 2, 4]",1.52381,16993
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.847,0,6939565490972.746,1,7,44,67,61085,7,kernel,0,"[64, 4, 1]",3.047619,16993
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.104,16384,6939565491031.945,1,7,57,51,61102,7,kernel,0,"[16, 16, 1]",3.047619,16997
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939565491095.689,1,7,48,0,61115,7,kernel,0,"[1, 1, 1]",0.011905,17001
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.401,0,6939565491289.16,1,7,22,20,61148,7,kernel,0,"[200, 1, 1]",2.380952,17022
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.168,0,6939565491401.864,1,7,22,20,61162,7,kernel,0,"[200, 1, 1]",2.380952,17027
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.976,16384,6939565491520.232,1,7,57,44,61187,7,kernel,0,"[4, 2, 28]",2.666667,17037
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.2,0,6939565491535.912,1,7,44,25,61189,7,kernel,0,"[16, 4, 1]",0.761905,17037
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.368,16384,6939565491606.568,1,7,57,51,61206,7,kernel,0,"[16, 16, 1]",3.047619,17041
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.912,16,6939565491670.728,1,7,48,0,61219,7,kernel,0,"[4, 1, 1]",0.047619,17045
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565491883.463,1,7,22,5,61242,7,kernel,0,"[50, 1, 1]",0.595238,17064
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939565491992.007,1,7,40,5,61277,7,kernel,0,"[50, 1, 1]",0.595238,17067
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939565492016.839,1,7,38,0,61279,7,kernel,0,"[2, 1, 1]",0.02381,17067
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939565492150.023,1,7,22,5,61308,7,kernel,0,"[50, 1, 1]",0.595238,17083
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.008,25600,6939565492384.262,1,7,80,6,61338,7,kernel,0,"[8, 1, 8]",0.761905,17095
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565492392.134,1,7,44,25,61339,7,kernel,0,"[16, 4, 1]",0.761905,17095
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939565492394.95,1,7,80,6,61361,7,kernel,0,"[64, 1, 1]",0.761905,17099
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.0,16,6939565492443.846,1,7,48,0,61373,7,kernel,0,"[1, 1, 1]",0.011905,17103
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939565495120.288,1,7,22,5,61436,7,kernel,0,"[50, 1, 1]",0.595238,17145
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.552,16,6939565495123.36,1,7,32,10,61450,7,kernel,0,"[25, 1, 1]",0.297619,17146
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565495127.648,1,7,16,0,61463,7,kernel,0,"[2, 1, 1]",0.02381,17154
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.8,53504,6939565495130.464,1,7,236,0,61477,7,kernel,0,"[1, 8, 1]",0.095238,17139
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.087,0,6939565495168.224,1,7,16,10,61535,7,kernel,0,"[100, 1, 1]",1.190476,17204
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565495172.16,1,7,16,10,61560,7,kernel,0,"[100, 1, 1]",1.190476,17214
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939565495176.352,1,7,22,10,61574,7,kernel,0,"[100, 1, 1]",1.190476,17218
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.144,0,6939565495178.656,1,7,16,20,61609,7,kernel,0,"[200, 1, 1]",2.380952,17239
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.176,16384,6939565495181.632,1,7,57,25,61635,7,kernel,0,"[4, 2, 16]",1.52381,17250
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.368,0,6939565495192.512,1,7,44,25,61637,7,kernel,0,"[16, 4, 1]",0.761905,17250
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.193,16384,6939565495195.615,1,7,57,25,61654,7,kernel,0,"[16, 8, 1]",1.52381,17254
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.839,16,6939565495204.672,1,7,48,0,61667,7,kernel,0,"[2, 1, 1]",0.02381,17258
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.912,25600,6939565495213.248,1,7,80,6,61705,7,kernel,0,"[8, 1, 8]",0.761905,17278
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.017,0,6939565495220.895,1,7,44,25,61706,7,kernel,0,"[16, 4, 1]",0.761905,17278
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.111,25600,6939565495223.712,1,7,80,6,61728,7,kernel,0,"[64, 1, 1]",0.761905,17282
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.856,16,6939565495230.655,1,7,48,0,61740,7,kernel,0,"[1, 1, 1]",0.011905,17286
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.92,0,6939565495237.279,1,7,22,5,61755,7,kernel,0,"[50, 1, 1]",0.595238,17297
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.017,0,6939565495239.903,1,7,30,0,61772,7,kernel,0,"[2, 2, 1]",0.047619,17300
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",8.544,0,6939565495242.687,1,7,30,100,61791,7,kernel,0,"[1024, 2, 1]",24.380953,17307
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.712,16,6939565495251.936,1,7,40,5,61828,7,kernel,0,"[50, 1, 1]",0.595238,17314
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565495256.351,1,7,38,0,61830,7,kernel,0,"[2, 1, 1]",0.02381,17314
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.791,0,6939565495261.6,1,7,22,5,61859,7,kernel,0,"[50, 1, 1]",0.595238,17330
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.264,25600,6939565497622.906,1,7,80,6,61889,7,kernel,0,"[8, 1, 8]",0.761905,17342
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939565497630.874,1,7,44,25,61890,7,kernel,0,"[16, 4, 1]",0.761905,17342
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565497633.978,1,7,80,6,61912,7,kernel,0,"[64, 1, 1]",0.761905,17346
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939565497640.794,1,7,48,0,61924,7,kernel,0,"[1, 1, 1]",0.011905,17350
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565497649.498,1,7,22,5,61987,7,kernel,0,"[50, 1, 1]",0.595238,17392
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565497651.93,1,7,32,10,62001,7,kernel,0,"[25, 1, 1]",0.297619,17393
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565497656.058,1,7,16,0,62014,7,kernel,0,"[2, 1, 1]",0.02381,17401
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.12,53504,6939565497658.778,1,7,236,0,62028,7,kernel,0,"[1, 8, 1]",0.095238,17386
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565497696.794,1,7,16,15,62086,7,kernel,0,"[150, 1, 1]",1.785714,17451
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565497700.89,1,7,16,15,62111,7,kernel,0,"[150, 1, 1]",1.785714,17461
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565497705.018,1,7,22,15,62125,7,kernel,0,"[150, 1, 1]",1.785714,17465
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565497707.482,1,7,16,15,62145,7,kernel,0,"[150, 1, 1]",1.785714,17472
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565497711.578,1,7,22,15,62159,7,kernel,0,"[150, 1, 1]",1.785714,17476
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565497714.106,1,7,16,30,62194,7,kernel,0,"[300, 1, 1]",3.571429,17497
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.768,16384,6939565497717.21,1,7,57,38,62220,7,kernel,0,"[4, 2, 24]",2.285714,17508
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.968,0,6939565497730.81,1,7,44,25,62222,7,kernel,0,"[16, 4, 1]",0.761905,17508
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.199,16384,6939565497735.482,1,7,57,38,62239,7,kernel,0,"[16, 12, 1]",2.285714,17512
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939565497747.482,1,7,48,0,62252,7,kernel,0,"[3, 1, 1]",0.035714,17516
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565497756.122,1,7,22,5,62275,7,kernel,0,"[50, 1, 1]",0.595238,17535
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939565497758.714,1,7,40,5,62310,7,kernel,0,"[50, 1, 1]",0.595238,17538
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.544,0,6939565497762.266,1,7,38,0,62312,7,kernel,0,"[2, 1, 1]",0.02381,17538
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565497767.641,1,7,22,5,62341,7,kernel,0,"[50, 1, 1]",0.595238,17554
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.424,16384,6939565497770.106,1,7,57,25,62367,7,kernel,0,"[16, 2, 4]",1.52381,17566
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939565497786.362,1,7,44,67,62369,7,kernel,0,"[64, 4, 1]",3.047619,17566
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.56,16384,6939565497789.946,1,7,57,51,62386,7,kernel,0,"[16, 16, 1]",3.047619,17570
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.697,16,6939565497805.273,1,7,48,0,62399,7,kernel,0,"[1, 1, 1]",0.011905,17574
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939565500108.244,1,7,22,20,62432,7,kernel,0,"[200, 1, 1]",2.380952,17595
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.488,0,6939565500111.988,1,7,22,20,62446,7,kernel,0,"[200, 1, 1]",2.380952,17600
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.056,16384,6939565500116.276,1,7,57,44,62471,7,kernel,0,"[4, 2, 28]",2.666667,17610
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.744,0,6939565500134.164,1,7,44,25,62473,7,kernel,0,"[16, 4, 1]",0.761905,17610
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.072,16384,6939565500139.028,1,7,57,51,62490,7,kernel,0,"[16, 16, 1]",3.047619,17614
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.616,16,6939565500154.836,1,7,48,0,62503,7,kernel,0,"[4, 1, 1]",0.047619,17618
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565500163.252,1,7,22,5,62526,7,kernel,0,"[50, 1, 1]",0.595238,17637
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.752,16,6939565500165.716,1,7,40,5,62561,7,kernel,0,"[50, 1, 1]",0.595238,17640
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939565500169.3,1,7,38,0,62563,7,kernel,0,"[2, 1, 1]",0.02381,17640
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565500174.548,1,7,22,5,62592,7,kernel,0,"[50, 1, 1]",0.595238,17656
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.976,25600,6939565500177.044,1,7,80,6,62622,7,kernel,0,"[8, 1, 8]",0.761905,17668
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.952,0,6939565500184.788,1,7,44,25,62623,7,kernel,0,"[16, 4, 1]",0.761905,17668
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565500187.444,1,7,80,6,62645,7,kernel,0,"[64, 1, 1]",0.761905,17672
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.656,16,6939565500194.196,1,7,48,0,62657,7,kernel,0,"[1, 1, 1]",0.011905,17676
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565500201.684,1,7,22,5,62720,7,kernel,0,"[50, 1, 1]",0.595238,17718
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.424,16,6939565500203.892,1,7,32,10,62734,7,kernel,0,"[25, 1, 1]",0.297619,17719
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565500208.148,1,7,16,0,62747,7,kernel,0,"[2, 1, 1]",0.02381,17727
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.992,53504,6939565500210.964,1,7,236,0,62761,7,kernel,0,"[1, 8, 1]",0.095238,17712
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.928,0,6939565500249.012,1,7,16,10,62819,7,kernel,0,"[100, 1, 1]",1.190476,17777
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565500252.788,1,7,16,10,62844,7,kernel,0,"[100, 1, 1]",1.190476,17787
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939565500256.884,1,7,22,10,62858,7,kernel,0,"[100, 1, 1]",1.190476,17791
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565500259.22,1,7,16,20,62893,7,kernel,0,"[200, 1, 1]",2.380952,17812
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.088,16384,6939565500262.164,1,7,57,25,62919,7,kernel,0,"[4, 2, 16]",1.52381,17823
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.656,0,6939565500272.084,1,7,44,25,62921,7,kernel,0,"[16, 4, 1]",0.761905,17823
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.192,16384,6939565500275.476,1,7,57,25,62938,7,kernel,0,"[16, 8, 1]",1.52381,17827
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.76,16,6939565502672.782,1,7,48,0,62951,7,kernel,0,"[2, 1, 1]",0.02381,17831
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565502683.31,1,7,22,5,62970,7,kernel,0,"[50, 1, 1]",0.595238,17842
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.976,25600,6939565502686.126,1,7,80,6,63002,7,kernel,0,"[8, 1, 8]",0.761905,17852
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.08,0,6939565502693.806,1,7,44,25,63003,7,kernel,0,"[16, 4, 1]",0.761905,17852
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939565502696.654,1,7,80,6,63025,7,kernel,0,"[64, 1, 1]",0.761905,17856
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.144,16,6939565502703.534,1,7,48,0,63037,7,kernel,0,"[1, 1, 1]",0.011905,17860
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.984,0,6939565502710.446,1,7,22,5,63052,7,kernel,0,"[50, 1, 1]",0.595238,17871
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.016,0,6939565502713.262,1,7,30,0,63069,7,kernel,0,"[2, 2, 1]",0.047619,17874
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",9.984,0,6939565502716.014,1,7,30,100,63088,7,kernel,0,"[1024, 2, 1]",24.380953,17881
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.2,16,6939565502726.766,1,7,40,5,63125,7,kernel,0,"[50, 1, 1]",0.595238,17888
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.544,0,6939565502730.83,1,7,38,0,63127,7,kernel,0,"[2, 1, 1]",0.02381,17888
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565502736.238,1,7,22,5,63156,7,kernel,0,"[50, 1, 1]",0.595238,17904
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.56,25600,6939565502738.862,1,7,80,6,63186,7,kernel,0,"[8, 1, 8]",0.761905,17916
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565502746.254,1,7,44,25,63187,7,kernel,0,"[16, 4, 1]",0.761905,17916
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.76,25600,6939565502749.038,1,7,80,6,63209,7,kernel,0,"[64, 1, 1]",0.761905,17920
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565502755.662,1,7,48,0,63221,7,kernel,0,"[1, 1, 1]",0.011905,17924
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565502764.078,1,7,22,5,63284,7,kernel,0,"[50, 1, 1]",0.595238,17966
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.328,16,6939565502766.286,1,7,32,10,63298,7,kernel,0,"[25, 1, 1]",0.297619,17967
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.048,0,6939565502770.382,1,7,16,0,63311,7,kernel,0,"[2, 1, 1]",0.02381,17975
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.8,53504,6939565502773.198,1,7,236,0,63325,7,kernel,0,"[1, 8, 1]",0.095238,17960
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565502811.086,1,7,16,15,63383,7,kernel,0,"[150, 1, 1]",1.785714,18025
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565502815.054,1,7,16,15,63408,7,kernel,0,"[150, 1, 1]",1.785714,18035
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565502819.566,1,7,22,15,63422,7,kernel,0,"[150, 1, 1]",1.785714,18039
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565502822.19,1,7,16,15,63442,7,kernel,0,"[150, 1, 1]",1.785714,18046
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565502826.286,1,7,22,15,63456,7,kernel,0,"[150, 1, 1]",1.785714,18050
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565502828.814,1,7,16,30,63491,7,kernel,0,"[300, 1, 1]",3.571429,18071
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.768,16384,6939565502831.918,1,7,57,38,63517,7,kernel,0,"[4, 2, 24]",2.285714,18082
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.064,0,6939565502845.422,1,7,44,25,63519,7,kernel,0,"[16, 4, 1]",0.761905,18082
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.424,16384,6939565502850.19,1,7,57,38,63536,7,kernel,0,"[16, 12, 1]",2.285714,18086
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565502862.35,1,7,48,0,63549,7,kernel,0,"[3, 1, 1]",0.035714,18090
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565502870.83,1,7,22,5,63572,7,kernel,0,"[50, 1, 1]",0.595238,18109
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.912,16,6939565502873.262,1,7,40,5,63607,7,kernel,0,"[50, 1, 1]",0.595238,18112
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565502876.878,1,7,38,0,63609,7,kernel,0,"[2, 1, 1]",0.02381,18112
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939565505212.296,1,7,22,5,63638,7,kernel,0,"[50, 1, 1]",0.595238,18128
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.503,16384,6939565505215.401,1,7,57,25,63664,7,kernel,0,"[16, 2, 4]",1.52381,18140
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939565505233.672,1,7,44,67,63666,7,kernel,0,"[64, 4, 1]",3.047619,18140
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.464,16384,6939565505237.448,1,7,57,51,63683,7,kernel,0,"[16, 16, 1]",3.047619,18144
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939565505252.68,1,7,48,0,63696,7,kernel,0,"[1, 1, 1]",0.011905,18148
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939565505261.416,1,7,22,20,63729,7,kernel,0,"[200, 1, 1]",2.380952,18169
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939565505264.52,1,7,22,20,63743,7,kernel,0,"[200, 1, 1]",2.380952,18174
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.456,16384,6939565505268.296,1,7,57,44,63768,7,kernel,0,"[4, 2, 28]",2.666667,18184
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.616,0,6939565505284.584,1,7,44,25,63770,7,kernel,0,"[16, 4, 1]",0.761905,18184
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.728,16384,6939565505289.0,1,7,57,51,63787,7,kernel,0,"[16, 16, 1]",3.047619,18188
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.944,16,6939565505303.56,1,7,48,0,63800,7,kernel,0,"[4, 1, 1]",0.047619,18192
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565505311.336,1,7,22,5,63823,7,kernel,0,"[50, 1, 1]",0.595238,18211
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939565505313.96,1,7,40,5,63858,7,kernel,0,"[50, 1, 1]",0.595238,18214
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565505317.544,1,7,38,0,63860,7,kernel,0,"[2, 1, 1]",0.02381,18214
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565505322.728,1,7,22,5,63889,7,kernel,0,"[50, 1, 1]",0.595238,18230
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.912,25600,6939565505325.224,1,7,80,6,63919,7,kernel,0,"[8, 1, 8]",0.761905,18242
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.952,0,6939565505332.968,1,7,44,25,63920,7,kernel,0,"[16, 4, 1]",0.761905,18242
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939565505335.624,1,7,80,6,63942,7,kernel,0,"[64, 1, 1]",0.761905,18246
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.912,16,6939565505342.504,1,7,48,0,63954,7,kernel,0,"[1, 1, 1]",0.011905,18250
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565505350.28,1,7,22,5,64017,7,kernel,0,"[50, 1, 1]",0.595238,18292
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565505352.488,1,7,32,10,64031,7,kernel,0,"[25, 1, 1]",0.297619,18293
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565505356.616,1,7,16,0,64044,7,kernel,0,"[2, 1, 1]",0.02381,18301
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.736,53504,6939565505359.4,1,7,236,0,64058,7,kernel,0,"[1, 8, 1]",0.095238,18286
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.928,0,6939565505397.224,1,7,16,10,64116,7,kernel,0,"[100, 1, 1]",1.190476,18351
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565505401.032,1,7,16,10,64141,7,kernel,0,"[100, 1, 1]",1.190476,18361
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565505405.128,1,7,22,10,64155,7,kernel,0,"[100, 1, 1]",1.190476,18365
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565505407.464,1,7,16,20,64190,7,kernel,0,"[200, 1, 1]",2.380952,18386
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.152,16384,6939565505410.408,1,7,57,25,64216,7,kernel,0,"[4, 2, 16]",1.52381,18397
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.88,0,6939565505420.776,1,7,44,25,64218,7,kernel,0,"[16, 4, 1]",0.761905,18397
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.096,16384,6939565505424.488,1,7,57,25,64235,7,kernel,0,"[16, 8, 1]",1.52381,18401
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939565505433.384,1,7,48,0,64248,7,kernel,0,"[2, 1, 1]",0.02381,18405
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565505441.96,1,7,22,5,64263,7,kernel,0,"[50, 1, 1]",0.595238,18416
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939565505444.616,1,7,80,6,64295,7,kernel,0,"[8, 1, 8]",0.761905,18426
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565505452.552,1,7,44,25,64296,7,kernel,0,"[16, 4, 1]",0.761905,18426
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.271,25600,6939565507797.475,1,7,80,6,64318,7,kernel,0,"[64, 1, 1]",0.761905,18430
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.065,16,6939565507804.578,1,7,48,0,64330,7,kernel,0,"[1, 1, 1]",0.011905,18434
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939565507813.442,1,7,22,5,64345,7,kernel,0,"[50, 1, 1]",0.595238,18445
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.272,0,6939565507816.546,1,7,30,0,64362,7,kernel,0,"[2, 2, 1]",0.047619,18448
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.753,0,6939565507819.65,1,7,30,100,64381,7,kernel,0,"[1024, 2, 1]",24.380953,18455
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.2,16,6939565507831.106,1,7,40,5,64418,7,kernel,0,"[50, 1, 1]",0.595238,18462
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.608,0,6939565507835.042,1,7,38,0,64420,7,kernel,0,"[2, 1, 1]",0.02381,18462
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.761,0,6939565507840.386,1,7,22,5,64449,7,kernel,0,"[50, 1, 1]",0.595238,18478
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.296,25600,6939565507842.85,1,7,80,6,64479,7,kernel,0,"[8, 1, 8]",0.761905,18490
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565507850.882,1,7,44,25,64480,7,kernel,0,"[16, 4, 1]",0.761905,18490
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.856,25600,6939565507853.634,1,7,80,6,64502,7,kernel,0,"[64, 1, 1]",0.761905,18494
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.976,16,6939565507860.322,1,7,48,0,64514,7,kernel,0,"[1, 1, 1]",0.011905,18498
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565507868.066,1,7,22,5,64577,7,kernel,0,"[50, 1, 1]",0.595238,18540
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565507870.274,1,7,32,10,64591,7,kernel,0,"[25, 1, 1]",0.297619,18541
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565507874.37,1,7,16,0,64604,7,kernel,0,"[2, 1, 1]",0.02381,18549
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939565507877.186,1,7,236,0,64618,7,kernel,0,"[1, 8, 1]",0.095238,18534
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565507914.818,1,7,16,15,64676,7,kernel,0,"[150, 1, 1]",1.785714,18599
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565507919.01,1,7,16,15,64701,7,kernel,0,"[150, 1, 1]",1.785714,18609
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565507923.138,1,7,22,15,64715,7,kernel,0,"[150, 1, 1]",1.785714,18613
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565507925.634,1,7,16,15,64735,7,kernel,0,"[150, 1, 1]",1.785714,18620
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565507929.698,1,7,22,15,64749,7,kernel,0,"[150, 1, 1]",1.785714,18624
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.272,0,6939565507932.162,1,7,16,30,64784,7,kernel,0,"[300, 1, 1]",3.571429,18645
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.224,16384,6939565507935.298,1,7,57,38,64810,7,kernel,0,"[4, 2, 24]",2.285714,18656
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.616,0,6939565507948.29,1,7,44,25,64812,7,kernel,0,"[16, 4, 1]",0.761905,18656
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.2,16384,6939565507952.674,1,7,57,38,64829,7,kernel,0,"[16, 12, 1]",2.285714,18660
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565507964.674,1,7,48,0,64842,7,kernel,0,"[3, 1, 1]",0.035714,18664
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565507973.282,1,7,22,5,64865,7,kernel,0,"[50, 1, 1]",0.595238,18683
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939565507975.906,1,7,40,5,64900,7,kernel,0,"[50, 1, 1]",0.595238,18686
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565507979.426,1,7,38,0,64902,7,kernel,0,"[2, 1, 1]",0.02381,18686
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565507984.61,1,7,22,5,64931,7,kernel,0,"[50, 1, 1]",0.595238,18702
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.648,16384,6939565507987.074,1,7,57,25,64957,7,kernel,0,"[16, 2, 4]",1.52381,18714
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939565508003.586,1,7,44,67,64959,7,kernel,0,"[64, 4, 1]",3.047619,18714
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.624,16384,6939565508007.17,1,7,57,51,64976,7,kernel,0,"[16, 16, 1]",3.047619,18718
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.209,16,6939565510318.908,1,7,48,0,64989,7,kernel,0,"[1, 1, 1]",0.011905,18722
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.88,0,6939565510329.853,1,7,22,20,65022,7,kernel,0,"[200, 1, 1]",2.380952,18743
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.881,0,6939565510333.468,1,7,22,20,65036,7,kernel,0,"[200, 1, 1]",2.380952,18748
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.024,16384,6939565510337.116,1,7,57,44,65061,7,kernel,0,"[4, 2, 28]",2.666667,18758
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.808,0,6939565510354.941,1,7,44,25,65063,7,kernel,0,"[16, 4, 1]",0.761905,18758
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.952,16384,6939565510359.516,1,7,57,51,65080,7,kernel,0,"[16, 16, 1]",3.047619,18762
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.072,16,6939565510374.236,1,7,48,0,65093,7,kernel,0,"[4, 1, 1]",0.047619,18766
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565510382.044,1,7,22,5,65116,7,kernel,0,"[50, 1, 1]",0.595238,18785
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.847,16,6939565510384.669,1,7,40,5,65151,7,kernel,0,"[50, 1, 1]",0.595238,18788
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565510388.252,1,7,38,0,65153,7,kernel,0,"[2, 1, 1]",0.02381,18788
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.599,0,6939565510393.437,1,7,22,5,65182,7,kernel,0,"[50, 1, 1]",0.595238,18804
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939565510395.74,1,7,80,6,65212,7,kernel,0,"[8, 1, 8]",0.761905,18816
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.017,0,6939565510403.58,1,7,44,25,65213,7,kernel,0,"[16, 4, 1]",0.761905,18816
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.049,25600,6939565510406.396,1,7,80,6,65235,7,kernel,0,"[64, 1, 1]",0.761905,18820
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.464,16,6939565510413.148,1,7,48,0,65247,7,kernel,0,"[1, 1, 1]",0.011905,18824
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565510420.316,1,7,22,5,65310,7,kernel,0,"[50, 1, 1]",0.595238,18866
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.424,16,6939565510422.525,1,7,32,10,65324,7,kernel,0,"[25, 1, 1]",0.297619,18867
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565510426.716,1,7,16,0,65337,7,kernel,0,"[2, 1, 1]",0.02381,18875
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.512,53504,6939565510429.532,1,7,236,0,65351,7,kernel,0,"[1, 8, 1]",0.095238,18860
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565510467.068,1,7,16,10,65409,7,kernel,0,"[100, 1, 1]",1.190476,18925
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565510470.844,1,7,16,10,65434,7,kernel,0,"[100, 1, 1]",1.190476,18935
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565510474.94,1,7,22,10,65448,7,kernel,0,"[100, 1, 1]",1.190476,18939
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565510477.276,1,7,16,20,65483,7,kernel,0,"[200, 1, 1]",2.380952,18960
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.12,16384,6939565510480.252,1,7,57,25,65509,7,kernel,0,"[4, 2, 16]",1.52381,18971
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.04,0,6939565510490.108,1,7,44,25,65511,7,kernel,0,"[16, 4, 1]",0.761905,18971
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.16,16384,6939565510493.884,1,7,57,25,65528,7,kernel,0,"[16, 8, 1]",1.52381,18975
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939565510502.812,1,7,48,0,65541,7,kernel,0,"[2, 1, 1]",0.02381,18979
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565510511.388,1,7,22,5,65556,7,kernel,0,"[50, 1, 1]",0.595238,18990
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939565510513.884,1,7,80,6,65588,7,kernel,0,"[8, 1, 8]",0.761905,19000
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939565510521.724,1,7,44,25,65589,7,kernel,0,"[16, 4, 1]",0.761905,19000
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565510524.54,1,7,80,6,65611,7,kernel,0,"[64, 1, 1]",0.761905,19004
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.176,16,6939565510531.292,1,7,48,0,65623,7,kernel,0,"[1, 1, 1]",0.011905,19008
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565512894.647,1,7,22,5,65638,7,kernel,0,"[50, 1, 1]",0.595238,19019
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.335,0,6939565512897.591,1,7,30,0,65655,7,kernel,0,"[2, 2, 1]",0.047619,19022
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.455,0,6939565512900.663,1,7,30,100,65674,7,kernel,0,"[1024, 2, 1]",24.380953,19029
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.944,16,6939565512912.855,1,7,40,5,65711,7,kernel,0,"[50, 1, 1]",0.595238,19036
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565512916.598,1,7,38,0,65713,7,kernel,0,"[2, 1, 1]",0.02381,19036
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.759,0,6939565512921.847,1,7,22,5,65742,7,kernel,0,"[50, 1, 1]",0.595238,19052
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.361,25600,6939565512924.31,1,7,80,6,65772,7,kernel,0,"[8, 1, 8]",0.761905,19064
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.049,0,6939565512932.374,1,7,44,25,65773,7,kernel,0,"[16, 4, 1]",0.761905,19064
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.081,25600,6939565512935.158,1,7,80,6,65795,7,kernel,0,"[64, 1, 1]",0.761905,19068
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.809,16,6939565512942.07,1,7,48,0,65807,7,kernel,0,"[1, 1, 1]",0.011905,19072
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565512950.614,1,7,22,5,65870,7,kernel,0,"[50, 1, 1]",0.595238,19114
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.359,16,6939565512952.823,1,7,32,10,65884,7,kernel,0,"[25, 1, 1]",0.297619,19115
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565512956.95,1,7,16,0,65897,7,kernel,0,"[2, 1, 1]",0.02381,19123
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.673,53504,6939565512959.766,1,7,236,0,65911,7,kernel,0,"[1, 8, 1]",0.095238,19108
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565512997.59,1,7,16,15,65969,7,kernel,0,"[150, 1, 1]",1.785714,19173
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.215,0,6939565513001.783,1,7,16,15,65994,7,kernel,0,"[150, 1, 1]",1.785714,19183
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565513005.847,1,7,22,15,66008,7,kernel,0,"[150, 1, 1]",1.785714,19187
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565513008.31,1,7,16,15,66028,7,kernel,0,"[150, 1, 1]",1.785714,19194
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565513012.438,1,7,22,15,66042,7,kernel,0,"[150, 1, 1]",1.785714,19198
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565513014.934,1,7,16,30,66077,7,kernel,0,"[300, 1, 1]",3.571429,19219
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.767,16384,6939565513018.039,1,7,57,38,66103,7,kernel,0,"[4, 2, 24]",2.285714,19230
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.872,0,6939565513031.542,1,7,44,25,66105,7,kernel,0,"[16, 4, 1]",0.761905,19230
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.392,16384,6939565513036.118,1,7,57,38,66122,7,kernel,0,"[16, 12, 1]",2.285714,19234
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939565513048.278,1,7,48,0,66135,7,kernel,0,"[3, 1, 1]",0.035714,19238
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565513056.726,1,7,22,5,66158,7,kernel,0,"[50, 1, 1]",0.595238,19257
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939565513059.35,1,7,40,5,66193,7,kernel,0,"[50, 1, 1]",0.595238,19260
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939565513062.87,1,7,38,0,66195,7,kernel,0,"[2, 1, 1]",0.02381,19260
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565513068.118,1,7,22,5,66224,7,kernel,0,"[50, 1, 1]",0.595238,19276
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.648,16384,6939565513070.55,1,7,57,25,66250,7,kernel,0,"[16, 2, 4]",1.52381,19288
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.88,0,6939565513086.966,1,7,44,67,66252,7,kernel,0,"[64, 4, 1]",3.047619,19288
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.208,16384,6939565513090.614,1,7,57,51,66269,7,kernel,0,"[16, 16, 1]",3.047619,19292
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.728,16,6939565513105.558,1,7,48,0,66282,7,kernel,0,"[1, 1, 1]",0.011905,19296
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.464,0,6939565513112.054,1,7,22,20,66315,7,kernel,0,"[200, 1, 1]",2.380952,19317
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.36,0,6939565515464.177,1,7,22,20,66329,7,kernel,0,"[200, 1, 1]",2.380952,19322
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.736,16384,6939565515468.305,1,7,57,44,66354,7,kernel,0,"[4, 2, 28]",2.666667,19332
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.647,0,6939565515485.777,1,7,44,25,66356,7,kernel,0,"[16, 4, 1]",0.761905,19332
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.431,16384,6939565515490.161,1,7,57,51,66373,7,kernel,0,"[16, 16, 1]",3.047619,19336
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.521,16,6939565515505.296,1,7,48,0,66386,7,kernel,0,"[4, 1, 1]",0.047619,19340
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.889,0,6939565515513.584,1,7,22,5,66409,7,kernel,0,"[50, 1, 1]",0.595238,19359
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.817,16,6939565515516.208,1,7,40,5,66444,7,kernel,0,"[50, 1, 1]",0.595238,19362
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565515519.824,1,7,38,0,66446,7,kernel,0,"[2, 1, 1]",0.02381,19362
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.695,0,6939565515525.009,1,7,22,5,66475,7,kernel,0,"[50, 1, 1]",0.595238,19378
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.88,25600,6939565515527.472,1,7,80,6,66505,7,kernel,0,"[8, 1, 8]",0.761905,19390
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.951,0,6939565515535.153,1,7,44,25,66506,7,kernel,0,"[16, 4, 1]",0.761905,19390
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.113,25600,6939565515537.936,1,7,80,6,66528,7,kernel,0,"[64, 1, 1]",0.761905,19394
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.559,16,6939565515544.913,1,7,48,0,66540,7,kernel,0,"[1, 1, 1]",0.011905,19398
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.409,0,6939565515552.272,1,7,22,5,66603,7,kernel,0,"[50, 1, 1]",0.595238,19440
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565515554.48,1,7,32,10,66617,7,kernel,0,"[25, 1, 1]",0.297619,19441
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.983,0,6939565515558.609,1,7,16,0,66630,7,kernel,0,"[2, 1, 1]",0.02381,19449
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939565515561.425,1,7,236,0,66644,7,kernel,0,"[1, 8, 1]",0.095238,19434
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.927,0,6939565515599.057,1,7,16,10,66702,7,kernel,0,"[100, 1, 1]",1.190476,19499
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565515602.864,1,7,16,10,66727,7,kernel,0,"[100, 1, 1]",1.190476,19509
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.535,0,6939565515606.961,1,7,22,10,66741,7,kernel,0,"[100, 1, 1]",1.190476,19513
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.144,0,6939565515609.297,1,7,16,20,66776,7,kernel,0,"[200, 1, 1]",2.380952,19534
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.184,16384,6939565515612.24,1,7,57,25,66802,7,kernel,0,"[4, 2, 16]",1.52381,19545
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939565515622.288,1,7,44,25,66804,7,kernel,0,"[16, 4, 1]",0.761905,19545
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.096,16384,6939565515626.064,1,7,57,25,66821,7,kernel,0,"[16, 8, 1]",1.52381,19549
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565515634.992,1,7,48,0,66834,7,kernel,0,"[2, 1, 1]",0.02381,19553
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939565515643.6,1,7,22,5,66849,7,kernel,0,"[50, 1, 1]",0.595238,19564
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.976,25600,6939565515646.256,1,7,80,6,66881,7,kernel,0,"[8, 1, 8]",0.761905,19574
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939565515654.032,1,7,44,25,66882,7,kernel,0,"[16, 4, 1]",0.761905,19574
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.984,25600,6939565515656.816,1,7,80,6,66904,7,kernel,0,"[64, 1, 1]",0.761905,19578
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.048,16,6939565515663.6,1,7,48,0,66916,7,kernel,0,"[1, 1, 1]",0.011905,19582
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939565515670.416,1,7,22,5,66931,7,kernel,0,"[50, 1, 1]",0.595238,19593
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",1.984,0,6939565515673.008,1,7,30,0,66948,7,kernel,0,"[2, 2, 1]",0.047619,19596
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",8.672,0,6939565515675.792,1,7,30,100,66967,7,kernel,0,"[1024, 2, 1]",24.380953,19603
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939565515685.232,1,7,40,5,67004,7,kernel,0,"[50, 1, 1]",0.595238,19610
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.736,0,6939565515689.008,1,7,38,0,67006,7,kernel,0,"[2, 1, 1]",0.02381,19610
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565518022.763,1,7,22,5,67035,7,kernel,0,"[50, 1, 1]",0.595238,19626
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.296,25600,6939565518025.643,1,7,80,6,67065,7,kernel,0,"[8, 1, 8]",0.761905,19638
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565518033.643,1,7,44,25,67066,7,kernel,0,"[16, 4, 1]",0.761905,19638
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565518036.715,1,7,80,6,67088,7,kernel,0,"[64, 1, 1]",0.761905,19642
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.159,16,6939565518043.467,1,7,48,0,67100,7,kernel,0,"[1, 1, 1]",0.011905,19646
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565518052.363,1,7,22,5,67163,7,kernel,0,"[50, 1, 1]",0.595238,19688
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.296,16,6939565518054.571,1,7,32,10,67177,7,kernel,0,"[25, 1, 1]",0.297619,19689
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.017,0,6939565518058.666,1,7,16,0,67190,7,kernel,0,"[2, 1, 1]",0.02381,19697
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.959,53504,6939565518061.483,1,7,236,0,67204,7,kernel,0,"[1, 8, 1]",0.095238,19682
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565518099.403,1,7,16,15,67262,7,kernel,0,"[150, 1, 1]",1.785714,19747
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565518103.755,1,7,16,15,67287,7,kernel,0,"[150, 1, 1]",1.785714,19757
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565518107.85,1,7,22,15,67301,7,kernel,0,"[150, 1, 1]",1.785714,19761
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.215,0,6939565518110.315,1,7,16,15,67321,7,kernel,0,"[150, 1, 1]",1.785714,19768
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565518114.314,1,7,22,15,67335,7,kernel,0,"[150, 1, 1]",1.785714,19772
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.241,0,6939565518116.81,1,7,16,30,67370,7,kernel,0,"[300, 1, 1]",3.571429,19793
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.735,16384,6939565518119.755,1,7,57,38,67396,7,kernel,0,"[4, 2, 24]",2.285714,19804
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.679,0,6939565518133.227,1,7,44,25,67398,7,kernel,0,"[16, 4, 1]",0.761905,19804
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.615,16384,6939565518137.675,1,7,57,38,67415,7,kernel,0,"[16, 12, 1]",2.285714,19808
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565518150.123,1,7,48,0,67428,7,kernel,0,"[3, 1, 1]",0.035714,19812
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565518158.635,1,7,22,5,67451,7,kernel,0,"[50, 1, 1]",0.595238,19831
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.881,16,6939565518161.098,1,7,40,5,67486,7,kernel,0,"[50, 1, 1]",0.595238,19834
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.417,0,6939565518164.714,1,7,38,0,67488,7,kernel,0,"[2, 1, 1]",0.02381,19834
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.601,0,6939565518169.898,1,7,22,5,67517,7,kernel,0,"[50, 1, 1]",0.595238,19850
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.839,16384,6939565518172.363,1,7,57,25,67543,7,kernel,0,"[16, 2, 4]",1.52381,19862
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.849,0,6939565518188.938,1,7,44,67,67545,7,kernel,0,"[64, 4, 1]",3.047619,19862
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.88,16384,6939565518192.586,1,7,57,51,67562,7,kernel,0,"[16, 16, 1]",3.047619,19866
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.728,16,6939565518208.202,1,7,48,0,67575,7,kernel,0,"[1, 1, 1]",0.011905,19870
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939565518214.698,1,7,22,20,67608,7,kernel,0,"[200, 1, 1]",2.380952,19891
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.008,0,6939565518217.802,1,7,22,20,67622,7,kernel,0,"[200, 1, 1]",2.380952,19896
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.104,16384,6939565518221.546,1,7,57,44,67647,7,kernel,0,"[4, 2, 28]",2.666667,19906
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.616,0,6939565518237.354,1,7,44,25,67649,7,kernel,0,"[16, 4, 1]",0.761905,19906
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.92,16384,6939565518241.77,1,7,57,51,67666,7,kernel,0,"[16, 16, 1]",3.047619,19910
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.88,16,6939565518256.426,1,7,48,0,67679,7,kernel,0,"[4, 1, 1]",0.047619,19914
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565520615.845,1,7,22,5,67702,7,kernel,0,"[50, 1, 1]",0.595238,19933
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939565520618.757,1,7,40,5,67737,7,kernel,0,"[50, 1, 1]",0.595238,19936
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565520622.693,1,7,38,0,67739,7,kernel,0,"[2, 1, 1]",0.02381,19936
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565520627.877,1,7,22,5,67768,7,kernel,0,"[50, 1, 1]",0.595238,19952
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.296,25600,6939565520630.501,1,7,80,6,67798,7,kernel,0,"[8, 1, 8]",0.761905,19964
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565520638.533,1,7,44,25,67799,7,kernel,0,"[16, 4, 1]",0.761905,19964
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.015,25600,6939565520641.349,1,7,80,6,67821,7,kernel,0,"[64, 1, 1]",0.761905,19968
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939565520648.133,1,7,48,0,67833,7,kernel,0,"[1, 1, 1]",0.011905,19972
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565520656.901,1,7,22,5,67896,7,kernel,0,"[50, 1, 1]",0.595238,20014
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.393,16,6939565520659.108,1,7,32,10,67910,7,kernel,0,"[25, 1, 1]",0.297619,20015
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.985,0,6939565520663.204,1,7,16,0,67923,7,kernel,0,"[2, 1, 1]",0.02381,20023
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.672,53504,6939565520666.021,1,7,236,0,67937,7,kernel,0,"[1, 8, 1]",0.095238,20008
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.088,0,6939565520703.685,1,7,16,10,67995,7,kernel,0,"[100, 1, 1]",1.190476,20073
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.153,0,6939565520707.652,1,7,16,10,68020,7,kernel,0,"[100, 1, 1]",1.190476,20083
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.569,0,6939565520711.748,1,7,22,10,68034,7,kernel,0,"[100, 1, 1]",1.190476,20087
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.144,0,6939565520714.052,1,7,16,20,68069,7,kernel,0,"[200, 1, 1]",2.380952,20108
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.376,16384,6939565520716.997,1,7,57,25,68095,7,kernel,0,"[4, 2, 16]",1.52381,20119
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.817,0,6939565520727.172,1,7,44,25,68097,7,kernel,0,"[16, 4, 1]",0.761905,20119
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.065,16384,6939565520730.756,1,7,57,25,68114,7,kernel,0,"[16, 8, 1]",1.52381,20123
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.775,16,6939565520739.653,1,7,48,0,68127,7,kernel,0,"[2, 1, 1]",0.02381,20127
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.855,0,6939565520748.197,1,7,22,5,68142,7,kernel,0,"[50, 1, 1]",0.595238,20138
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.104,25600,6939565520750.82,1,7,80,6,68174,7,kernel,0,"[8, 1, 8]",0.761905,20148
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.983,0,6939565520758.693,1,7,44,25,68175,7,kernel,0,"[16, 4, 1]",0.761905,20148
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.984,25600,6939565520761.508,1,7,80,6,68197,7,kernel,0,"[64, 1, 1]",0.761905,20152
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.984,16,6939565520768.26,1,7,48,0,68209,7,kernel,0,"[1, 1, 1]",0.011905,20156
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565520775.044,1,7,22,5,68224,7,kernel,0,"[50, 1, 1]",0.595238,20167
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",1.985,0,6939565520777.668,1,7,30,0,68241,7,kernel,0,"[2, 2, 1]",0.047619,20170
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",9.216,0,6939565520780.42,1,7,30,100,68260,7,kernel,0,"[1024, 2, 1]",24.380953,20177
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.072,16,6939565520790.404,1,7,40,5,68297,7,kernel,0,"[50, 1, 1]",0.595238,20184
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565520794.34,1,7,38,0,68299,7,kernel,0,"[2, 1, 1]",0.02381,20184
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565520799.492,1,7,22,5,68328,7,kernel,0,"[50, 1, 1]",0.595238,20200
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.784,25600,6939565520802.244,1,7,80,6,68358,7,kernel,0,"[8, 1, 8]",0.761905,20212
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565520809.764,1,7,44,25,68359,7,kernel,0,"[16, 4, 1]",0.761905,20212
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.888,25600,6939565520812.612,1,7,80,6,68381,7,kernel,0,"[64, 1, 1]",0.761905,20216
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.08,16,6939565523172.991,1,7,48,0,68393,7,kernel,0,"[1, 1, 1]",0.011905,20220
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565523183.871,1,7,22,5,68456,7,kernel,0,"[50, 1, 1]",0.595238,20262
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565523186.719,1,7,32,10,68470,7,kernel,0,"[25, 1, 1]",0.297619,20263
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565523190.847,1,7,16,0,68483,7,kernel,0,"[2, 1, 1]",0.02381,20271
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.608,53504,6939565523193.663,1,7,236,0,68497,7,kernel,0,"[1, 8, 1]",0.095238,20256
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565523231.199,1,7,16,15,68555,7,kernel,0,"[150, 1, 1]",1.785714,20321
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565523235.231,1,7,16,15,68580,7,kernel,0,"[150, 1, 1]",1.785714,20331
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565523239.327,1,7,22,15,68594,7,kernel,0,"[150, 1, 1]",1.785714,20335
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565523241.759,1,7,16,15,68614,7,kernel,0,"[150, 1, 1]",1.785714,20342
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.665,0,6939565523245.886,1,7,22,15,68628,7,kernel,0,"[150, 1, 1]",1.785714,20346
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.239,0,6939565523248.383,1,7,16,30,68663,7,kernel,0,"[300, 1, 1]",3.571429,20367
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.183,16384,6939565523251.519,1,7,57,38,68689,7,kernel,0,"[4, 2, 24]",2.285714,20378
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.912,0,6939565523265.503,1,7,44,25,68691,7,kernel,0,"[16, 4, 1]",0.761905,20378
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.328,16384,6939565523269.151,1,7,57,38,68708,7,kernel,0,"[16, 12, 1]",2.285714,20382
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.617,16,6939565523281.214,1,7,48,0,68721,7,kernel,0,"[3, 1, 1]",0.035714,20386
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.791,0,6939565523289.631,1,7,22,5,68744,7,kernel,0,"[50, 1, 1]",0.595238,20405
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.976,16,6939565523292.223,1,7,40,5,68779,7,kernel,0,"[50, 1, 1]",0.595238,20408
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565523296.031,1,7,38,0,68781,7,kernel,0,"[2, 1, 1]",0.02381,20408
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.624,16,6939565523301.246,1,7,40,5,68822,7,kernel,0,"[50, 1, 1]",0.595238,20422
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.417,0,6939565523304.67,1,7,38,0,68824,7,kernel,0,"[2, 1, 1]",0.02381,20422
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.761,0,6939565523309.854,1,7,22,5,68853,7,kernel,0,"[50, 1, 1]",0.595238,20438
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.648,16384,6939565523312.479,1,7,57,25,68879,7,kernel,0,"[16, 2, 4]",1.52381,20450
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939565523328.83,1,7,44,67,68881,7,kernel,0,"[64, 4, 1]",3.047619,20450
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.136,16384,6939565523332.639,1,7,57,51,68898,7,kernel,0,"[16, 16, 1]",3.047619,20454
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.792,16,6939565523348.542,1,7,48,0,68911,7,kernel,0,"[1, 1, 1]",0.011905,20458
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.56,0,6939565523355.166,1,7,22,20,68944,7,kernel,0,"[200, 1, 1]",2.380952,20479
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.104,0,6939565523358.462,1,7,22,20,68958,7,kernel,0,"[200, 1, 1]",2.380952,20484
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.816,16384,6939565523362.398,1,7,57,44,68983,7,kernel,0,"[4, 2, 28]",2.666667,20494
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.392,0,6939565523378.014,1,7,44,25,68985,7,kernel,0,"[16, 4, 1]",0.761905,20494
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.92,16384,6939565523382.142,1,7,57,51,69002,7,kernel,0,"[16, 16, 1]",3.047619,20498
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.592,16,6939565523396.83,1,7,48,0,69015,7,kernel,0,"[4, 1, 1]",0.047619,20502
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565523404.158,1,7,22,5,69038,7,kernel,0,"[50, 1, 1]",0.595238,20521
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.136,16,6939565525701.721,1,7,40,5,69073,7,kernel,0,"[50, 1, 1]",0.595238,20524
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.704,0,6939565525705.625,1,7,38,0,69075,7,kernel,0,"[2, 1, 1]",0.02381,20524
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565525711.161,1,7,22,5,69104,7,kernel,0,"[50, 1, 1]",0.595238,20540
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.232,25600,6939565525713.625,1,7,80,6,69134,7,kernel,0,"[8, 1, 8]",0.761905,20552
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565525721.625,1,7,44,25,69135,7,kernel,0,"[16, 4, 1]",0.761905,20552
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.984,25600,6939565525724.473,1,7,80,6,69157,7,kernel,0,"[64, 1, 1]",0.761905,20556
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565525731.225,1,7,48,0,69169,7,kernel,0,"[1, 1, 1]",0.011905,20560
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565525739.769,1,7,22,5,69232,7,kernel,0,"[50, 1, 1]",0.595238,20602
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565525741.977,1,7,32,10,69246,7,kernel,0,"[25, 1, 1]",0.297619,20603
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565525746.201,1,7,16,0,69259,7,kernel,0,"[2, 1, 1]",0.02381,20611
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.736,53504,6939565525748.985,1,7,236,0,69273,7,kernel,0,"[1, 8, 1]",0.095238,20596
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565525786.617,1,7,16,15,69331,7,kernel,0,"[150, 1, 1]",1.785714,20661
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565525790.617,1,7,16,15,69356,7,kernel,0,"[150, 1, 1]",1.785714,20671
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565525795.129,1,7,22,15,69370,7,kernel,0,"[150, 1, 1]",1.785714,20675
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565525797.593,1,7,16,15,69390,7,kernel,0,"[150, 1, 1]",1.785714,20682
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565525801.785,1,7,22,15,69404,7,kernel,0,"[150, 1, 1]",1.785714,20686
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565525804.281,1,7,16,30,69439,7,kernel,0,"[300, 1, 1]",3.571429,20707
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.224,16384,6939565525807.257,1,7,57,38,69465,7,kernel,0,"[4, 2, 24]",2.285714,20718
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.68,0,6939565525820.185,1,7,44,25,69467,7,kernel,0,"[16, 4, 1]",0.761905,20718
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.744,16384,6939565525824.601,1,7,57,38,69484,7,kernel,0,"[16, 12, 1]",2.285714,20722
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565525837.176,1,7,48,0,69497,7,kernel,0,"[3, 1, 1]",0.035714,20726
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565525845.593,1,7,22,5,69520,7,kernel,0,"[50, 1, 1]",0.595238,20745
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.849,16,6939565525848.056,1,7,40,5,69555,7,kernel,0,"[50, 1, 1]",0.595238,20748
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565525851.673,1,7,38,0,69557,7,kernel,0,"[2, 1, 1]",0.02381,20748
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.729,0,6939565525856.856,1,7,22,5,69586,7,kernel,0,"[50, 1, 1]",0.595238,20764
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.519,16384,6939565525859.321,1,7,57,25,69612,7,kernel,0,"[16, 2, 4]",1.52381,20776
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565525875.577,1,7,44,67,69614,7,kernel,0,"[64, 4, 1]",3.047619,20776
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.625,16384,6939565525879.288,1,7,57,51,69631,7,kernel,0,"[16, 16, 1]",3.047619,20780
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.792,16,6939565525894.712,1,7,48,0,69644,7,kernel,0,"[1, 1, 1]",0.011905,20784
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.816,0,6939565525901.336,1,7,22,20,69677,7,kernel,0,"[200, 1, 1]",2.380952,20805
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.944,0,6939565525904.889,1,7,22,20,69691,7,kernel,0,"[200, 1, 1]",2.380952,20810
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.295,16384,6939565525908.697,1,7,57,44,69716,7,kernel,0,"[4, 2, 28]",2.666667,20820
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.616,0,6939565525924.824,1,7,44,25,69718,7,kernel,0,"[16, 4, 1]",0.761905,20820
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",17.888,16384,6939565528288.915,1,7,57,51,69735,7,kernel,0,"[16, 16, 1]",3.047619,20824
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565528307.507,1,7,48,0,69748,7,kernel,0,"[4, 1, 1]",0.047619,20828
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565528315.923,1,7,22,5,69771,7,kernel,0,"[50, 1, 1]",0.595238,20847
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939565528318.867,1,7,40,5,69806,7,kernel,0,"[50, 1, 1]",0.595238,20850
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565528322.451,1,7,38,0,69808,7,kernel,0,"[2, 1, 1]",0.02381,20850
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565528327.603,1,7,22,5,69837,7,kernel,0,"[50, 1, 1]",0.595238,20866
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.784,25600,6939565528330.067,1,7,80,6,69867,7,kernel,0,"[8, 1, 8]",0.761905,20878
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565528337.555,1,7,44,25,69868,7,kernel,0,"[16, 4, 1]",0.761905,20878
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939565528340.371,1,7,80,6,69890,7,kernel,0,"[64, 1, 1]",0.761905,20882
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.08,16,6939565528347.347,1,7,48,0,69902,7,kernel,0,"[1, 1, 1]",0.011905,20886
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565528354.099,1,7,22,5,69965,7,kernel,0,"[50, 1, 1]",0.595238,20928
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.232,16,6939565528356.339,1,7,32,10,69979,7,kernel,0,"[25, 1, 1]",0.297619,20929
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565528360.435,1,7,16,0,69992,7,kernel,0,"[2, 1, 1]",0.02381,20937
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939565528363.251,1,7,236,0,70006,7,kernel,0,"[1, 8, 1]",0.095238,20922
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565528400.819,1,7,16,15,70064,7,kernel,0,"[150, 1, 1]",1.785714,20987
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565528404.915,1,7,16,15,70089,7,kernel,0,"[150, 1, 1]",1.785714,20997
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.761,0,6939565528409.394,1,7,22,15,70103,7,kernel,0,"[150, 1, 1]",1.785714,21001
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565528411.859,1,7,16,15,70123,7,kernel,0,"[150, 1, 1]",1.785714,21008
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565528415.923,1,7,22,15,70137,7,kernel,0,"[150, 1, 1]",1.785714,21012
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565528418.451,1,7,16,30,70172,7,kernel,0,"[300, 1, 1]",3.571429,21033
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.0,16384,6939565528421.395,1,7,57,38,70198,7,kernel,0,"[4, 2, 24]",2.285714,21044
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.584,0,6939565528434.099,1,7,44,25,70200,7,kernel,0,"[16, 4, 1]",0.761905,21044
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.648,16384,6939565528438.547,1,7,57,38,70217,7,kernel,0,"[16, 12, 1]",2.285714,21048
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.681,16,6939565528451.058,1,7,48,0,70230,7,kernel,0,"[3, 1, 1]",0.035714,21052
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565528459.507,1,7,22,5,70253,7,kernel,0,"[50, 1, 1]",0.595238,21071
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.913,16,6939565528461.97,1,7,40,5,70288,7,kernel,0,"[50, 1, 1]",0.595238,21074
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565528465.587,1,7,38,0,70290,7,kernel,0,"[2, 1, 1]",0.02381,21074
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565528470.802,1,7,22,5,70319,7,kernel,0,"[50, 1, 1]",0.595238,21090
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.744,16384,6939565528473.267,1,7,57,25,70345,7,kernel,0,"[16, 2, 4]",1.52381,21102
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.168,0,6939565528489.81,1,7,44,67,70347,7,kernel,0,"[64, 4, 1]",3.047619,21102
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.239,16384,6939565528493.715,1,7,57,51,70364,7,kernel,0,"[16, 16, 1]",3.047619,21106
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.695,16,6939565528508.691,1,7,48,0,70377,7,kernel,0,"[1, 1, 1]",0.011905,21110
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.104,0,6939565530805.453,1,7,22,20,70410,7,kernel,0,"[200, 1, 1]",2.380952,21131
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.88,0,6939565530809.325,1,7,22,20,70424,7,kernel,0,"[200, 1, 1]",2.380952,21136
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.352,16384,6939565530812.909,1,7,57,44,70449,7,kernel,0,"[4, 2, 28]",2.666667,21146
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.68,0,6939565530830.061,1,7,44,25,70451,7,kernel,0,"[16, 4, 1]",0.761905,21146
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.984,16384,6939565530834.509,1,7,57,51,70468,7,kernel,0,"[16, 16, 1]",3.047619,21150
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.52,16,6939565530849.293,1,7,48,0,70481,7,kernel,0,"[4, 1, 1]",0.047619,21154
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565530857.549,1,7,22,5,70504,7,kernel,0,"[50, 1, 1]",0.595238,21173
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939565530860.141,1,7,40,5,70539,7,kernel,0,"[50, 1, 1]",0.595238,21176
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565530863.757,1,7,38,0,70541,7,kernel,0,"[2, 1, 1]",0.02381,21176
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565530868.941,1,7,22,5,70570,7,kernel,0,"[50, 1, 1]",0.595238,21192
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.88,25600,6939565530871.405,1,7,80,6,70600,7,kernel,0,"[8, 1, 8]",0.761905,21204
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.952,0,6939565530879.053,1,7,44,25,70601,7,kernel,0,"[16, 4, 1]",0.761905,21204
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565530881.709,1,7,80,6,70623,7,kernel,0,"[64, 1, 1]",0.761905,21208
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.56,16,6939565530888.621,1,7,48,0,70635,7,kernel,0,"[1, 1, 1]",0.011905,21212
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.408,0,6939565530895.917,1,7,22,5,70698,7,kernel,0,"[50, 1, 1]",0.595238,21254
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.36,16,6939565530898.061,1,7,32,10,70712,7,kernel,0,"[25, 1, 1]",0.297619,21255
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565530902.157,1,7,16,0,70725,7,kernel,0,"[2, 1, 1]",0.02381,21263
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.448,53504,6939565530904.973,1,7,236,0,70739,7,kernel,0,"[1, 8, 1]",0.095238,21248
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565530942.573,1,7,16,15,70797,7,kernel,0,"[150, 1, 1]",1.785714,21313
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565530946.381,1,7,16,15,70822,7,kernel,0,"[150, 1, 1]",1.785714,21323
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565530950.861,1,7,22,15,70836,7,kernel,0,"[150, 1, 1]",1.785714,21327
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565530953.325,1,7,16,15,70856,7,kernel,0,"[150, 1, 1]",1.785714,21334
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565530957.453,1,7,22,15,70870,7,kernel,0,"[150, 1, 1]",1.785714,21338
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565530959.917,1,7,16,30,70905,7,kernel,0,"[300, 1, 1]",3.571429,21359
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.48,16384,6939565530962.893,1,7,57,38,70931,7,kernel,0,"[4, 2, 24]",2.285714,21370
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.776,0,6939565530976.205,1,7,44,25,70933,7,kernel,0,"[16, 4, 1]",0.761905,21370
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.2,16384,6939565530980.781,1,7,57,38,70950,7,kernel,0,"[16, 12, 1]",2.285714,21374
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565530992.685,1,7,48,0,70963,7,kernel,0,"[3, 1, 1]",0.035714,21378
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565531001.133,1,7,22,5,70986,7,kernel,0,"[50, 1, 1]",0.595238,21397
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939565531003.597,1,7,40,5,71021,7,kernel,0,"[50, 1, 1]",0.595238,21400
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565531007.213,1,7,38,0,71023,7,kernel,0,"[2, 1, 1]",0.02381,21400
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.759,0,6939565531012.365,1,7,22,5,71052,7,kernel,0,"[50, 1, 1]",0.595238,21416
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.696,16384,6939565533367.719,1,7,57,25,71078,7,kernel,0,"[16, 2, 4]",1.52381,21428
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.136,0,6939565533386.279,1,7,44,67,71080,7,kernel,0,"[64, 4, 1]",3.047619,21428
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.208,16384,6939565533390.215,1,7,57,51,71097,7,kernel,0,"[16, 16, 1]",3.047619,21432
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939565533405.191,1,7,48,0,71110,7,kernel,0,"[1, 1, 1]",0.011905,21436
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939565533413.767,1,7,22,20,71143,7,kernel,0,"[200, 1, 1]",2.380952,21457
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.912,0,6939565533416.871,1,7,22,20,71157,7,kernel,0,"[200, 1, 1]",2.380952,21462
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.232,16384,6939565533420.647,1,7,57,44,71182,7,kernel,0,"[4, 2, 28]",2.666667,21472
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.456,0,6939565533436.711,1,7,44,25,71184,7,kernel,0,"[16, 4, 1]",0.761905,21472
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.176,16384,6939565533440.999,1,7,57,51,71201,7,kernel,0,"[16, 16, 1]",3.047619,21476
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.912,16,6939565533456.007,1,7,48,0,71214,7,kernel,0,"[4, 1, 1]",0.047619,21480
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565533463.783,1,7,22,5,71237,7,kernel,0,"[50, 1, 1]",0.595238,21499
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939565533466.439,1,7,40,5,71272,7,kernel,0,"[50, 1, 1]",0.595238,21502
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565533470.215,1,7,38,0,71274,7,kernel,0,"[2, 1, 1]",0.02381,21502
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565533475.431,1,7,22,5,71303,7,kernel,0,"[50, 1, 1]",0.595238,21518
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939565533477.735,1,7,80,6,71333,7,kernel,0,"[8, 1, 8]",0.761905,21530
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.92,0,6939565533485.703,1,7,44,25,71334,7,kernel,0,"[16, 4, 1]",0.761905,21530
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939565533488.359,1,7,80,6,71356,7,kernel,0,"[64, 1, 1]",0.761905,21534
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.784,16,6939565533495.495,1,7,48,0,71368,7,kernel,0,"[1, 1, 1]",0.011905,21538
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565533503.111,1,7,22,5,71431,7,kernel,0,"[50, 1, 1]",0.595238,21580
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.328,16,6939565533505.319,1,7,32,10,71445,7,kernel,0,"[25, 1, 1]",0.297619,21581
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565533509.415,1,7,16,0,71458,7,kernel,0,"[2, 1, 1]",0.02381,21589
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.352,53504,6939565533512.231,1,7,236,0,71472,7,kernel,0,"[1, 8, 1]",0.095238,21574
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565533549.703,1,7,16,15,71530,7,kernel,0,"[150, 1, 1]",1.785714,21639
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939565533553.607,1,7,16,15,71555,7,kernel,0,"[150, 1, 1]",1.785714,21649
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565533557.735,1,7,22,15,71569,7,kernel,0,"[150, 1, 1]",1.785714,21653
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565533560.167,1,7,16,15,71589,7,kernel,0,"[150, 1, 1]",1.785714,21660
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565533564.263,1,7,22,15,71603,7,kernel,0,"[150, 1, 1]",1.785714,21664
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565533566.631,1,7,16,30,71638,7,kernel,0,"[300, 1, 1]",3.571429,21685
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.864,16384,6939565533569.607,1,7,57,38,71664,7,kernel,0,"[4, 2, 24]",2.285714,21696
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.999,0,6939565533583.207,1,7,44,25,71666,7,kernel,0,"[16, 4, 1]",0.761905,21696
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.36,16384,6939565533587.943,1,7,57,38,71683,7,kernel,0,"[16, 12, 1]",2.285714,21700
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939565533600.103,1,7,48,0,71696,7,kernel,0,"[3, 1, 1]",0.035714,21704
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565533608.679,1,7,22,5,71719,7,kernel,0,"[50, 1, 1]",0.595238,21723
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939565535983.649,1,7,40,5,71754,7,kernel,0,"[50, 1, 1]",0.595238,21726
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.8,0,6939565535987.553,1,7,38,0,71756,7,kernel,0,"[2, 1, 1]",0.02381,21726
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565535993.217,1,7,22,5,71785,7,kernel,0,"[50, 1, 1]",0.595238,21742
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.056,16384,6939565535995.777,1,7,57,25,71811,7,kernel,0,"[16, 2, 4]",1.52381,21754
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.168,0,6939565536013.665,1,7,44,67,71813,7,kernel,0,"[64, 4, 1]",3.047619,21754
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.632,16384,6939565536017.569,1,7,57,51,71830,7,kernel,0,"[16, 16, 1]",3.047619,21758
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939565536032.033,1,7,48,0,71843,7,kernel,0,"[1, 1, 1]",0.011905,21762
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.464,0,6939565536040.609,1,7,22,20,71876,7,kernel,0,"[200, 1, 1]",2.380952,21783
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.88,0,6939565536043.873,1,7,22,20,71890,7,kernel,0,"[200, 1, 1]",2.380952,21788
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.648,16384,6939565536047.489,1,7,57,44,71915,7,kernel,0,"[4, 2, 28]",2.666667,21798
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.776,0,6939565536063.905,1,7,44,25,71917,7,kernel,0,"[16, 4, 1]",0.761905,21798
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.952,16384,6939565536068.513,1,7,57,51,71934,7,kernel,0,"[16, 16, 1]",3.047619,21802
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.944,16,6939565536083.201,1,7,48,0,71947,7,kernel,0,"[4, 1, 1]",0.047619,21806
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565536090.945,1,7,22,5,71970,7,kernel,0,"[50, 1, 1]",0.595238,21825
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.04,16,6939565536093.537,1,7,40,5,72005,7,kernel,0,"[50, 1, 1]",0.595238,21828
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939565536097.313,1,7,38,0,72007,7,kernel,0,"[2, 1, 1]",0.02381,21828
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565536102.529,1,7,22,5,72036,7,kernel,0,"[50, 1, 1]",0.595238,21844
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939565536104.801,1,7,80,6,72066,7,kernel,0,"[8, 1, 8]",0.761905,21856
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.92,0,6939565536112.609,1,7,44,25,72067,7,kernel,0,"[16, 4, 1]",0.761905,21856
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939565536115.233,1,7,80,6,72089,7,kernel,0,"[64, 1, 1]",0.761905,21860
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.56,16,6939565536122.017,1,7,48,0,72101,7,kernel,0,"[1, 1, 1]",0.011905,21864
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565536129.281,1,7,22,5,72164,7,kernel,0,"[50, 1, 1]",0.595238,21906
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565536131.489,1,7,32,10,72178,7,kernel,0,"[25, 1, 1]",0.297619,21907
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565536135.649,1,7,16,0,72191,7,kernel,0,"[2, 1, 1]",0.02381,21915
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.352,53504,6939565536138.465,1,7,236,0,72205,7,kernel,0,"[1, 8, 1]",0.095238,21900
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565536175.841,1,7,16,15,72263,7,kernel,0,"[150, 1, 1]",1.785714,21965
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565536179.905,1,7,16,15,72288,7,kernel,0,"[150, 1, 1]",1.785714,21975
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.663,0,6939565536184.065,1,7,22,15,72302,7,kernel,0,"[150, 1, 1]",1.785714,21979
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565536186.529,1,7,16,15,72322,7,kernel,0,"[150, 1, 1]",1.785714,21986
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565536190.625,1,7,22,15,72336,7,kernel,0,"[150, 1, 1]",1.785714,21990
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565536192.961,1,7,16,30,72371,7,kernel,0,"[300, 1, 1]",3.571429,22011
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",11.968,16384,6939565536195.937,1,7,57,38,72397,7,kernel,0,"[4, 2, 24]",2.285714,22022
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.617,0,6939565536208.608,1,7,44,25,72399,7,kernel,0,"[16, 4, 1]",0.761905,22022
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.807,16384,6939565536213.057,1,7,57,38,72416,7,kernel,0,"[16, 12, 1]",2.285714,22026
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939565536225.665,1,7,48,0,72429,7,kernel,0,"[3, 1, 1]",0.035714,22030
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565538558.331,1,7,22,5,72452,7,kernel,0,"[50, 1, 1]",0.595238,22049
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939565538561.275,1,7,40,5,72487,7,kernel,0,"[50, 1, 1]",0.595238,22052
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565538565.019,1,7,38,0,72489,7,kernel,0,"[2, 1, 1]",0.02381,22052
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565538570.235,1,7,22,5,72518,7,kernel,0,"[50, 1, 1]",0.595238,22068
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.12,16384,6939565538572.699,1,7,57,25,72544,7,kernel,0,"[16, 2, 4]",1.52381,22080
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.816,0,6939565538590.555,1,7,44,67,72546,7,kernel,0,"[64, 4, 1]",3.047619,22080
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.24,16384,6939565538594.363,1,7,57,51,72563,7,kernel,0,"[16, 16, 1]",3.047619,22084
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565538609.403,1,7,48,0,72576,7,kernel,0,"[1, 1, 1]",0.011905,22088
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939565538617.979,1,7,22,20,72609,7,kernel,0,"[200, 1, 1]",2.380952,22109
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.784,0,6939565538620.955,1,7,22,20,72623,7,kernel,0,"[200, 1, 1]",2.380952,22114
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.264,16384,6939565538624.539,1,7,57,44,72648,7,kernel,0,"[4, 2, 28]",2.666667,22124
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.392,0,6939565538640.603,1,7,44,25,72650,7,kernel,0,"[16, 4, 1]",0.761905,22124
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.304,16384,6939565538644.795,1,7,57,51,72667,7,kernel,0,"[16, 16, 1]",3.047619,22128
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.88,16,6939565538659.835,1,7,48,0,72680,7,kernel,0,"[4, 1, 1]",0.047619,22132
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565538667.451,1,7,22,5,72703,7,kernel,0,"[50, 1, 1]",0.595238,22151
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.752,16,6939565538670.043,1,7,40,5,72738,7,kernel,0,"[50, 1, 1]",0.595238,22154
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565538673.627,1,7,38,0,72740,7,kernel,0,"[2, 1, 1]",0.02381,22154
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565538678.875,1,7,22,5,72769,7,kernel,0,"[50, 1, 1]",0.595238,22170
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.008,25600,6939565538681.179,1,7,80,6,72799,7,kernel,0,"[8, 1, 8]",0.761905,22182
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.92,0,6939565538689.019,1,7,44,25,72800,7,kernel,0,"[16, 4, 1]",0.761905,22182
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565538691.675,1,7,80,6,72822,7,kernel,0,"[64, 1, 1]",0.761905,22186
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.56,16,6939565538698.459,1,7,48,0,72834,7,kernel,0,"[1, 1, 1]",0.011905,22190
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565538705.819,1,7,22,5,72897,7,kernel,0,"[50, 1, 1]",0.595238,22232
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565538708.251,1,7,32,10,72911,7,kernel,0,"[25, 1, 1]",0.297619,22233
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565538712.379,1,7,16,0,72924,7,kernel,0,"[2, 1, 1]",0.02381,22241
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939565538715.163,1,7,236,0,72938,7,kernel,0,"[1, 8, 1]",0.095238,22226
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.961,0,6939565538752.826,1,7,16,15,72996,7,kernel,0,"[150, 1, 1]",1.785714,22291
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565538756.795,1,7,16,15,73021,7,kernel,0,"[150, 1, 1]",1.785714,22301
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565538761.115,1,7,22,15,73035,7,kernel,0,"[150, 1, 1]",1.785714,22305
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565538763.579,1,7,16,15,73055,7,kernel,0,"[150, 1, 1]",1.785714,22312
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.599,0,6939565538767.707,1,7,22,15,73069,7,kernel,0,"[150, 1, 1]",1.785714,22316
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.136,0,6939565541081.109,1,7,16,30,73104,7,kernel,0,"[300, 1, 1]",3.571429,22337
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.217,16384,6939565541085.045,1,7,57,38,73130,7,kernel,0,"[4, 2, 24]",2.285714,22348
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.912,0,6939565541099.029,1,7,44,25,73132,7,kernel,0,"[16, 4, 1]",0.761905,22348
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.48,16384,6939565541102.709,1,7,57,38,73149,7,kernel,0,"[16, 12, 1]",2.285714,22352
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939565541115.893,1,7,48,0,73162,7,kernel,0,"[3, 1, 1]",0.035714,22356
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565541124.501,1,7,22,5,73185,7,kernel,0,"[50, 1, 1]",0.595238,22375
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565541127.093,1,7,16,5,73217,7,kernel,0,"[50, 1, 1]",0.595238,22392
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565541131.573,1,7,16,51,73242,7,kernel,0,"[512, 1, 1]",6.095238,22402
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.92,0,6939565541135.989,1,7,16,51,73267,7,kernel,0,"[512, 1, 1]",6.095238,22412
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",35.392,0,6939565541141.525,1,7,16,100,73294,7,kernel,0,"[10000, 1, 1]",119.047623,22424
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.704,8192,6939565541177.653,1,7,24,13,73301,7,kernel,0,"[16, 1, 1]",0.190476,22419
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.44,0,6939565541183.189,1,7,16,5,73327,7,kernel,0,"[50, 1, 1]",0.595238,22437
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939565541187.829,1,7,16,51,73352,7,kernel,0,"[512, 1, 1]",6.095238,22447
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",2.08,0,6939565541192.373,1,7,16,51,73377,7,kernel,0,"[512, 1, 1]",6.095238,22457
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",4.032,0,6939565541198.101,1,7,22,51,73391,7,kernel,0,"[512, 1, 1]",6.095238,22461
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",35.52,0,6939565541202.933,1,7,16,100,73417,7,kernel,0,"[10000, 1, 1]",119.047623,22474
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.992,8192,6939565541239.285,1,7,24,13,73424,7,kernel,0,"[16, 1, 1]",0.190476,22469
