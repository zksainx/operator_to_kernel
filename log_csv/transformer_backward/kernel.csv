pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,11.809524,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[512, 1, 1]",9.089,2064,6939292608610.708,1,7,32,25,10965,7,kernel,0,"[1, 62, 1]",0.738095,2051
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.567,0,6939292625576.517,1,7,16,0,10978,7,kernel,0,"[1, 1, 1]",0.011905,2056
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.712,0,6939292636967.354,1,7,16,100,11008,7,kernel,0,"[1954, 1, 1]",23.261906,2578
0,6.857143,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params),0,"[128, 1, 1]",50.656,30720,6939292640557.975,1,7,126,14,11052,7,kernel,0,"[4, 1, 36]",1.714286,2574
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.0,0,6939292640613.239,1,7,44,25,11053,7,kernel,0,"[16, 4, 1]",0.761905,2574
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.745,0,6939292641037.846,1,7,16,100,11075,7,kernel,0,"[1954, 1, 1]",23.261906,2586
0,119.238098,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",50.304,16384,6939292641460.086,1,7,57,67,11090,7,kernel,0,"[4, 313, 1]",14.904762,2582
0,3.809524,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",5.312,16,6939292641511.158,1,7,32,8,11103,7,kernel,0,"[20, 1, 1]",0.238095,2590
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.105,16,6939292641922.197,1,7,40,5,11156,7,kernel,0,"[50, 1, 1]",0.595238,2615
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.736,0,6939292641929.814,1,7,38,0,11158,7,kernel,0,"[2, 1, 1]",0.02381,2615
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.751,16,6939292641935.35,1,7,40,5,11199,7,kernel,0,"[50, 1, 1]",0.595238,2629
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.385,0,6939292641938.965,1,7,38,0,11201,7,kernel,0,"[2, 1, 1]",0.02381,2629
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939292642289.973,1,7,22,5,11230,7,kernel,0,"[50, 1, 1]",0.595238,2645
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.64,16384,6939292642419.829,1,7,57,25,11257,7,kernel,0,"[16, 2, 4]",1.52381,2657
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.88,0,6939292642437.301,1,7,44,67,11259,7,kernel,0,"[64, 4, 1]",3.047619,2657
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.368,16384,6939292642857.461,1,7,57,51,11281,7,kernel,0,"[16, 16, 1]",3.047619,2661
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.728,16,6939292643155.924,1,7,48,0,11294,7,kernel,0,"[1, 1, 1]",0.011905,2665
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939292643429.524,1,7,22,20,11327,7,kernel,0,"[200, 1, 1]",2.380952,2686
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.552,0,6939292657519.079,1,7,22,20,11341,7,kernel,0,"[200, 1, 1]",2.380952,2691
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.608,16384,6939292657523.335,1,7,57,44,11367,7,kernel,0,"[4, 2, 28]",2.666667,2701
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.584,0,6939292657540.807,1,7,44,25,11369,7,kernel,0,"[16, 4, 1]",0.761905,2701
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.112,16384,6939292657548.743,1,7,57,51,11387,7,kernel,0,"[16, 16, 1]",3.047619,2705
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939292657563.623,1,7,48,0,11400,7,kernel,0,"[4, 1, 1]",0.047619,2709
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292657930.726,1,7,22,5,11423,7,kernel,0,"[50, 1, 1]",0.595238,2728
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.041,16,6939292658149.19,1,7,40,5,11458,7,kernel,0,"[50, 1, 1]",0.595238,2731
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.736,0,6939292658153.158,1,7,38,0,11460,7,kernel,0,"[2, 1, 1]",0.02381,2731
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292658158.63,1,7,22,5,11489,7,kernel,0,"[50, 1, 1]",0.595238,2747
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.072,25600,6939292658464.198,1,7,80,6,11520,7,kernel,0,"[8, 1, 8]",0.761905,2759
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.272,0,6939292658472.006,1,7,44,25,11521,7,kernel,0,"[16, 4, 1]",0.761905,2759
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939292665784.319,1,7,80,6,11544,7,kernel,0,"[64, 1, 1]",0.761905,2763
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.824,16,6939292666101.983,1,7,48,0,11556,7,kernel,0,"[1, 1, 1]",0.011905,2767
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939292683205.199,1,7,22,5,11619,7,kernel,0,"[50, 1, 1]",0.595238,2809
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939292683208.143,1,7,32,10,11633,7,kernel,0,"[25, 1, 1]",0.297619,2810
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939292683212.431,1,7,16,0,11646,7,kernel,0,"[2, 1, 1]",0.02381,2818
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.96,53504,6939292695041.188,1,7,236,0,11660,7,kernel,0,"[1, 8, 1]",0.095238,2803
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939292695785.443,1,7,16,10,11718,7,kernel,0,"[100, 1, 1]",1.190476,2868
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939292696000.931,1,7,16,10,11743,7,kernel,0,"[100, 1, 1]",1.190476,2878
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292696006.019,1,7,22,10,11757,7,kernel,0,"[100, 1, 1]",1.190476,2882
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939292696265.891,1,7,16,20,11792,7,kernel,0,"[200, 1, 1]",2.380952,2903
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.048,16384,6939292696625.507,1,7,57,25,11819,7,kernel,0,"[4, 2, 16]",1.52381,2914
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939292696636.355,1,7,44,25,11821,7,kernel,0,"[16, 4, 1]",0.761905,2914
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.192,16384,6939292696640.131,1,7,57,25,11839,7,kernel,0,"[16, 8, 1]",1.52381,2918
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939292696649.059,1,7,48,0,11852,7,kernel,0,"[2, 1, 1]",0.02381,2922
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.039,25600,6939292697133.603,1,7,80,6,11890,7,kernel,0,"[8, 1, 8]",0.761905,2942
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.304,0,6939292697141.347,1,7,44,25,11891,7,kernel,0,"[16, 4, 1]",0.761905,2942
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.047,25600,6939292697144.387,1,7,80,6,11913,7,kernel,0,"[64, 1, 1]",0.761905,2946
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939292697151.171,1,7,48,0,11925,7,kernel,0,"[1, 1, 1]",0.011905,2950
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.985,0,6939292697159.874,1,7,22,5,11940,7,kernel,0,"[50, 1, 1]",0.595238,2961
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.368,0,6939292705819.354,1,7,30,0,11957,7,kernel,0,"[2, 2, 1]",0.047619,2964
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.496,0,6939292705826.779,1,7,30,100,11976,7,kernel,0,"[1024, 2, 1]",24.380953,2971
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939292706030.458,1,7,40,5,12013,7,kernel,0,"[50, 1, 1]",0.595238,2978
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.704,0,6939292706034.362,1,7,38,0,12015,7,kernel,0,"[2, 1, 1]",0.02381,2978
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.791,0,6939292706039.835,1,7,22,5,12044,7,kernel,0,"[50, 1, 1]",0.595238,2994
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.944,25600,6939292706322.33,1,7,80,6,12074,7,kernel,0,"[8, 1, 8]",0.761905,3006
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.304,0,6939292706330.106,1,7,44,25,12075,7,kernel,0,"[16, 4, 1]",0.761905,3006
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939292706333.242,1,7,80,6,12097,7,kernel,0,"[64, 1, 1]",0.761905,3010
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.76,16,6939292706556.89,1,7,48,0,12109,7,kernel,0,"[1, 1, 1]",0.011905,3014
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.241,0,6939292706838.521,1,7,22,5,12172,7,kernel,0,"[50, 1, 1]",0.595238,3056
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.489,16,6939292706841.529,1,7,32,10,12186,7,kernel,0,"[25, 1, 1]",0.297619,3057
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.015,0,6939292706866.682,1,7,16,0,12199,7,kernel,0,"[2, 1, 1]",0.02381,3065
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.896,53504,6939292707085.881,1,7,236,0,12213,7,kernel,0,"[1, 8, 1]",0.095238,3050
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939292707488.217,1,7,16,15,12271,7,kernel,0,"[150, 1, 1]",1.785714,3115
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.632,0,6939292707792.281,1,7,16,15,12296,7,kernel,0,"[150, 1, 1]",1.785714,3125
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.432,0,6939292707797.913,1,7,22,15,12310,7,kernel,0,"[150, 1, 1]",1.785714,3129
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292707801.177,1,7,16,15,12330,7,kernel,0,"[150, 1, 1]",1.785714,3136
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.663,0,6939292707805.785,1,7,22,15,12344,7,kernel,0,"[150, 1, 1]",1.785714,3140
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939292708188.28,1,7,16,30,12379,7,kernel,0,"[300, 1, 1]",3.571429,3161
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.472,16384,6939292708192.152,1,7,57,38,12406,7,kernel,0,"[4, 2, 24]",2.285714,3172
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.751,0,6939292708206.329,1,7,44,25,12408,7,kernel,0,"[16, 4, 1]",0.761905,3172
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.736,16384,6939292708635.576,1,7,57,38,12426,7,kernel,0,"[16, 12, 1]",2.285714,3176
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939292708649.048,1,7,48,0,12439,7,kernel,0,"[3, 1, 1]",0.035714,3180
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939292708657.656,1,7,22,5,12462,7,kernel,0,"[50, 1, 1]",0.595238,3199
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939292708660.568,1,7,40,5,12497,7,kernel,0,"[50, 1, 1]",0.595238,3202
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939292708664.184,1,7,38,0,12499,7,kernel,0,"[2, 1, 1]",0.02381,3202
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.049,0,6939292709088.887,1,7,22,5,12528,7,kernel,0,"[50, 1, 1]",0.595238,3218
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.799,16384,6939292709091.8,1,7,57,25,12554,7,kernel,0,"[16, 2, 4]",1.52381,3230
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.816,0,6939292709109.399,1,7,44,67,12556,7,kernel,0,"[64, 4, 1]",3.047619,3230
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.728,16384,6939292709112.952,1,7,57,51,12573,7,kernel,0,"[16, 16, 1]",3.047619,3234
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939292709127.447,1,7,48,0,12586,7,kernel,0,"[1, 1, 1]",0.011905,3238
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.752,0,6939292709774.583,1,7,22,20,12619,7,kernel,0,"[200, 1, 1]",2.380952,3259
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.656,0,6939292709778.039,1,7,22,20,12633,7,kernel,0,"[200, 1, 1]",2.380952,3264
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.584,16384,6939292709781.463,1,7,57,44,12658,7,kernel,0,"[4, 2, 28]",2.666667,3274
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.456,0,6939292709797.847,1,7,44,25,12660,7,kernel,0,"[16, 4, 1]",0.761905,3274
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.984,16384,6939292709802.135,1,7,57,51,12677,7,kernel,0,"[16, 16, 1]",3.047619,3278
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.552,16,6939292709816.887,1,7,48,0,12690,7,kernel,0,"[4, 1, 1]",0.047619,3282
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292709825.271,1,7,22,5,12713,7,kernel,0,"[50, 1, 1]",0.595238,3301
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939292709827.735,1,7,40,5,12748,7,kernel,0,"[50, 1, 1]",0.595238,3304
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939292709831.351,1,7,38,0,12750,7,kernel,0,"[2, 1, 1]",0.02381,3304
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939292710030.583,1,7,22,5,12779,7,kernel,0,"[50, 1, 1]",0.595238,3320
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.848,25600,6939292710439.35,1,7,80,6,12809,7,kernel,0,"[8, 1, 8]",0.761905,3332
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.368,0,6939292710446.934,1,7,44,25,12810,7,kernel,0,"[16, 4, 1]",0.761905,3332
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939292710450.102,1,7,80,6,12832,7,kernel,0,"[64, 1, 1]",0.761905,3336
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939292710457.046,1,7,48,0,12844,7,kernel,0,"[1, 1, 1]",0.011905,3340
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939292710881.11,1,7,22,5,12907,7,kernel,0,"[50, 1, 1]",0.595238,3382
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292710883.958,1,7,32,10,12921,7,kernel,0,"[25, 1, 1]",0.297619,3383
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292710888.246,1,7,16,0,12934,7,kernel,0,"[2, 1, 1]",0.02381,3391
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.608,53504,6939292710891.062,1,7,236,0,12948,7,kernel,0,"[1, 8, 1]",0.095238,3376
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939292711335.317,1,7,16,10,13006,7,kernel,0,"[100, 1, 1]",1.190476,3441
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939292711340.565,1,7,16,10,13031,7,kernel,0,"[100, 1, 1]",1.190476,3451
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939292711344.949,1,7,22,10,13045,7,kernel,0,"[100, 1, 1]",1.190476,3455
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.912,0,6939292711560.181,1,7,16,20,13080,7,kernel,0,"[200, 1, 1]",2.380952,3476
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.376,16384,6939292711744.213,1,7,57,25,13106,7,kernel,0,"[4, 2, 16]",1.52381,3487
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.368,0,6939292711754.357,1,7,44,25,13108,7,kernel,0,"[16, 4, 1]",0.761905,3487
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.128,16384,6939292711757.461,1,7,57,25,13125,7,kernel,0,"[16, 8, 1]",1.52381,3491
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939292711766.389,1,7,48,0,13138,7,kernel,0,"[2, 1, 1]",0.02381,3495
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939292712003.925,1,7,22,5,13157,7,kernel,0,"[50, 1, 1]",0.595238,3506
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.168,25600,6939292712007.061,1,7,80,6,13189,7,kernel,0,"[8, 1, 8]",0.761905,3516
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292712015.029,1,7,44,25,13190,7,kernel,0,"[16, 4, 1]",0.761905,3516
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.176,25600,6939292712211.605,1,7,80,6,13212,7,kernel,0,"[64, 1, 1]",0.761905,3520
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.936,16,6939292712218.516,1,7,48,0,13224,7,kernel,0,"[1, 1, 1]",0.011905,3524
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.113,0,6939292712227.252,1,7,22,5,13239,7,kernel,0,"[50, 1, 1]",0.595238,3535
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.305,0,6939292712422.516,1,7,30,0,13256,7,kernel,0,"[2, 2, 1]",0.047619,3538
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.144,0,6939292712763.028,1,7,30,100,13279,7,kernel,0,"[1024, 2, 1]",24.380953,3545
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.072,16,6939292712969.236,1,7,40,5,13316,7,kernel,0,"[50, 1, 1]",0.595238,3552
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.736,0,6939292712973.364,1,7,38,0,13318,7,kernel,0,"[2, 1, 1]",0.02381,3552
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939292713167.476,1,7,22,5,13347,7,kernel,0,"[50, 1, 1]",0.595238,3568
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.912,25600,6939292713170.324,1,7,80,6,13377,7,kernel,0,"[8, 1, 8]",0.761905,3580
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.488,0,6939292713420.115,1,7,44,25,13378,7,kernel,0,"[16, 4, 1]",0.761905,3580
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.369,25600,6939292713424.403,1,7,80,6,13400,7,kernel,0,"[64, 1, 1]",0.761905,3584
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939292713431.539,1,7,48,0,13412,7,kernel,0,"[1, 1, 1]",0.011905,3588
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292713862.867,1,7,22,5,13475,7,kernel,0,"[50, 1, 1]",0.595238,3630
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292713865.875,1,7,32,10,13489,7,kernel,0,"[25, 1, 1]",0.297619,3631
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939292714053.107,1,7,16,0,13502,7,kernel,0,"[2, 1, 1]",0.02381,3639
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.768,53504,6939292714055.923,1,7,236,0,13516,7,kernel,0,"[1, 8, 1]",0.095238,3624
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.601,0,6939292714507.346,1,7,16,15,13574,7,kernel,0,"[150, 1, 1]",1.785714,3689
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.215,0,6939292714512.819,1,7,16,15,13599,7,kernel,0,"[150, 1, 1]",1.785714,3699
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939292714915.41,1,7,22,15,13613,7,kernel,0,"[150, 1, 1]",1.785714,3703
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939292714919.186,1,7,16,15,13633,7,kernel,0,"[150, 1, 1]",1.785714,3710
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292714923.794,1,7,22,15,13647,7,kernel,0,"[150, 1, 1]",1.785714,3714
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939292714926.29,1,7,16,30,13682,7,kernel,0,"[300, 1, 1]",3.571429,3735
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.088,16384,6939292715112.722,1,7,57,38,13708,7,kernel,0,"[4, 2, 24]",2.285714,3746
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939292715126.642,1,7,44,25,13710,7,kernel,0,"[16, 4, 1]",0.761905,3746
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.48,16384,6939292715130.194,1,7,57,38,13727,7,kernel,0,"[16, 12, 1]",2.285714,3750
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.728,16,6939292715748.177,1,7,48,0,13740,7,kernel,0,"[3, 1, 1]",0.035714,3754
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292715758.705,1,7,22,5,13763,7,kernel,0,"[50, 1, 1]",0.595238,3773
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.944,16,6939292715761.489,1,7,40,5,13798,7,kernel,0,"[50, 1, 1]",0.595238,3776
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939292715765.265,1,7,38,0,13800,7,kernel,0,"[2, 1, 1]",0.02381,3776
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939292715770.481,1,7,22,5,13829,7,kernel,0,"[50, 1, 1]",0.595238,3792
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.672,16384,6939292715772.913,1,7,57,25,13855,7,kernel,0,"[16, 2, 4]",1.52381,3804
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939292715790.353,1,7,44,67,13857,7,kernel,0,"[64, 4, 1]",3.047619,3804
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",16.128,16384,6939292716237.041,1,7,57,51,13874,7,kernel,0,"[16, 16, 1]",3.047619,3808
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939292716253.969,1,7,48,0,13887,7,kernel,0,"[1, 1, 1]",0.011905,3812
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.232,0,6939292716262.577,1,7,22,20,13920,7,kernel,0,"[200, 1, 1]",2.380952,3833
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.88,0,6939292716266.641,1,7,22,20,13934,7,kernel,0,"[200, 1, 1]",2.380952,3838
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.096,16384,6939292716270.225,1,7,57,44,13959,7,kernel,0,"[4, 2, 28]",2.666667,3848
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.392,0,6939292716287.153,1,7,44,25,13961,7,kernel,0,"[16, 4, 1]",0.761905,3848
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.232,16384,6939292716291.281,1,7,57,51,13978,7,kernel,0,"[16, 16, 1]",3.047619,3852
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.472,16,6939292717177.808,1,7,48,0,13991,7,kernel,0,"[4, 1, 1]",0.047619,3856
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292717187.984,1,7,22,5,14014,7,kernel,0,"[50, 1, 1]",0.595238,3875
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939292717190.8,1,7,40,5,14049,7,kernel,0,"[50, 1, 1]",0.595238,3878
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939292717194.416,1,7,38,0,14051,7,kernel,0,"[2, 1, 1]",0.02381,3878
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292717199.632,1,7,22,5,14080,7,kernel,0,"[50, 1, 1]",0.595238,3894
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939292717202.032,1,7,80,6,14110,7,kernel,0,"[8, 1, 8]",0.761905,3906
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939292717209.872,1,7,44,25,14111,7,kernel,0,"[16, 4, 1]",0.761905,3906
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939292717212.72,1,7,80,6,14133,7,kernel,0,"[64, 1, 1]",0.761905,3910
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.496,16,6939292717219.632,1,7,48,0,14145,7,kernel,0,"[1, 1, 1]",0.011905,3914
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939292718080.015,1,7,22,5,14208,7,kernel,0,"[50, 1, 1]",0.595238,3956
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292718082.831,1,7,32,10,14222,7,kernel,0,"[25, 1, 1]",0.297619,3957
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292718087.087,1,7,16,0,14235,7,kernel,0,"[2, 1, 1]",0.02381,3965
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.448,53504,6939292718089.903,1,7,236,0,14249,7,kernel,0,"[1, 8, 1]",0.095238,3950
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.056,0,6939292718127.375,1,7,16,10,14307,7,kernel,0,"[100, 1, 1]",1.190476,4015
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.152,0,6939292718131.343,1,7,16,10,14332,7,kernel,0,"[100, 1, 1]",1.190476,4025
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939292718135.375,1,7,22,10,14346,7,kernel,0,"[100, 1, 1]",1.190476,4029
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.976,0,6939292719854.189,1,7,16,20,14381,7,kernel,0,"[200, 1, 1]",2.380952,4050
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.985,16384,6939292719857.933,1,7,57,25,14407,7,kernel,0,"[4, 2, 16]",1.52381,4061
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.368,0,6939292719868.685,1,7,44,25,14409,7,kernel,0,"[16, 4, 1]",0.761905,4061
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.096,16384,6939292719872.077,1,7,57,25,14426,7,kernel,0,"[16, 8, 1]",1.52381,4065
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939292719881.006,1,7,48,0,14439,7,kernel,0,"[2, 1, 1]",0.02381,4069
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292719889.742,1,7,22,5,14454,7,kernel,0,"[50, 1, 1]",0.595238,4080
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939292719892.205,1,7,80,6,14486,7,kernel,0,"[8, 1, 8]",0.761905,4090
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.952,0,6939292719900.173,1,7,44,25,14487,7,kernel,0,"[16, 4, 1]",0.761905,4090
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.049,25600,6939292719902.989,1,7,80,6,14509,7,kernel,0,"[64, 1, 1]",0.761905,4094
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.144,16,6939292719909.773,1,7,48,0,14521,7,kernel,0,"[1, 1, 1]",0.011905,4098
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292719916.685,1,7,22,5,14536,7,kernel,0,"[50, 1, 1]",0.595238,4109
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",1.985,0,6939292719919.437,1,7,30,0,14553,7,kernel,0,"[2, 2, 1]",0.047619,4112
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",9.184,0,6939292719922.221,1,7,30,100,14572,7,kernel,0,"[1024, 2, 1]",24.380953,4119
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939292719932.205,1,7,40,5,14609,7,kernel,0,"[50, 1, 1]",0.595238,4126
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939292719935.789,1,7,38,0,14611,7,kernel,0,"[2, 1, 1]",0.02381,4126
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939292719940.941,1,7,22,5,14640,7,kernel,0,"[50, 1, 1]",0.595238,4142
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.688,25600,6939292719943.437,1,7,80,6,14670,7,kernel,0,"[8, 1, 8]",0.761905,4154
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.015,0,6939292719950.958,1,7,44,25,14671,7,kernel,0,"[16, 4, 1]",0.761905,4154
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.888,25600,6939292719953.805,1,7,80,6,14693,7,kernel,0,"[64, 1, 1]",0.761905,4158
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.745,16,6939292719960.525,1,7,48,0,14705,7,kernel,0,"[1, 1, 1]",0.011905,4162
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939292720266.157,1,7,22,5,14768,7,kernel,0,"[50, 1, 1]",0.595238,4204
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292720269.101,1,7,32,10,14782,7,kernel,0,"[25, 1, 1]",0.297619,4205
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939292720466.573,1,7,16,0,14795,7,kernel,0,"[2, 1, 1]",0.02381,4213
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.312,53504,6939292720469.741,1,7,236,0,14809,7,kernel,0,"[1, 8, 1]",0.095238,4198
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.601,0,6939292720805.484,1,7,16,15,14867,7,kernel,0,"[150, 1, 1]",1.785714,4263
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.599,0,6939292721019.341,1,7,16,15,14892,7,kernel,0,"[150, 1, 1]",1.785714,4273
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.624,0,6939292721024.556,1,7,22,15,14906,7,kernel,0,"[150, 1, 1]",1.785714,4277
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292721028.012,1,7,16,15,14926,7,kernel,0,"[150, 1, 1]",1.785714,4284
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939292721228.14,1,7,22,15,14940,7,kernel,0,"[150, 1, 1]",1.785714,4288
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.528,0,6939292721231.98,1,7,16,30,14975,7,kernel,0,"[300, 1, 1]",3.571429,4309
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.536,16384,6939292721447.404,1,7,57,38,15001,7,kernel,0,"[4, 2, 24]",2.285714,4320
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.296,0,6939292721461.676,1,7,44,25,15003,7,kernel,0,"[16, 4, 1]",0.761905,4320
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.224,16384,6939292721465.772,1,7,57,38,15020,7,kernel,0,"[16, 12, 1]",2.285714,4324
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.889,16,6939292721824.043,1,7,48,0,15033,7,kernel,0,"[3, 1, 1]",0.035714,4328
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.336,0,6939292721834.731,1,7,22,5,15056,7,kernel,0,"[50, 1, 1]",0.595238,4347
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.04,16,6939292721837.836,1,7,40,5,15091,7,kernel,0,"[50, 1, 1]",0.595238,4350
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939292721841.74,1,7,38,0,15093,7,kernel,0,"[2, 1, 1]",0.02381,4350
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939292722176.395,1,7,22,5,15122,7,kernel,0,"[50, 1, 1]",0.595238,4366
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.311,16384,6939292722179.468,1,7,57,25,15148,7,kernel,0,"[16, 2, 4]",1.52381,4378
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939292722197.515,1,7,44,67,15150,7,kernel,0,"[64, 4, 1]",3.047619,4378
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.616,16384,6939292723591.818,1,7,57,51,15171,7,kernel,0,"[16, 16, 1]",3.047619,4382
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.096,16,6939292723608.202,1,7,48,0,15184,7,kernel,0,"[1, 1, 1]",0.011905,4386
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.232,0,6939292723617.066,1,7,22,20,15217,7,kernel,0,"[200, 1, 1]",2.380952,4407
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.168,0,6939292723621.098,1,7,22,20,15231,7,kernel,0,"[200, 1, 1]",2.380952,4412
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.448,16384,6939292723625.002,1,7,57,44,15256,7,kernel,0,"[4, 2, 28]",2.666667,4422
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.616,0,6939292723642.154,1,7,44,25,15258,7,kernel,0,"[16, 4, 1]",0.761905,4422
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.624,16384,6939292723646.602,1,7,57,51,15275,7,kernel,0,"[16, 16, 1]",3.047619,4426
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.976,16,6939292723662.058,1,7,48,0,15288,7,kernel,0,"[4, 1, 1]",0.047619,4430
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292723669.77,1,7,22,5,15311,7,kernel,0,"[50, 1, 1]",0.595238,4449
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939292723672.394,1,7,40,5,15346,7,kernel,0,"[50, 1, 1]",0.595238,4452
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939292723676.17,1,7,38,0,15348,7,kernel,0,"[2, 1, 1]",0.02381,4452
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939292723681.386,1,7,22,5,15377,7,kernel,0,"[50, 1, 1]",0.595238,4468
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939292723683.69,1,7,80,6,15407,7,kernel,0,"[8, 1, 8]",0.761905,4480
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939292723691.53,1,7,44,25,15408,7,kernel,0,"[16, 4, 1]",0.761905,4480
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939292723694.346,1,7,80,6,15430,7,kernel,0,"[64, 1, 1]",0.761905,4484
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.304,16,6939292723937.802,1,7,48,0,15442,7,kernel,0,"[1, 1, 1]",0.011905,4488
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939292724170.825,1,7,22,5,15505,7,kernel,0,"[50, 1, 1]",0.595238,4530
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292724173.706,1,7,32,10,15519,7,kernel,0,"[25, 1, 1]",0.297619,4531
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292724177.994,1,7,16,0,15532,7,kernel,0,"[2, 1, 1]",0.02381,4539
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.768,53504,6939292724372.201,1,7,236,0,15546,7,kernel,0,"[1, 8, 1]",0.095238,4524
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.504,0,6939292724667.689,1,7,16,10,15604,7,kernel,0,"[100, 1, 1]",1.190476,4589
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939292724874.057,1,7,16,10,15629,7,kernel,0,"[100, 1, 1]",1.190476,4599
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939292724879.497,1,7,22,10,15643,7,kernel,0,"[100, 1, 1]",1.190476,4603
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939292725207.849,1,7,16,20,15678,7,kernel,0,"[200, 1, 1]",2.380952,4624
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.952,16384,6939292725211.88,1,7,57,25,15704,7,kernel,0,"[4, 2, 16]",1.52381,4635
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",5.568,0,6939292725597.192,1,7,44,25,15706,7,kernel,0,"[16, 4, 1]",0.761905,4635
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",9.12,16384,6939292725603.624,1,7,57,25,15723,7,kernel,0,"[16, 8, 1]",1.52381,4639
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939292725613.576,1,7,48,0,15736,7,kernel,0,"[2, 1, 1]",0.02381,4643
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939292725622.152,1,7,22,5,15751,7,kernel,0,"[50, 1, 1]",0.595238,4654
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.104,25600,6939292725624.808,1,7,80,6,15783,7,kernel,0,"[8, 1, 8]",0.761905,4664
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939292725632.744,1,7,44,25,15784,7,kernel,0,"[16, 4, 1]",0.761905,4664
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939292725838.376,1,7,80,6,15806,7,kernel,0,"[64, 1, 1]",0.761905,4668
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939292725845.512,1,7,48,0,15818,7,kernel,0,"[1, 1, 1]",0.011905,4672
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292725853.928,1,7,22,5,15833,7,kernel,0,"[50, 1, 1]",0.595238,4683
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.368,0,6939292726919.623,1,7,30,0,15850,7,kernel,0,"[2, 2, 1]",0.047619,4686
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.008,0,6939292726922.727,1,7,30,100,15869,7,kernel,0,"[1024, 2, 1]",24.380953,4693
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.136,16,6939292726934.535,1,7,40,5,15906,7,kernel,0,"[50, 1, 1]",0.595238,4700
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939292726938.439,1,7,38,0,15908,7,kernel,0,"[2, 1, 1]",0.02381,4700
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939292726943.623,1,7,22,5,15937,7,kernel,0,"[50, 1, 1]",0.595238,4716
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.104,25600,6939292726946.279,1,7,80,6,15967,7,kernel,0,"[8, 1, 8]",0.761905,4728
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292726954.151,1,7,44,25,15968,7,kernel,0,"[16, 4, 1]",0.761905,4728
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939292726956.999,1,7,80,6,15990,7,kernel,0,"[64, 1, 1]",0.761905,4732
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939292726963.847,1,7,48,0,16002,7,kernel,0,"[1, 1, 1]",0.011905,4736
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939292726972.455,1,7,22,5,16065,7,kernel,0,"[50, 1, 1]",0.595238,4778
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.36,16,6939292726975.047,1,7,32,10,16079,7,kernel,0,"[25, 1, 1]",0.297619,4779
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939292726979.175,1,7,16,0,16092,7,kernel,0,"[2, 1, 1]",0.02381,4787
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.545,53504,6939292727216.358,1,7,236,0,16106,7,kernel,0,"[1, 8, 1]",0.095238,4772
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.632,0,6939292727567.462,1,7,16,15,16164,7,kernel,0,"[150, 1, 1]",1.785714,4837
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292727572.71,1,7,16,15,16189,7,kernel,0,"[150, 1, 1]",1.785714,4847
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.88,0,6939292727794.246,1,7,22,15,16203,7,kernel,0,"[150, 1, 1]",1.785714,4851
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939292727797.99,1,7,16,15,16223,7,kernel,0,"[150, 1, 1]",1.785714,4858
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292727802.886,1,7,22,15,16237,7,kernel,0,"[150, 1, 1]",1.785714,4862
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.104,0,6939292728025.414,1,7,16,30,16272,7,kernel,0,"[300, 1, 1]",3.571429,4883
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.536,16384,6939292728047.494,1,7,57,38,16298,7,kernel,0,"[4, 2, 24]",2.285714,4894
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939292728061.798,1,7,44,25,16300,7,kernel,0,"[16, 4, 1]",0.761905,4894
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.704,16384,6939292728119.462,1,7,57,38,16317,7,kernel,0,"[16, 12, 1]",2.285714,4898
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.729,16,6939292728336.773,1,7,48,0,16330,7,kernel,0,"[3, 1, 1]",0.035714,4902
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.079,0,6939292728542.214,1,7,22,5,16353,7,kernel,0,"[50, 1, 1]",0.595238,4921
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.073,16,6939292728545.125,1,7,40,5,16388,7,kernel,0,"[50, 1, 1]",0.595238,4924
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.352,0,6939292728549.029,1,7,38,0,16390,7,kernel,0,"[2, 1, 1]",0.02381,4924
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939292728765.733,1,7,22,5,16419,7,kernel,0,"[50, 1, 1]",0.595238,4940
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.96,16384,6939292728768.485,1,7,57,25,16445,7,kernel,0,"[16, 2, 4]",1.52381,4952
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.88,0,6939292728786.213,1,7,44,67,16447,7,kernel,0,"[64, 4, 1]",3.047619,4952
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.696,16384,6939292728789.893,1,7,57,51,16464,7,kernel,0,"[16, 16, 1]",3.047619,4956
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.984,16,6939292729255.973,1,7,48,0,16477,7,kernel,0,"[1, 1, 1]",0.011905,4960
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.912,0,6939292729266.821,1,7,22,20,16510,7,kernel,0,"[200, 1, 1]",2.380952,4981
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.784,0,6939292729270.437,1,7,22,20,16524,7,kernel,0,"[200, 1, 1]",2.380952,4986
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.416,16384,6939292729273.925,1,7,57,44,16549,7,kernel,0,"[4, 2, 28]",2.666667,4996
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.52,0,6939292729291.141,1,7,44,25,16551,7,kernel,0,"[16, 4, 1]",0.761905,4996
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.776,16384,6939292731377.667,1,7,57,51,16572,7,kernel,0,"[16, 16, 1]",3.047619,5000
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939292731394.147,1,7,48,0,16585,7,kernel,0,"[4, 1, 1]",0.047619,5004
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.92,0,6939292731402.818,1,7,22,5,16608,7,kernel,0,"[50, 1, 1]",0.595238,5023
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939292731405.571,1,7,40,5,16643,7,kernel,0,"[50, 1, 1]",0.595238,5026
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939292731409.187,1,7,38,0,16645,7,kernel,0,"[2, 1, 1]",0.02381,5026
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939292731414.339,1,7,22,5,16674,7,kernel,0,"[50, 1, 1]",0.595238,5042
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.912,25600,6939292731416.835,1,7,80,6,16704,7,kernel,0,"[8, 1, 8]",0.761905,5054
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.047,0,6939292731424.515,1,7,44,25,16705,7,kernel,0,"[16, 4, 1]",0.761905,5054
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.047,25600,6939292731427.363,1,7,80,6,16727,7,kernel,0,"[64, 1, 1]",0.761905,5058
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.305,16,6939292731434.242,1,7,48,0,16739,7,kernel,0,"[1, 1, 1]",0.011905,5062
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.408,0,6939292731441.347,1,7,22,5,16802,7,kernel,0,"[50, 1, 1]",0.595238,5104
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939292731443.555,1,7,32,10,16816,7,kernel,0,"[25, 1, 1]",0.297619,5105
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292731447.811,1,7,16,0,16829,7,kernel,0,"[2, 1, 1]",0.02381,5113
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.64,53504,6939292731450.627,1,7,236,0,16843,7,kernel,0,"[1, 8, 1]",0.095238,5098
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.927,0,6939292731488.291,1,7,16,10,16901,7,kernel,0,"[100, 1, 1]",1.190476,5163
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.183,0,6939292731492.099,1,7,16,10,16926,7,kernel,0,"[100, 1, 1]",1.190476,5173
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.496,0,6939292731726.978,1,7,22,10,16940,7,kernel,0,"[100, 1, 1]",1.190476,5177
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.464,0,6939292731730.274,1,7,16,20,16975,7,kernel,0,"[200, 1, 1]",2.380952,5198
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",11.744,16384,6939292732018.722,1,7,57,25,17001,7,kernel,0,"[4, 2, 16]",1.52381,5209
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.656,0,6939292732031.234,1,7,44,25,17003,7,kernel,0,"[16, 4, 1]",0.761905,5209
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.096,16384,6939292732034.626,1,7,57,25,17020,7,kernel,0,"[16, 8, 1]",1.52381,5213
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939292732043.426,1,7,48,0,17033,7,kernel,0,"[2, 1, 1]",0.02381,5217
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292732259.01,1,7,22,5,17048,7,kernel,0,"[50, 1, 1]",0.595238,5228
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.392,25600,6939292732261.858,1,7,80,6,17080,7,kernel,0,"[8, 1, 8]",0.761905,5238
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292732270.018,1,7,44,25,17081,7,kernel,0,"[16, 4, 1]",0.761905,5238
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939292732272.866,1,7,80,6,17103,7,kernel,0,"[64, 1, 1]",0.761905,5242
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.272,16,6939292732490.402,1,7,48,0,17115,7,kernel,0,"[1, 1, 1]",0.011905,5246
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939292732501.442,1,7,22,5,17130,7,kernel,0,"[50, 1, 1]",0.595238,5257
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.208,0,6939292732504.386,1,7,30,0,17147,7,kernel,0,"[2, 2, 1]",0.047619,5260
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.168,0,6939292732721.921,1,7,30,100,17166,7,kernel,0,"[1024, 2, 1]",24.380953,5267
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.296,16,6939292732733.825,1,7,40,5,17203,7,kernel,0,"[50, 1, 1]",0.595238,5274
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.417,0,6939292732737.889,1,7,38,0,17205,7,kernel,0,"[2, 1, 1]",0.02381,5274
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939292732955.361,1,7,22,5,17234,7,kernel,0,"[50, 1, 1]",0.595238,5290
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.168,25600,6939292733568.801,1,7,80,6,17264,7,kernel,0,"[8, 1, 8]",0.761905,5302
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.304,0,6939292733576.737,1,7,44,25,17265,7,kernel,0,"[16, 4, 1]",0.761905,5302
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.111,25600,6939292733579.873,1,7,80,6,17287,7,kernel,0,"[64, 1, 1]",0.761905,5306
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939292733586.721,1,7,48,0,17299,7,kernel,0,"[1, 1, 1]",0.011905,5310
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939292733595.329,1,7,22,5,17362,7,kernel,0,"[50, 1, 1]",0.595238,5352
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.329,16,6939292733597.536,1,7,32,10,17376,7,kernel,0,"[25, 1, 1]",0.297619,5353
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939292733601.665,1,7,16,0,17389,7,kernel,0,"[2, 1, 1]",0.02381,5361
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.864,53504,6939292734258.176,1,7,236,0,17403,7,kernel,0,"[1, 8, 1]",0.095238,5346
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939292734295.872,1,7,16,15,17461,7,kernel,0,"[150, 1, 1]",1.785714,5411
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292734300.448,1,7,16,15,17486,7,kernel,0,"[150, 1, 1]",1.785714,5421
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292734304.96,1,7,22,15,17500,7,kernel,0,"[150, 1, 1]",1.785714,5425
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292734307.424,1,7,16,15,17520,7,kernel,0,"[150, 1, 1]",1.785714,5432
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.199,0,6939292734784.256,1,7,22,15,17534,7,kernel,0,"[150, 1, 1]",1.785714,5436
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.56,0,6939292734788.224,1,7,16,30,17569,7,kernel,0,"[300, 1, 1]",3.571429,5457
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.505,16384,6939292734791.519,1,7,57,38,17595,7,kernel,0,"[4, 2, 24]",2.285714,5468
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.753,0,6939292734805.791,1,7,44,25,17597,7,kernel,0,"[16, 4, 1]",0.761905,5468
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.511,16384,6939292734809.376,1,7,57,38,17614,7,kernel,0,"[16, 12, 1]",2.285714,5472
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939292734822.687,1,7,48,0,17627,7,kernel,0,"[3, 1, 1]",0.035714,5476
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292735061.503,1,7,22,5,17650,7,kernel,0,"[50, 1, 1]",0.595238,5495
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.232,16,6939292735064.415,1,7,40,5,17685,7,kernel,0,"[50, 1, 1]",0.595238,5498
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939292735068.447,1,7,38,0,17687,7,kernel,0,"[2, 1, 1]",0.02381,5498
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939292735398.815,1,7,22,5,17716,7,kernel,0,"[50, 1, 1]",0.595238,5514
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.088,16384,6939292735401.695,1,7,57,25,17742,7,kernel,0,"[16, 2, 4]",1.52381,5526
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939292735419.487,1,7,44,67,17744,7,kernel,0,"[64, 4, 1]",3.047619,5526
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.728,16384,6939292735423.199,1,7,57,51,17761,7,kernel,0,"[16, 16, 1]",3.047619,5530
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.76,16,6939292735714.271,1,7,48,0,17774,7,kernel,0,"[1, 1, 1]",0.011905,5534
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.881,0,6939292735724.862,1,7,22,20,17807,7,kernel,0,"[200, 1, 1]",2.380952,5555
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.137,0,6939292735728.51,1,7,22,20,17821,7,kernel,0,"[200, 1, 1]",2.380952,5560
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.087,16384,6939292735969.055,1,7,57,44,17846,7,kernel,0,"[4, 2, 28]",2.666667,5570
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.68,0,6939292735986.942,1,7,44,25,17848,7,kernel,0,"[16, 4, 1]",0.761905,5570
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.176,16384,6939292735991.39,1,7,57,51,17865,7,kernel,0,"[16, 16, 1]",3.047619,5574
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.616,16,6939292736006.334,1,7,48,0,17878,7,kernel,0,"[4, 1, 1]",0.047619,5578
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292736223.806,1,7,22,5,17901,7,kernel,0,"[50, 1, 1]",0.595238,5597
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939292736226.75,1,7,40,5,17936,7,kernel,0,"[50, 1, 1]",0.595238,5600
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939292736230.91,1,7,38,0,17938,7,kernel,0,"[2, 1, 1]",0.02381,5600
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939292736449.278,1,7,22,5,17967,7,kernel,0,"[50, 1, 1]",0.595238,5616
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.232,25600,6939292736452.254,1,7,80,6,17997,7,kernel,0,"[8, 1, 8]",0.761905,5628
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939292736460.286,1,7,44,25,17998,7,kernel,0,"[16, 4, 1]",0.761905,5628
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939292736662.782,1,7,80,6,18020,7,kernel,0,"[64, 1, 1]",0.761905,5632
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.192,16,6939292736669.662,1,7,48,0,18032,7,kernel,0,"[1, 1, 1]",0.011905,5636
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939292737282.269,1,7,22,5,18095,7,kernel,0,"[50, 1, 1]",0.595238,5678
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939292737285.309,1,7,32,10,18109,7,kernel,0,"[25, 1, 1]",0.297619,5679
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292737289.597,1,7,16,0,18122,7,kernel,0,"[2, 1, 1]",0.02381,5687
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.992,53504,6939292737292.413,1,7,236,0,18136,7,kernel,0,"[1, 8, 1]",0.095238,5672
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939292737870.717,1,7,16,10,18194,7,kernel,0,"[100, 1, 1]",1.190476,5737
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939292737876.349,1,7,16,10,18219,7,kernel,0,"[100, 1, 1]",1.190476,5747
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939292737880.925,1,7,22,10,18233,7,kernel,0,"[100, 1, 1]",1.190476,5751
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.944,0,6939292738134.941,1,7,16,20,18268,7,kernel,0,"[200, 1, 1]",2.380952,5772
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.592,16384,6939292738138.684,1,7,57,25,18294,7,kernel,0,"[4, 2, 16]",1.52381,5783
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939292738150.044,1,7,44,25,18296,7,kernel,0,"[16, 4, 1]",0.761905,5783
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.128,16384,6939292738153.148,1,7,57,25,18313,7,kernel,0,"[16, 8, 1]",1.52381,5787
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.984,16,6939292738598.844,1,7,48,0,18326,7,kernel,0,"[2, 1, 1]",0.02381,5791
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.4,0,6939292738609.628,1,7,22,5,18341,7,kernel,0,"[50, 1, 1]",0.595238,5802
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.944,25600,6939292738612.764,1,7,80,6,18373,7,kernel,0,"[8, 1, 8]",0.761905,5812
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939292738620.444,1,7,44,25,18374,7,kernel,0,"[16, 4, 1]",0.761905,5812
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939292738623.292,1,7,80,6,18396,7,kernel,0,"[64, 1, 1]",0.761905,5816
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.144,16,6939292738630.14,1,7,48,0,18408,7,kernel,0,"[1, 1, 1]",0.011905,5820
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.432,0,6939292738853.148,1,7,22,5,18423,7,kernel,0,"[50, 1, 1]",0.595238,5831
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.368,0,6939292738856.316,1,7,30,0,18440,7,kernel,0,"[2, 2, 1]",0.047619,5834
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.296,0,6939292739144.284,1,7,30,100,18463,7,kernel,0,"[1024, 2, 1]",24.380953,5841
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939292739433.979,1,7,40,5,18500,7,kernel,0,"[50, 1, 1]",0.595238,5848
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.704,0,6939292739437.723,1,7,38,0,18502,7,kernel,0,"[2, 1, 1]",0.02381,5848
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939292739443.259,1,7,22,5,18531,7,kernel,0,"[50, 1, 1]",0.595238,5864
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.744,25600,6939292739681.979,1,7,80,6,18561,7,kernel,0,"[8, 1, 8]",0.761905,5876
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.272,0,6939292739690.555,1,7,44,25,18562,7,kernel,0,"[16, 4, 1]",0.761905,5876
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939292739693.563,1,7,80,6,18584,7,kernel,0,"[64, 1, 1]",0.761905,5880
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939292739700.315,1,7,48,0,18596,7,kernel,0,"[1, 1, 1]",0.011905,5884
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292740107.803,1,7,22,5,18659,7,kernel,0,"[50, 1, 1]",0.595238,5926
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292740111.066,1,7,32,10,18673,7,kernel,0,"[25, 1, 1]",0.297619,5927
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.464,0,6939292740327.322,1,7,16,0,18686,7,kernel,0,"[2, 1, 1]",0.02381,5935
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.024,53504,6939292740330.65,1,7,236,0,18700,7,kernel,0,"[1, 8, 1]",0.095238,5920
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939292740971.482,1,7,16,15,18758,7,kernel,0,"[150, 1, 1]",1.785714,5985
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292740976.954,1,7,16,15,18783,7,kernel,0,"[150, 1, 1]",1.785714,5995
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292740981.786,1,7,22,15,18797,7,kernel,0,"[150, 1, 1]",1.785714,5999
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292740984.25,1,7,16,15,18817,7,kernel,0,"[150, 1, 1]",1.785714,6006
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292740988.666,1,7,22,15,18831,7,kernel,0,"[150, 1, 1]",1.785714,6010
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.424,0,6939292743374.36,1,7,16,30,18866,7,kernel,0,"[300, 1, 1]",3.571429,6031
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.696,16384,6939292743378.584,1,7,57,38,18892,7,kernel,0,"[4, 2, 24]",2.285714,6042
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939292743393.271,1,7,44,25,18894,7,kernel,0,"[16, 4, 1]",0.761905,6042
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.416,16384,6939292743396.76,1,7,57,38,18911,7,kernel,0,"[16, 12, 1]",2.285714,6046
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939292743409.911,1,7,48,0,18924,7,kernel,0,"[3, 1, 1]",0.035714,6050
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939292743418.487,1,7,22,5,18947,7,kernel,0,"[50, 1, 1]",0.595238,6069
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.849,16,6939292743421.079,1,7,40,5,18982,7,kernel,0,"[50, 1, 1]",0.595238,6072
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.449,0,6939292743424.631,1,7,38,0,18984,7,kernel,0,"[2, 1, 1]",0.02381,6072
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.657,16,6939292743429.815,1,7,40,5,19025,7,kernel,0,"[50, 1, 1]",0.595238,6086
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.385,0,6939292743433.239,1,7,38,0,19027,7,kernel,0,"[2, 1, 1]",0.02381,6086
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.793,0,6939292743438.423,1,7,22,5,19056,7,kernel,0,"[50, 1, 1]",0.595238,6102
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.616,16384,6939292743441.048,1,7,57,25,19082,7,kernel,0,"[16, 2, 4]",1.52381,6114
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.073,0,6939292743457.463,1,7,44,67,19084,7,kernel,0,"[64, 4, 1]",3.047619,6114
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.913,16384,6939292743461.239,1,7,57,51,19101,7,kernel,0,"[16, 16, 1]",3.047619,6118
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.079,16,6939292743477.016,1,7,48,0,19114,7,kernel,0,"[1, 1, 1]",0.011905,6122
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.529,0,6939292743483.895,1,7,22,20,19147,7,kernel,0,"[200, 1, 1]",2.380952,6143
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.944,0,6939292743487.191,1,7,22,20,19161,7,kernel,0,"[200, 1, 1]",2.380952,6148
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.072,16384,6939292743490.967,1,7,57,44,19186,7,kernel,0,"[4, 2, 28]",2.666667,6158
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.232,0,6939292743506.871,1,7,44,25,19188,7,kernel,0,"[16, 4, 1]",0.761905,6158
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.176,16384,6939292743510.903,1,7,57,51,19205,7,kernel,0,"[16, 16, 1]",3.047619,6162
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.624,16,6939292743525.815,1,7,48,0,19218,7,kernel,0,"[4, 1, 1]",0.047619,6166
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.855,0,6939292743533.272,1,7,22,5,19241,7,kernel,0,"[50, 1, 1]",0.595238,6185
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.689,16,6939292743535.895,1,7,40,5,19276,7,kernel,0,"[50, 1, 1]",0.595238,6188
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939292743539.319,1,7,38,0,19278,7,kernel,0,"[2, 1, 1]",0.02381,6188
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292743544.503,1,7,22,5,19307,7,kernel,0,"[50, 1, 1]",0.595238,6204
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.944,25600,6939292743546.999,1,7,80,6,19337,7,kernel,0,"[8, 1, 8]",0.761905,6216
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939292743554.679,1,7,44,25,19338,7,kernel,0,"[16, 4, 1]",0.761905,6216
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.984,25600,6939292743557.495,1,7,80,6,19360,7,kernel,0,"[64, 1, 1]",0.761905,6220
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.591,16,6939292743564.28,1,7,48,0,19372,7,kernel,0,"[1, 1, 1]",0.011905,6224
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939292745865.141,1,7,22,5,19435,7,kernel,0,"[50, 1, 1]",0.595238,6266
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939292745868.341,1,7,32,10,19449,7,kernel,0,"[25, 1, 1]",0.297619,6267
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.952,0,6939292745872.597,1,7,16,0,19462,7,kernel,0,"[2, 1, 1]",0.02381,6275
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.672,53504,6939292745875.381,1,7,236,0,19476,7,kernel,0,"[1, 8, 1]",0.095238,6260
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.088,0,6939292745912.981,1,7,16,15,19534,7,kernel,0,"[150, 1, 1]",1.785714,6325
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292745917.109,1,7,16,15,19559,7,kernel,0,"[150, 1, 1]",1.785714,6335
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292745921.461,1,7,22,15,19573,7,kernel,0,"[150, 1, 1]",1.785714,6339
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292745923.925,1,7,16,15,19593,7,kernel,0,"[150, 1, 1]",1.785714,6346
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292745928.021,1,7,22,15,19607,7,kernel,0,"[150, 1, 1]",1.785714,6350
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939292745930.517,1,7,16,30,19642,7,kernel,0,"[300, 1, 1]",3.571429,6371
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.864,16384,6939292745933.461,1,7,57,38,19668,7,kernel,0,"[4, 2, 24]",2.285714,6382
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.912,0,6939292745947.093,1,7,44,25,19670,7,kernel,0,"[16, 4, 1]",0.761905,6382
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.84,16384,6939292745950.709,1,7,57,38,19687,7,kernel,0,"[16, 12, 1]",2.285714,6386
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.552,16,6939292745963.317,1,7,48,0,19700,7,kernel,0,"[3, 1, 1]",0.035714,6390
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292745971.733,1,7,22,5,19723,7,kernel,0,"[50, 1, 1]",0.595238,6409
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939292745974.293,1,7,40,5,19758,7,kernel,0,"[50, 1, 1]",0.595238,6412
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939292745977.909,1,7,38,0,19760,7,kernel,0,"[2, 1, 1]",0.02381,6412
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939292745983.125,1,7,22,5,19789,7,kernel,0,"[50, 1, 1]",0.595238,6428
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.68,16384,6939292745985.589,1,7,57,25,19815,7,kernel,0,"[16, 2, 4]",1.52381,6440
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939292746001.973,1,7,44,67,19817,7,kernel,0,"[64, 4, 1]",3.047619,6440
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.112,16384,6939292746005.621,1,7,57,51,19838,7,kernel,0,"[16, 16, 1]",3.047619,6444
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.824,16,6939292748382.483,1,7,48,0,19851,7,kernel,0,"[1, 1, 1]",0.011905,6448
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.816,0,6939292748393.171,1,7,22,20,19884,7,kernel,0,"[200, 1, 1]",2.380952,6469
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.848,0,6939292748396.691,1,7,22,20,19898,7,kernel,0,"[200, 1, 1]",2.380952,6474
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.896,16384,6939292748400.307,1,7,57,44,19923,7,kernel,0,"[4, 2, 28]",2.666667,6484
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.328,0,6939292748417.939,1,7,44,25,19925,7,kernel,0,"[16, 4, 1]",0.761905,6484
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.2,16384,6939292748422.003,1,7,57,51,19942,7,kernel,0,"[16, 16, 1]",3.047619,6488
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.008,16,6939292748438.003,1,7,48,0,19955,7,kernel,0,"[4, 1, 1]",0.047619,6492
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292748445.779,1,7,22,5,19978,7,kernel,0,"[50, 1, 1]",0.595238,6511
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.072,16,6939292748448.371,1,7,40,5,20013,7,kernel,0,"[50, 1, 1]",0.595238,6514
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939292748452.307,1,7,38,0,20015,7,kernel,0,"[2, 1, 1]",0.02381,6514
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939292748457.523,1,7,22,5,20044,7,kernel,0,"[50, 1, 1]",0.595238,6530
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939292748459.827,1,7,80,6,20074,7,kernel,0,"[8, 1, 8]",0.761905,6542
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292748467.795,1,7,44,25,20075,7,kernel,0,"[16, 4, 1]",0.761905,6542
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939292748470.611,1,7,80,6,20097,7,kernel,0,"[64, 1, 1]",0.761905,6546
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.784,16,6939292748477.523,1,7,48,0,20109,7,kernel,0,"[1, 1, 1]",0.011905,6550
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939292748485.107,1,7,22,5,20172,7,kernel,0,"[50, 1, 1]",0.595238,6592
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.328,16,6939292748487.571,1,7,32,10,20186,7,kernel,0,"[25, 1, 1]",0.297619,6593
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939292748491.699,1,7,16,0,20199,7,kernel,0,"[2, 1, 1]",0.02381,6601
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939292748494.419,1,7,236,0,20213,7,kernel,0,"[1, 8, 1]",0.095238,6586
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939292748532.115,1,7,16,15,20271,7,kernel,0,"[150, 1, 1]",1.785714,6651
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292748536.083,1,7,16,15,20296,7,kernel,0,"[150, 1, 1]",1.785714,6661
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292748540.275,1,7,22,15,20310,7,kernel,0,"[150, 1, 1]",1.785714,6665
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292748542.739,1,7,16,15,20330,7,kernel,0,"[150, 1, 1]",1.785714,6672
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939292750816.945,1,7,22,15,20344,7,kernel,0,"[150, 1, 1]",1.785714,6676
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.56,0,6939292750820.849,1,7,16,30,20379,7,kernel,0,"[300, 1, 1]",3.571429,6697
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.183,16384,6939292750824.241,1,7,57,38,20405,7,kernel,0,"[4, 2, 24]",2.285714,6708
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939292750838.256,1,7,44,25,20407,7,kernel,0,"[16, 4, 1]",0.761905,6708
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.063,16384,6939292750841.809,1,7,57,38,20424,7,kernel,0,"[16, 12, 1]",2.285714,6712
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.552,16,6939292750854.609,1,7,48,0,20437,7,kernel,0,"[3, 1, 1]",0.035714,6716
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.92,0,6939292750863.025,1,7,22,5,20460,7,kernel,0,"[50, 1, 1]",0.595238,6735
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939292750865.648,1,7,40,5,20495,7,kernel,0,"[50, 1, 1]",0.595238,6738
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939292750869.201,1,7,38,0,20497,7,kernel,0,"[2, 1, 1]",0.02381,6738
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292750874.416,1,7,22,5,20526,7,kernel,0,"[50, 1, 1]",0.595238,6754
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.776,16384,6939292750876.881,1,7,57,25,20552,7,kernel,0,"[16, 2, 4]",1.52381,6766
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.073,0,6939292750893.488,1,7,44,67,20554,7,kernel,0,"[64, 4, 1]",3.047619,6766
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.073,16384,6939292750897.264,1,7,57,51,20571,7,kernel,0,"[16, 16, 1]",3.047619,6770
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.016,16,6939292750913.201,1,7,48,0,20584,7,kernel,0,"[1, 1, 1]",0.011905,6774
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.433,0,6939292750919.984,1,7,22,20,20617,7,kernel,0,"[200, 1, 1]",2.380952,6795
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.008,0,6939292750923.249,1,7,22,20,20631,7,kernel,0,"[200, 1, 1]",2.380952,6800
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.783,16384,6939292750926.993,1,7,57,44,20656,7,kernel,0,"[4, 2, 28]",2.666667,6810
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.776,0,6939292750942.48,1,7,44,25,20658,7,kernel,0,"[16, 4, 1]",0.761905,6810
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.791,16384,6939292750947.089,1,7,57,51,20675,7,kernel,0,"[16, 16, 1]",3.047619,6814
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.689,16,6939292750961.712,1,7,48,0,20688,7,kernel,0,"[4, 1, 1]",0.047619,6818
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.823,0,6939292750969.265,1,7,22,5,20711,7,kernel,0,"[50, 1, 1]",0.595238,6837
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939292750971.889,1,7,40,5,20746,7,kernel,0,"[50, 1, 1]",0.595238,6840
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939292750975.44,1,7,38,0,20748,7,kernel,0,"[2, 1, 1]",0.02381,6840
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292750980.657,1,7,22,5,20777,7,kernel,0,"[50, 1, 1]",0.595238,6856
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939292750983.12,1,7,80,6,20807,7,kernel,0,"[8, 1, 8]",0.761905,6868
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292750990.96,1,7,44,25,20808,7,kernel,0,"[16, 4, 1]",0.761905,6868
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939292750993.776,1,7,80,6,20830,7,kernel,0,"[64, 1, 1]",0.761905,6872
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.719,16,6939292751000.561,1,7,48,0,20842,7,kernel,0,"[1, 1, 1]",0.011905,6876
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.207,0,6939292753129.135,1,7,22,5,20905,7,kernel,0,"[50, 1, 1]",0.595238,6918
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.521,16,6939292753132.494,1,7,32,10,20919,7,kernel,0,"[25, 1, 1]",0.297619,6919
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.985,0,6939292753136.75,1,7,16,0,20932,7,kernel,0,"[2, 1, 1]",0.02381,6927
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.641,53504,6939292753139.566,1,7,236,0,20946,7,kernel,0,"[1, 8, 1]",0.095238,6912
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.119,0,6939292753177.103,1,7,16,15,21004,7,kernel,0,"[150, 1, 1]",1.785714,6977
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292753181.454,1,7,16,15,21029,7,kernel,0,"[150, 1, 1]",1.785714,6987
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292753185.486,1,7,22,15,21043,7,kernel,0,"[150, 1, 1]",1.785714,6991
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.215,0,6939292753187.983,1,7,16,15,21063,7,kernel,0,"[150, 1, 1]",1.785714,6998
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.665,0,6939292753192.078,1,7,22,15,21077,7,kernel,0,"[150, 1, 1]",1.785714,7002
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939292753194.574,1,7,16,30,21112,7,kernel,0,"[300, 1, 1]",3.571429,7023
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.768,16384,6939292753197.55,1,7,57,38,21138,7,kernel,0,"[4, 2, 24]",2.285714,7034
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939292753211.022,1,7,44,25,21140,7,kernel,0,"[16, 4, 1]",0.761905,7034
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.224,16384,6939292753214.638,1,7,57,38,21157,7,kernel,0,"[16, 12, 1]",2.285714,7038
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.551,16,6939292753227.567,1,7,48,0,21170,7,kernel,0,"[3, 1, 1]",0.035714,7042
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939292753235.854,1,7,22,5,21193,7,kernel,0,"[50, 1, 1]",0.595238,7061
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.879,16,6939292753238.447,1,7,40,5,21228,7,kernel,0,"[50, 1, 1]",0.595238,7064
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.449,0,6939292753242.158,1,7,38,0,21230,7,kernel,0,"[2, 1, 1]",0.02381,7064
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939292753247.342,1,7,22,5,21259,7,kernel,0,"[50, 1, 1]",0.595238,7080
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.032,16384,6939292753249.774,1,7,57,25,21285,7,kernel,0,"[16, 2, 4]",1.52381,7092
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939292753266.638,1,7,44,67,21287,7,kernel,0,"[64, 4, 1]",3.047619,7092
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.592,16384,6939292753467.918,1,7,57,51,21308,7,kernel,0,"[16, 16, 1]",3.047619,7096
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939292753483.342,1,7,48,0,21321,7,kernel,0,"[1, 1, 1]",0.011905,7100
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939292753815.374,1,7,22,20,21354,7,kernel,0,"[200, 1, 1]",2.380952,7121
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.976,0,6939292753817.934,1,7,22,20,21368,7,kernel,0,"[200, 1, 1]",2.380952,7126
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.256,16384,6939292754000.846,1,7,57,44,21393,7,kernel,0,"[4, 2, 28]",2.666667,7136
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.712,0,6939292754017.806,1,7,44,25,21395,7,kernel,0,"[16, 4, 1]",0.761905,7136
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.816,16384,6939292754022.254,1,7,57,51,21412,7,kernel,0,"[16, 16, 1]",3.047619,7140
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.199,16,6939292754220.398,1,7,48,0,21425,7,kernel,0,"[4, 1, 1]",0.047619,7144
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939292754228.429,1,7,22,5,21448,7,kernel,0,"[50, 1, 1]",0.595238,7163
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939292754469.229,1,7,40,5,21483,7,kernel,0,"[50, 1, 1]",0.595238,7166
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939292754472.749,1,7,38,0,21485,7,kernel,0,"[2, 1, 1]",0.02381,7166
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292754682.189,1,7,22,5,21514,7,kernel,0,"[50, 1, 1]",0.595238,7182
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.848,25600,6939292754684.685,1,7,80,6,21544,7,kernel,0,"[8, 1, 8]",0.761905,7194
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.488,0,6939292754915.917,1,7,44,25,21545,7,kernel,0,"[16, 4, 1]",0.761905,7194
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.272,25600,6939292754920.237,1,7,80,6,21567,7,kernel,0,"[64, 1, 1]",0.761905,7198
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939292754927.341,1,7,48,0,21579,7,kernel,0,"[1, 1, 1]",0.011905,7202
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292755207.596,1,7,22,5,21642,7,kernel,0,"[50, 1, 1]",0.595238,7244
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.519,16,6939292755210.541,1,7,32,10,21656,7,kernel,0,"[25, 1, 1]",0.297619,7245
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292755214.86,1,7,16,0,21669,7,kernel,0,"[2, 1, 1]",0.02381,7253
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939292755687.084,1,7,236,0,21683,7,kernel,0,"[1, 8, 1]",0.095238,7238
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939292755724.396,1,7,16,15,21741,7,kernel,0,"[150, 1, 1]",1.785714,7303
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939292755729.196,1,7,16,15,21766,7,kernel,0,"[150, 1, 1]",1.785714,7313
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292755733.324,1,7,22,15,21780,7,kernel,0,"[150, 1, 1]",1.785714,7317
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939292756361.196,1,7,16,15,21800,7,kernel,0,"[150, 1, 1]",1.785714,7324
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.273,0,6939292756366.667,1,7,22,15,21814,7,kernel,0,"[150, 1, 1]",1.785714,7328
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939292756369.675,1,7,16,30,21849,7,kernel,0,"[300, 1, 1]",3.571429,7349
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.599,16384,6939292756372.78,1,7,57,38,21875,7,kernel,0,"[4, 2, 24]",2.285714,7360
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939292756387.116,1,7,44,25,21877,7,kernel,0,"[16, 4, 1]",0.761905,7360
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.64,16384,6939292756390.603,1,7,57,38,21894,7,kernel,0,"[16, 12, 1]",2.285714,7364
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.649,16,6939292756404.075,1,7,48,0,21907,7,kernel,0,"[3, 1, 1]",0.035714,7368
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939292756412.459,1,7,22,5,21930,7,kernel,0,"[50, 1, 1]",0.595238,7387
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.136,16,6939292756649.835,1,7,40,5,21965,7,kernel,0,"[50, 1, 1]",0.595238,7390
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.832,0,6939292756653.707,1,7,38,0,21967,7,kernel,0,"[2, 1, 1]",0.02381,7390
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292756659.243,1,7,22,5,21996,7,kernel,0,"[50, 1, 1]",0.595238,7406
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.056,16384,6939292757901.418,1,7,57,25,22022,7,kernel,0,"[16, 2, 4]",1.52381,7418
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.424,0,6939292757919.274,1,7,44,67,22024,7,kernel,0,"[64, 4, 1]",3.047619,7418
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.632,16384,6939292757923.53,1,7,57,51,22041,7,kernel,0,"[16, 16, 1]",3.047619,7422
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939292757937.962,1,7,48,0,22054,7,kernel,0,"[1, 1, 1]",0.011905,7426
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939292757946.538,1,7,22,20,22087,7,kernel,0,"[200, 1, 1]",2.380952,7447
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.912,0,6939292757949.674,1,7,22,20,22101,7,kernel,0,"[200, 1, 1]",2.380952,7452
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.0,16384,6939292757953.418,1,7,57,44,22126,7,kernel,0,"[4, 2, 28]",2.666667,7462
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.488,0,6939292757970.186,1,7,44,25,22128,7,kernel,0,"[16, 4, 1]",0.761905,7462
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.816,16384,6939292757974.474,1,7,57,51,22145,7,kernel,0,"[16, 16, 1]",3.047619,7466
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.816,16,6939292757989.994,1,7,48,0,22158,7,kernel,0,"[4, 1, 1]",0.047619,7470
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939292757997.61,1,7,22,5,22181,7,kernel,0,"[50, 1, 1]",0.595238,7489
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939292758000.234,1,7,40,5,22216,7,kernel,0,"[50, 1, 1]",0.595238,7492
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939292758003.818,1,7,38,0,22218,7,kernel,0,"[2, 1, 1]",0.02381,7492
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292758009.066,1,7,22,5,22247,7,kernel,0,"[50, 1, 1]",0.595238,7508
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.232,25600,6939292758011.53,1,7,80,6,22277,7,kernel,0,"[8, 1, 8]",0.761905,7520
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.92,0,6939292758019.53,1,7,44,25,22278,7,kernel,0,"[16, 4, 1]",0.761905,7520
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939292758022.186,1,7,80,6,22300,7,kernel,0,"[64, 1, 1]",0.761905,7524
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.72,16,6939292758029.034,1,7,48,0,22312,7,kernel,0,"[1, 1, 1]",0.011905,7528
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.72,0,6939292759630.888,1,7,22,5,22375,7,kernel,0,"[50, 1, 1]",0.595238,7570
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939292759634.44,1,7,32,10,22389,7,kernel,0,"[25, 1, 1]",0.297619,7571
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939292759638.696,1,7,16,0,22402,7,kernel,0,"[2, 1, 1]",0.02381,7579
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.768,53504,6939292759641.512,1,7,236,0,22416,7,kernel,0,"[1, 8, 1]",0.095238,7564
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.088,0,6939292759679.176,1,7,16,15,22474,7,kernel,0,"[150, 1, 1]",1.785714,7629
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939292759683.112,1,7,16,15,22499,7,kernel,0,"[150, 1, 1]",1.785714,7639
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939292759687.464,1,7,22,15,22513,7,kernel,0,"[150, 1, 1]",1.785714,7643
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939292759689.928,1,7,16,15,22533,7,kernel,0,"[150, 1, 1]",1.785714,7650
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.663,0,6939292759694.057,1,7,22,15,22547,7,kernel,0,"[150, 1, 1]",1.785714,7654
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939292759696.552,1,7,16,30,22582,7,kernel,0,"[300, 1, 1]",3.571429,7675
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.12,16384,6939292759699.528,1,7,57,38,22608,7,kernel,0,"[4, 2, 24]",2.285714,7686
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939292759713.48,1,7,44,25,22610,7,kernel,0,"[16, 4, 1]",0.761905,7686
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.288,16384,6939292759717.256,1,7,57,38,22631,7,kernel,0,"[16, 12, 1]",2.285714,7690
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939292759730.312,1,7,48,0,22644,7,kernel,0,"[3, 1, 1]",0.035714,7694
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292759738.76,1,7,22,5,22667,7,kernel,0,"[50, 1, 1]",0.595238,7713
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939292760013.096,1,7,40,5,22702,7,kernel,0,"[50, 1, 1]",0.595238,7716
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.704,0,6939292760017.032,1,7,38,0,22704,7,kernel,0,"[2, 1, 1]",0.02381,7716
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939292760961.351,1,7,22,5,22733,7,kernel,0,"[50, 1, 1]",0.595238,7732
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.96,16384,6939292760964.167,1,7,57,25,22759,7,kernel,0,"[16, 2, 4]",1.52381,7744
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939292760981.959,1,7,44,67,22761,7,kernel,0,"[64, 4, 1]",3.047619,7744
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.952,16384,6939292760985.543,1,7,57,51,22778,7,kernel,0,"[16, 16, 1]",3.047619,7748
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939292761000.327,1,7,48,0,22791,7,kernel,0,"[1, 1, 1]",0.011905,7752
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939292761008.935,1,7,22,20,22824,7,kernel,0,"[200, 1, 1]",2.380952,7773
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939292761012.135,1,7,22,20,22838,7,kernel,0,"[200, 1, 1]",2.380952,7778
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.136,16384,6939292761015.943,1,7,57,44,22863,7,kernel,0,"[4, 2, 28]",2.666667,7788
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.712,0,6939292761031.911,1,7,44,25,22865,7,kernel,0,"[16, 4, 1]",0.761905,7788
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.432,16384,6939292761036.327,1,7,57,51,22882,7,kernel,0,"[16, 16, 1]",3.047619,7792
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.784,16,6939292761051.591,1,7,48,0,22895,7,kernel,0,"[4, 1, 1]",0.047619,7796
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292761059.207,1,7,22,5,22918,7,kernel,0,"[50, 1, 1]",0.595238,7815
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.912,16,6939292761061.831,1,7,40,5,22953,7,kernel,0,"[50, 1, 1]",0.595238,7818
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939292761065.607,1,7,38,0,22955,7,kernel,0,"[2, 1, 1]",0.02381,7818
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939292762350.918,1,7,22,5,22984,7,kernel,0,"[50, 1, 1]",0.595238,7834
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939292762354.054,1,7,80,6,23014,7,kernel,0,"[8, 1, 8]",0.761905,7846
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292762362.054,1,7,44,25,23015,7,kernel,0,"[16, 4, 1]",0.761905,7846
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939292762365.126,1,7,80,6,23037,7,kernel,0,"[64, 1, 1]",0.761905,7850
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939292762372.23,1,7,48,0,23049,7,kernel,0,"[1, 1, 1]",0.011905,7854
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.408,0,6939292762380.838,1,7,22,5,23112,7,kernel,0,"[50, 1, 1]",0.595238,7896
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.328,16,6939292762383.046,1,7,32,10,23126,7,kernel,0,"[25, 1, 1]",0.297619,7897
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939292762387.174,1,7,16,0,23139,7,kernel,0,"[2, 1, 1]",0.02381,7905
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.704,53504,6939292762389.958,1,7,236,0,23153,7,kernel,0,"[1, 8, 1]",0.095238,7890
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939292762427.686,1,7,16,15,23211,7,kernel,0,"[150, 1, 1]",1.785714,7955
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.601,0,6939292762761.125,1,7,16,15,23236,7,kernel,0,"[150, 1, 1]",1.785714,7965
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.463,0,6939292762766.758,1,7,22,15,23250,7,kernel,0,"[150, 1, 1]",1.785714,7969
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.217,0,6939292762770.021,1,7,16,15,23270,7,kernel,0,"[150, 1, 1]",1.785714,7976
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292762774.47,1,7,22,15,23284,7,kernel,0,"[150, 1, 1]",1.785714,7980
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.232,0,6939292763200.997,1,7,16,30,23319,7,kernel,0,"[300, 1, 1]",3.571429,8001
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.92,16384,6939292763204.933,1,7,57,38,23345,7,kernel,0,"[4, 2, 24]",2.285714,8012
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939292763219.589,1,7,44,25,23347,7,kernel,0,"[16, 4, 1]",0.761905,8012
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.32,16384,6939292763223.077,1,7,57,38,23364,7,kernel,0,"[16, 12, 1]",2.285714,8016
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939292763236.229,1,7,48,0,23377,7,kernel,0,"[3, 1, 1]",0.035714,8020
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939292763481.861,1,7,22,5,23400,7,kernel,0,"[50, 1, 1]",0.595238,8039
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.504,0,6939292763687.941,1,7,16,5,23432,7,kernel,0,"[50, 1, 1]",0.595238,8056
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",2.016,0,6939292763693.253,1,7,16,51,23457,7,kernel,0,"[512, 1, 1]",6.095238,8066
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.953,0,6939292763931.14,1,7,16,51,23482,7,kernel,0,"[512, 1, 1]",6.095238,8076
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",36.352,0,6939292768751.872,1,7,16,100,23513,7,kernel,0,"[10000, 1, 1]",119.047623,8088
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.608,8192,6939292781270.836,1,7,24,13,23520,7,kernel,0,"[16, 1, 1]",0.190476,8083
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.504,0,6939292781520.692,1,7,16,5,23546,7,kernel,0,"[50, 1, 1]",0.595238,8101
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.664,0,6939292781708.692,1,7,16,51,23571,7,kernel,0,"[512, 1, 1]",6.095238,8111
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939292781713.876,1,7,16,51,23596,7,kernel,0,"[512, 1, 1]",6.095238,8121
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",4.865,0,6939292781910.515,1,7,22,51,23610,7,kernel,0,"[512, 1, 1]",6.095238,8125
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",36.671,0,6939292782228.724,1,7,16,100,23640,7,kernel,0,"[10000, 1, 1]",119.047623,8138
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.832,8192,6939292782266.163,1,7,24,13,23647,7,kernel,0,"[16, 1, 1]",0.190476,8133
