pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.44,0,6939293082647.013,1,7,16,0,29133,7,kernel,0,"[1, 1, 1]",0.011905,8198
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.745,0,6939293084346.306,1,7,16,100,29163,7,kernel,0,"[1954, 1, 1]",23.261906,8722
0,6.857143,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params),0,"[128, 1, 1]",51.104,30720,6939293084350.755,1,7,126,14,29181,7,kernel,0,"[4, 1, 36]",1.714286,8718
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.576,0,6939293084402.627,1,7,44,25,29182,7,kernel,0,"[16, 4, 1]",0.761905,8718
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.68,0,6939293084407.906,1,7,16,100,29200,7,kernel,0,"[1954, 1, 1]",23.261906,8730
0,119.238098,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",45.729,16384,6939293084412.386,1,7,57,67,29214,7,kernel,0,"[4, 313, 1]",14.904762,8726
0,3.809524,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",4.288,16,6939293084458.85,1,7,32,8,29227,7,kernel,0,"[20, 1, 1]",0.238095,8734
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.879,16,6939293084463.875,1,7,40,5,29280,7,kernel,0,"[50, 1, 1]",0.595238,8759
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.447,0,6939293084467.491,1,7,38,0,29282,7,kernel,0,"[2, 1, 1]",0.02381,8759
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939293086457.152,1,7,40,5,29323,7,kernel,0,"[50, 1, 1]",0.595238,8773
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.8,0,6939293086461.056,1,7,38,0,29325,7,kernel,0,"[2, 1, 1]",0.02381,8773
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939293086466.592,1,7,22,5,29354,7,kernel,0,"[50, 1, 1]",0.595238,8789
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.576,16384,6939293086469.216,1,7,57,25,29380,7,kernel,0,"[16, 2, 4]",1.52381,8801
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.816,0,6939293086486.688,1,7,44,67,29382,7,kernel,0,"[64, 4, 1]",3.047619,8801
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.208,16384,6939293086490.304,1,7,57,51,29399,7,kernel,0,"[16, 16, 1]",3.047619,8805
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939293086505.248,1,7,48,0,29412,7,kernel,0,"[1, 1, 1]",0.011905,8809
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.496,0,6939293086513.984,1,7,22,20,29445,7,kernel,0,"[200, 1, 1]",2.380952,8830
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.136,0,6939293086517.216,1,7,22,20,29459,7,kernel,0,"[200, 1, 1]",2.380952,8835
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.36,16384,6939293086521.216,1,7,57,44,29484,7,kernel,0,"[4, 2, 28]",2.666667,8845
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.52,0,6939293086537.312,1,7,44,25,29486,7,kernel,0,"[16, 4, 1]",0.761905,8845
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.176,16384,6939293086541.664,1,7,57,51,29503,7,kernel,0,"[16, 16, 1]",3.047619,8849
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.008,16,6939293086556.64,1,7,48,0,29516,7,kernel,0,"[4, 1, 1]",0.047619,8853
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939293086564.384,1,7,22,5,29539,7,kernel,0,"[50, 1, 1]",0.595238,8872
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.976,16,6939293086567.008,1,7,40,5,29574,7,kernel,0,"[50, 1, 1]",0.595238,8875
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939293086570.784,1,7,38,0,29576,7,kernel,0,"[2, 1, 1]",0.02381,8875
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939293086575.968,1,7,22,5,29605,7,kernel,0,"[50, 1, 1]",0.595238,8891
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939293086578.464,1,7,80,6,29635,7,kernel,0,"[8, 1, 8]",0.761905,8903
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.952,0,6939293086586.304,1,7,44,25,29636,7,kernel,0,"[16, 4, 1]",0.761905,8903
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293086589.088,1,7,80,6,29658,7,kernel,0,"[64, 1, 1]",0.761905,8907
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.56,16,6939293086595.872,1,7,48,0,29670,7,kernel,0,"[1, 1, 1]",0.011905,8911
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939293086603.296,1,7,22,5,29733,7,kernel,0,"[50, 1, 1]",0.595238,8953
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.36,16,6939293086605.504,1,7,32,10,29747,7,kernel,0,"[25, 1, 1]",0.297619,8954
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939293086943.008,1,7,16,0,29760,7,kernel,0,"[2, 1, 1]",0.02381,8962
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.897,53504,6939293086946.143,1,7,236,0,29774,7,kernel,0,"[1, 8, 1]",0.095238,8947
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.504,0,6939293088984.701,1,7,16,10,29832,7,kernel,0,"[100, 1, 1]",1.190476,9012
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.152,0,6939293088990.173,1,7,16,10,29857,7,kernel,0,"[100, 1, 1]",1.190476,9022
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939293088994.557,1,7,22,10,29871,7,kernel,0,"[100, 1, 1]",1.190476,9026
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.304,0,6939293088996.893,1,7,16,20,29906,7,kernel,0,"[200, 1, 1]",2.380952,9047
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.208,16384,6939293088999.997,1,7,57,25,29932,7,kernel,0,"[4, 2, 16]",1.52381,9058
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939293089011.037,1,7,44,25,29934,7,kernel,0,"[16, 4, 1]",0.761905,9058
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.128,16384,6939293089014.077,1,7,57,25,29951,7,kernel,0,"[16, 8, 1]",1.52381,9062
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.616,16,6939293089023.005,1,7,48,0,29964,7,kernel,0,"[2, 1, 1]",0.02381,9066
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.784,25600,6939293089031.421,1,7,80,6,30002,7,kernel,0,"[8, 1, 8]",0.761905,9086
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293089039.037,1,7,44,25,30003,7,kernel,0,"[16, 4, 1]",0.761905,9086
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293089041.789,1,7,80,6,30025,7,kernel,0,"[64, 1, 1]",0.761905,9090
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.048,16,6939293089048.541,1,7,48,0,30037,7,kernel,0,"[1, 1, 1]",0.011905,9094
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939293089055.325,1,7,22,5,30052,7,kernel,0,"[50, 1, 1]",0.595238,9105
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.016,0,6939293089058.109,1,7,30,0,30069,7,kernel,0,"[2, 2, 1]",0.047619,9108
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",8.32,0,6939293089060.861,1,7,30,100,30088,7,kernel,0,"[1024, 2, 1]",24.380953,9115
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.616,16,6939293089069.981,1,7,40,5,30125,7,kernel,0,"[50, 1, 1]",0.595238,9122
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293089074.397,1,7,38,0,30127,7,kernel,0,"[2, 1, 1]",0.02381,9122
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293089079.613,1,7,22,5,30156,7,kernel,0,"[50, 1, 1]",0.595238,9138
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.72,25600,6939293089082.077,1,7,80,6,30186,7,kernel,0,"[8, 1, 8]",0.761905,9150
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293089089.597,1,7,44,25,30187,7,kernel,0,"[16, 4, 1]",0.761905,9150
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.76,25600,6939293089092.445,1,7,80,6,30209,7,kernel,0,"[64, 1, 1]",0.761905,9154
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939293089099.037,1,7,48,0,30221,7,kernel,0,"[1, 1, 1]",0.011905,9158
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939293089302.845,1,7,22,5,30284,7,kernel,0,"[50, 1, 1]",0.595238,9200
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939293089305.149,1,7,32,10,30298,7,kernel,0,"[25, 1, 1]",0.297619,9201
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293089309.405,1,7,16,0,30311,7,kernel,0,"[2, 1, 1]",0.02381,9209
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.448,53504,6939293089484.061,1,7,236,0,30325,7,kernel,0,"[1, 8, 1]",0.095238,9194
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.28,0,6939293089855.292,1,7,16,15,30383,7,kernel,0,"[150, 1, 1]",1.785714,9259
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.28,0,6939293090028.508,1,7,16,15,30408,7,kernel,0,"[150, 1, 1]",1.785714,9269
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939293090032.7,1,7,22,15,30422,7,kernel,0,"[150, 1, 1]",1.785714,9273
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939293090035.196,1,7,16,15,30442,7,kernel,0,"[150, 1, 1]",1.785714,9280
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293090212.604,1,7,22,15,30456,7,kernel,0,"[150, 1, 1]",1.785714,9284
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.271,0,6939293090395.1,1,7,16,30,30491,7,kernel,0,"[300, 1, 1]",3.571429,9305
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.056,16384,6939293090570.779,1,7,57,38,30517,7,kernel,0,"[4, 2, 24]",2.285714,9316
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939293090584.636,1,7,44,25,30519,7,kernel,0,"[16, 4, 1]",0.761905,9316
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.328,16384,6939293090588.092,1,7,57,38,30536,7,kernel,0,"[16, 12, 1]",2.285714,9320
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.745,16,6939293090600.187,1,7,48,0,30549,7,kernel,0,"[3, 1, 1]",0.035714,9324
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939293090798.171,1,7,22,5,30572,7,kernel,0,"[50, 1, 1]",0.595238,9343
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.976,16,6939293090800.987,1,7,40,5,30607,7,kernel,0,"[50, 1, 1]",0.595238,9346
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",7.776,0,6939293091012.667,1,7,38,0,30609,7,kernel,0,"[2, 1, 1]",0.02381,9346
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939293091021.307,1,7,22,5,30638,7,kernel,0,"[50, 1, 1]",0.595238,9362
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.568,16384,6939293091492.602,1,7,57,25,30664,7,kernel,0,"[16, 2, 4]",1.52381,9374
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.136,0,6939293091510.97,1,7,44,67,30666,7,kernel,0,"[64, 4, 1]",3.047619,9374
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.856,16384,6939293091514.906,1,7,57,51,30683,7,kernel,0,"[16, 16, 1]",3.047619,9378
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.871,16,6939293091529.531,1,7,48,0,30696,7,kernel,0,"[1, 1, 1]",0.011905,9382
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.72,0,6939293091538.138,1,7,22,20,30729,7,kernel,0,"[200, 1, 1]",2.380952,9403
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.169,0,6939293091541.562,1,7,22,20,30743,7,kernel,0,"[200, 1, 1]",2.380952,9408
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.36,16384,6939293091545.498,1,7,57,44,30768,7,kernel,0,"[4, 2, 28]",2.666667,9418
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.648,0,6939293091561.562,1,7,44,25,30770,7,kernel,0,"[16, 4, 1]",0.761905,9418
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.68,16384,6939293092216.634,1,7,57,51,30787,7,kernel,0,"[16, 16, 1]",3.047619,9422
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939293092233.049,1,7,48,0,30800,7,kernel,0,"[4, 1, 1]",0.047619,9426
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939293092241.498,1,7,22,5,30823,7,kernel,0,"[50, 1, 1]",0.595238,9445
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.847,16,6939293092244.09,1,7,40,5,30858,7,kernel,0,"[50, 1, 1]",0.595238,9448
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293092247.706,1,7,38,0,30860,7,kernel,0,"[2, 1, 1]",0.02381,9448
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939293092253.018,1,7,22,5,30889,7,kernel,0,"[50, 1, 1]",0.595238,9464
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.168,25600,6939293092255.641,1,7,80,6,30919,7,kernel,0,"[8, 1, 8]",0.761905,9476
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.017,0,6939293092263.609,1,7,44,25,30920,7,kernel,0,"[16, 4, 1]",0.761905,9476
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293092266.425,1,7,80,6,30942,7,kernel,0,"[64, 1, 1]",0.761905,9480
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.081,16,6939293092273.433,1,7,48,0,30954,7,kernel,0,"[1, 1, 1]",0.011905,9484
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939293092653.401,1,7,22,5,31017,7,kernel,0,"[50, 1, 1]",0.595238,9526
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939293092656.377,1,7,32,10,31031,7,kernel,0,"[25, 1, 1]",0.297619,9527
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939293093597.816,1,7,16,0,31044,7,kernel,0,"[2, 1, 1]",0.02381,9535
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.184,53504,6939293093600.952,1,7,236,0,31058,7,kernel,0,"[1, 8, 1]",0.095238,9520
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.312,0,6939293093638.936,1,7,16,10,31116,7,kernel,0,"[100, 1, 1]",1.190476,9585
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939293093643.192,1,7,16,10,31141,7,kernel,0,"[100, 1, 1]",1.190476,9595
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939293093647.32,1,7,22,10,31155,7,kernel,0,"[100, 1, 1]",1.190476,9599
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.112,0,6939293093649.656,1,7,16,20,31190,7,kernel,0,"[200, 1, 1]",2.380952,9620
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.08,16384,6939293093652.632,1,7,57,25,31216,7,kernel,0,"[4, 2, 16]",1.52381,9631
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939293093663.48,1,7,44,25,31218,7,kernel,0,"[16, 4, 1]",0.761905,9631
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.096,16384,6939293093666.616,1,7,57,25,31235,7,kernel,0,"[16, 8, 1]",1.52381,9635
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.016,16,6939293095201.078,1,7,48,0,31248,7,kernel,0,"[2, 1, 1]",0.02381,9639
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939293095211.894,1,7,22,5,31267,7,kernel,0,"[50, 1, 1]",0.595238,9650
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.264,25600,6939293095214.87,1,7,80,6,31299,7,kernel,0,"[8, 1, 8]",0.761905,9660
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939293095222.902,1,7,44,25,31300,7,kernel,0,"[16, 4, 1]",0.761905,9660
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293095225.718,1,7,80,6,31322,7,kernel,0,"[64, 1, 1]",0.761905,9664
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.016,16,6939293095232.502,1,7,48,0,31334,7,kernel,0,"[1, 1, 1]",0.011905,9668
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939293095239.254,1,7,22,5,31349,7,kernel,0,"[50, 1, 1]",0.595238,9679
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.048,0,6939293095241.878,1,7,30,0,31366,7,kernel,0,"[2, 2, 1]",0.047619,9682
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",8.768,0,6939293095244.79,1,7,30,100,31385,7,kernel,0,"[1024, 2, 1]",24.380953,9689
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939293095254.678,1,7,40,5,31422,7,kernel,0,"[50, 1, 1]",0.595238,9696
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939293095258.262,1,7,38,0,31424,7,kernel,0,"[2, 1, 1]",0.02381,9696
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939293095263.478,1,7,22,5,31453,7,kernel,0,"[50, 1, 1]",0.595238,9712
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.464,25600,6939293095266.102,1,7,80,6,31483,7,kernel,0,"[8, 1, 8]",0.761905,9724
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293095273.366,1,7,44,25,31484,7,kernel,0,"[16, 4, 1]",0.761905,9724
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.632,25600,6939293095276.214,1,7,80,6,31506,7,kernel,0,"[64, 1, 1]",0.761905,9728
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939293095282.678,1,7,48,0,31518,7,kernel,0,"[1, 1, 1]",0.011905,9732
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939293095291.03,1,7,22,5,31581,7,kernel,0,"[50, 1, 1]",0.595238,9774
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.36,16,6939293095293.238,1,7,32,10,31595,7,kernel,0,"[25, 1, 1]",0.297619,9775
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293095297.366,1,7,16,0,31608,7,kernel,0,"[2, 1, 1]",0.02381,9783
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.832,53504,6939293095944.629,1,7,236,0,31622,7,kernel,0,"[1, 8, 1]",0.095238,9768
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939293095982.357,1,7,16,15,31680,7,kernel,0,"[150, 1, 1]",1.785714,9833
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293095986.901,1,7,16,15,31705,7,kernel,0,"[150, 1, 1]",1.785714,9843
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939293095991.381,1,7,22,15,31719,7,kernel,0,"[150, 1, 1]",1.785714,9847
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293095993.845,1,7,16,15,31739,7,kernel,0,"[150, 1, 1]",1.785714,9854
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.848,0,6939293096233.429,1,7,22,15,31753,7,kernel,0,"[150, 1, 1]",1.785714,9858
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.592,0,6939293096237.077,1,7,16,30,31788,7,kernel,0,"[300, 1, 1]",3.571429,9879
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.92,16384,6939293097484.147,1,7,57,38,31814,7,kernel,0,"[4, 2, 24]",2.285714,9890
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.041,0,6939293097498.803,1,7,44,25,31816,7,kernel,0,"[16, 4, 1]",0.761905,9890
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.352,16384,6939293097502.643,1,7,57,38,31833,7,kernel,0,"[16, 12, 1]",2.285714,9894
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.873,16,6939293097515.795,1,7,48,0,31846,7,kernel,0,"[3, 1, 1]",0.035714,9898
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939293097524.371,1,7,22,5,31869,7,kernel,0,"[50, 1, 1]",0.595238,9917
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.976,16,6939293097526.963,1,7,40,5,31904,7,kernel,0,"[50, 1, 1]",0.595238,9920
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.511,0,6939293097530.74,1,7,38,0,31906,7,kernel,0,"[2, 1, 1]",0.02381,9920
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939293097536.019,1,7,22,5,31935,7,kernel,0,"[50, 1, 1]",0.595238,9936
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.616,16384,6939293097538.644,1,7,57,25,31961,7,kernel,0,"[16, 2, 4]",1.52381,9948
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939293097555.059,1,7,44,67,31963,7,kernel,0,"[64, 4, 1]",3.047619,9948
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.721,16384,6939293097558.803,1,7,57,51,31980,7,kernel,0,"[16, 16, 1]",3.047619,9952
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.92,16,6939293097574.259,1,7,48,0,31993,7,kernel,0,"[1, 1, 1]",0.011905,9956
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.464,0,6939293097580.915,1,7,22,20,32026,7,kernel,0,"[200, 1, 1]",2.380952,9977
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.815,0,6939293097584.212,1,7,22,20,32040,7,kernel,0,"[200, 1, 1]",2.380952,9982
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.007,16384,6939293097587.828,1,7,57,44,32065,7,kernel,0,"[4, 2, 28]",2.666667,9992
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.36,0,6939293097603.539,1,7,44,25,32067,7,kernel,0,"[16, 4, 1]",0.761905,9992
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.104,16384,6939293097607.667,1,7,57,51,32084,7,kernel,0,"[16, 16, 1]",3.047619,9996
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.496,16,6939293097623.507,1,7,48,0,32097,7,kernel,0,"[4, 1, 1]",0.047619,10000
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939293109909.029,1,7,22,5,32120,7,kernel,0,"[50, 1, 1]",0.595238,10019
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939293109912.069,1,7,40,5,32155,7,kernel,0,"[50, 1, 1]",0.595238,10022
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939293109915.845,1,7,38,0,32157,7,kernel,0,"[2, 1, 1]",0.02381,10022
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939293110111.045,1,7,22,5,32186,7,kernel,0,"[50, 1, 1]",0.595238,10038
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.008,25600,6939293110113.509,1,7,80,6,32216,7,kernel,0,"[8, 1, 8]",0.761905,10050
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293110121.349,1,7,44,25,32217,7,kernel,0,"[16, 4, 1]",0.761905,10050
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939293110124.165,1,7,80,6,32239,7,kernel,0,"[64, 1, 1]",0.761905,10054
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.016,16,6939293110689.124,1,7,48,0,32251,7,kernel,0,"[1, 1, 1]",0.011905,10058
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939293110699.94,1,7,22,5,32314,7,kernel,0,"[50, 1, 1]",0.595238,10100
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.328,16,6939293110703.012,1,7,32,10,32328,7,kernel,0,"[25, 1, 1]",0.297619,10101
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939293110707.14,1,7,16,0,32341,7,kernel,0,"[2, 1, 1]",0.02381,10109
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.768,53504,6939293110709.956,1,7,236,0,32355,7,kernel,0,"[1, 8, 1]",0.095238,10094
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293111077.124,1,7,16,10,32413,7,kernel,0,"[100, 1, 1]",1.190476,10159
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.569,0,6939293111297.219,1,7,16,10,32438,7,kernel,0,"[100, 1, 1]",1.190476,10169
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.983,0,6939293111302.692,1,7,22,10,32452,7,kernel,0,"[100, 1, 1]",1.190476,10173
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.008,0,6939293111518.595,1,7,16,20,32487,7,kernel,0,"[200, 1, 1]",2.380952,10194
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.944,16384,6939293111522.339,1,7,57,25,32513,7,kernel,0,"[4, 2, 16]",1.52381,10205
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939293111534.051,1,7,44,25,32515,7,kernel,0,"[16, 4, 1]",0.761905,10205
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.704,16384,6939293111714.851,1,7,57,25,32532,7,kernel,0,"[16, 8, 1]",1.52381,10209
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939293111724.259,1,7,48,0,32545,7,kernel,0,"[2, 1, 1]",0.02381,10213
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939293111732.675,1,7,22,5,32560,7,kernel,0,"[50, 1, 1]",0.595238,10224
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.912,25600,6939293111947.683,1,7,80,6,32592,7,kernel,0,"[8, 1, 8]",0.761905,10234
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939293111955.299,1,7,44,25,32593,7,kernel,0,"[16, 4, 1]",0.761905,10234
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939293111958.435,1,7,80,6,32615,7,kernel,0,"[64, 1, 1]",0.761905,10238
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939293111965.379,1,7,48,0,32627,7,kernel,0,"[1, 1, 1]",0.011905,10242
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.079,0,6939293112184.451,1,7,22,5,32642,7,kernel,0,"[50, 1, 1]",0.595238,10253
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.463,0,6939293112187.267,1,7,30,0,32659,7,kernel,0,"[2, 2, 1]",0.047619,10256
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.04,0,6939293112378.722,1,7,30,100,32678,7,kernel,0,"[1024, 2, 1]",24.380953,10263
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.264,16,6939293112390.626,1,7,40,5,32715,7,kernel,0,"[50, 1, 1]",0.595238,10270
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939293112394.594,1,7,38,0,32717,7,kernel,0,"[2, 1, 1]",0.02381,10270
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.015,0,6939293112897.058,1,7,22,5,32746,7,kernel,0,"[50, 1, 1]",0.595238,10286
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939293112899.842,1,7,80,6,32776,7,kernel,0,"[8, 1, 8]",0.761905,10298
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.047,0,6939293112907.714,1,7,44,25,32777,7,kernel,0,"[16, 4, 1]",0.761905,10298
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293112910.53,1,7,80,6,32799,7,kernel,0,"[64, 1, 1]",0.761905,10302
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939293112917.314,1,7,48,0,32811,7,kernel,0,"[1, 1, 1]",0.011905,10306
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939293113350.657,1,7,22,5,32874,7,kernel,0,"[50, 1, 1]",0.595238,10348
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939293113353.633,1,7,32,10,32888,7,kernel,0,"[25, 1, 1]",0.297619,10349
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293113357.921,1,7,16,0,32901,7,kernel,0,"[2, 1, 1]",0.02381,10357
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939293113360.737,1,7,236,0,32915,7,kernel,0,"[1, 8, 1]",0.095238,10342
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939293113816.225,1,7,16,15,32973,7,kernel,0,"[150, 1, 1]",1.785714,10407
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939293113821.409,1,7,16,15,32998,7,kernel,0,"[150, 1, 1]",1.785714,10417
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.697,0,6939293113825.984,1,7,22,15,33012,7,kernel,0,"[150, 1, 1]",1.785714,10421
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.215,0,6939293113828.449,1,7,16,15,33032,7,kernel,0,"[150, 1, 1]",1.785714,10428
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.912,0,6939293114238.72,1,7,22,15,33046,7,kernel,0,"[150, 1, 1]",1.785714,10432
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.528,0,6939293114242.336,1,7,16,30,33081,7,kernel,0,"[300, 1, 1]",3.571429,10453
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.312,16384,6939293114245.632,1,7,57,38,33107,7,kernel,0,"[4, 2, 24]",2.285714,10464
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939293114259.648,1,7,44,25,33109,7,kernel,0,"[16, 4, 1]",0.761905,10464
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.616,16384,6939293114263.424,1,7,57,38,33126,7,kernel,0,"[16, 12, 1]",2.285714,10468
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.663,16,6939293114689.568,1,7,48,0,33139,7,kernel,0,"[3, 1, 1]",0.035714,10472
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939293114700.064,1,7,22,5,33162,7,kernel,0,"[50, 1, 1]",0.595238,10491
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.879,16,6939293114703.008,1,7,40,5,33197,7,kernel,0,"[50, 1, 1]",0.595238,10494
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939293114706.592,1,7,38,0,33199,7,kernel,0,"[2, 1, 1]",0.02381,10494
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939293114711.839,1,7,22,5,33228,7,kernel,0,"[50, 1, 1]",0.595238,10510
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.96,16384,6939293115115.455,1,7,57,25,33254,7,kernel,0,"[16, 2, 4]",1.52381,10522
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.168,0,6939293115133.119,1,7,44,67,33256,7,kernel,0,"[64, 4, 1]",3.047619,10522
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.144,16384,6939293115137.087,1,7,57,51,33273,7,kernel,0,"[16, 16, 1]",3.047619,10526
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939293115151.999,1,7,48,0,33286,7,kernel,0,"[1, 1, 1]",0.011905,10530
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.432,0,6939293115160.415,1,7,22,20,33319,7,kernel,0,"[200, 1, 1]",2.380952,10551
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.168,0,6939293115163.679,1,7,22,20,33333,7,kernel,0,"[200, 1, 1]",2.380952,10556
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.864,16384,6939293115586.559,1,7,57,44,33358,7,kernel,0,"[4, 2, 28]",2.666667,10566
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.456,0,6939293115604.191,1,7,44,25,33360,7,kernel,0,"[16, 4, 1]",0.761905,10566
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.855,16384,6939293115608.479,1,7,57,51,33377,7,kernel,0,"[16, 16, 1]",3.047619,10570
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.552,16,6939293115623.039,1,7,48,0,33390,7,kernel,0,"[4, 1, 1]",0.047619,10574
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.825,0,6939293115631.326,1,7,22,5,33413,7,kernel,0,"[50, 1, 1]",0.595238,10593
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.881,16,6939293115633.918,1,7,40,5,33448,7,kernel,0,"[50, 1, 1]",0.595238,10596
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293115637.566,1,7,38,0,33450,7,kernel,0,"[2, 1, 1]",0.02381,10596
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939293116049.63,1,7,22,5,33479,7,kernel,0,"[50, 1, 1]",0.595238,10612
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939293116052.702,1,7,80,6,33509,7,kernel,0,"[8, 1, 8]",0.761905,10624
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293116060.478,1,7,44,25,33510,7,kernel,0,"[16, 4, 1]",0.761905,10624
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.112,25600,6939293116063.326,1,7,80,6,33532,7,kernel,0,"[64, 1, 1]",0.761905,10628
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939293116070.27,1,7,48,0,33544,7,kernel,0,"[1, 1, 1]",0.011905,10632
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.337,0,6939293116375.549,1,7,22,5,33607,7,kernel,0,"[50, 1, 1]",0.595238,10674
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.456,16,6939293116378.654,1,7,32,10,33621,7,kernel,0,"[25, 1, 1]",0.297619,10675
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.015,0,6939293116389.15,1,7,16,0,33634,7,kernel,0,"[2, 1, 1]",0.02381,10683
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.513,53504,6939293116434.813,1,7,236,0,33648,7,kernel,0,"[1, 8, 1]",0.095238,10668
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293116883.453,1,7,16,10,33706,7,kernel,0,"[100, 1, 1]",1.190476,10733
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939293117093.597,1,7,16,10,33731,7,kernel,0,"[100, 1, 1]",1.190476,10743
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939293117099.069,1,7,22,10,33745,7,kernel,0,"[100, 1, 1]",1.190476,10747
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.271,0,6939293117281.789,1,7,16,20,33780,7,kernel,0,"[200, 1, 1]",2.380952,10768
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.952,16384,6939293117508.764,1,7,57,25,33806,7,kernel,0,"[4, 2, 16]",1.52381,10779
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.625,0,6939293117519.452,1,7,44,25,33808,7,kernel,0,"[16, 4, 1]",0.761905,10779
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.128,16384,6939293117522.876,1,7,57,25,33825,7,kernel,0,"[16, 8, 1]",1.52381,10783
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.936,16,6939293117531.868,1,7,48,0,33838,7,kernel,0,"[2, 1, 1]",0.02381,10787
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.984,0,6939293117540.604,1,7,22,5,33853,7,kernel,0,"[50, 1, 1]",0.595238,10798
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.072,25600,6939293117744.924,1,7,80,6,33885,7,kernel,0,"[8, 1, 8]",0.761905,10808
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939293117752.828,1,7,44,25,33886,7,kernel,0,"[16, 4, 1]",0.761905,10808
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293117755.9,1,7,80,6,33908,7,kernel,0,"[64, 1, 1]",0.761905,10812
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.112,16,6939293117954.588,1,7,48,0,33920,7,kernel,0,"[1, 1, 1]",0.011905,10816
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939293117965.436,1,7,22,5,33935,7,kernel,0,"[50, 1, 1]",0.595238,10827
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.24,0,6939293117968.54,1,7,30,0,33952,7,kernel,0,"[2, 2, 1]",0.047619,10830
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.496,0,6939293118213.468,1,7,30,100,33971,7,kernel,0,"[1024, 2, 1]",24.380953,10837
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.872,16,6939293118224.731,1,7,40,5,34008,7,kernel,0,"[50, 1, 1]",0.595238,10844
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.415,0,6939293118229.468,1,7,38,0,34010,7,kernel,0,"[2, 1, 1]",0.02381,10844
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939293118466.299,1,7,22,5,34039,7,kernel,0,"[50, 1, 1]",0.595238,10860
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.168,25600,6939293118469.243,1,7,80,6,34069,7,kernel,0,"[8, 1, 8]",0.761905,10872
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293118477.147,1,7,44,25,34070,7,kernel,0,"[16, 4, 1]",0.761905,10872
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939293118671.611,1,7,80,6,34092,7,kernel,0,"[64, 1, 1]",0.761905,10876
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.032,16,6939293118678.459,1,7,48,0,34104,7,kernel,0,"[1, 1, 1]",0.011905,10880
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.177,0,6939293119101.818,1,7,22,5,34167,7,kernel,0,"[50, 1, 1]",0.595238,10922
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.521,16,6939293119104.762,1,7,32,10,34181,7,kernel,0,"[25, 1, 1]",0.297619,10923
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293119109.05,1,7,16,0,34194,7,kernel,0,"[2, 1, 1]",0.02381,10931
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.352,53504,6939293119111.866,1,7,236,0,34208,7,kernel,0,"[1, 8, 1]",0.095238,10916
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293119585.434,1,7,16,15,34266,7,kernel,0,"[150, 1, 1]",1.785714,10981
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293119591.066,1,7,16,15,34291,7,kernel,0,"[150, 1, 1]",1.785714,10991
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293119595.866,1,7,22,15,34305,7,kernel,0,"[150, 1, 1]",1.785714,10995
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.44,0,6939293119790.298,1,7,16,15,34325,7,kernel,0,"[150, 1, 1]",1.785714,11002
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939293119795.034,1,7,22,15,34339,7,kernel,0,"[150, 1, 1]",1.785714,11006
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939293120652.601,1,7,16,30,34374,7,kernel,0,"[300, 1, 1]",3.571429,11027
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.472,16384,6939293120656.505,1,7,57,38,34400,7,kernel,0,"[4, 2, 24]",2.285714,11038
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939293120670.681,1,7,44,25,34402,7,kernel,0,"[16, 4, 1]",0.761905,11038
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.808,16384,6939293120674.169,1,7,57,38,34419,7,kernel,0,"[16, 12, 1]",2.285714,11042
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939293120686.809,1,7,48,0,34432,7,kernel,0,"[3, 1, 1]",0.035714,11046
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.823,0,6939293120695.417,1,7,22,5,34455,7,kernel,0,"[50, 1, 1]",0.595238,11065
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.105,16,6939293120698.072,1,7,40,5,34490,7,kernel,0,"[50, 1, 1]",0.595238,11068
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939293120702.009,1,7,38,0,34492,7,kernel,0,"[2, 1, 1]",0.02381,11068
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939293120707.161,1,7,22,5,34521,7,kernel,0,"[50, 1, 1]",0.595238,11084
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.712,16384,6939293120709.785,1,7,57,25,34547,7,kernel,0,"[16, 2, 4]",1.52381,11096
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.168,0,6939293120726.297,1,7,44,67,34549,7,kernel,0,"[64, 4, 1]",3.047619,11096
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.36,16384,6939293120730.265,1,7,57,51,34566,7,kernel,0,"[16, 16, 1]",3.047619,11100
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.208,16,6939293121621.944,1,7,48,0,34579,7,kernel,0,"[1, 1, 1]",0.011905,11104
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.848,0,6939293121633.016,1,7,22,20,34612,7,kernel,0,"[200, 1, 1]",2.380952,11125
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.104,0,6939293121636.632,1,7,22,20,34626,7,kernel,0,"[200, 1, 1]",2.380952,11130
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.024,16384,6939293121640.568,1,7,57,44,34651,7,kernel,0,"[4, 2, 28]",2.666667,11140
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.84,0,6939293121658.423,1,7,44,25,34653,7,kernel,0,"[16, 4, 1]",0.761905,11140
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.728,16384,6939293121663.063,1,7,57,51,34670,7,kernel,0,"[16, 16, 1]",3.047619,11144
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.976,16,6939293121677.56,1,7,48,0,34683,7,kernel,0,"[4, 1, 1]",0.047619,11148
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939293121685.335,1,7,22,5,34706,7,kernel,0,"[50, 1, 1]",0.595238,11167
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.815,16,6939293121688.056,1,7,40,5,34741,7,kernel,0,"[50, 1, 1]",0.595238,11170
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293121691.672,1,7,38,0,34743,7,kernel,0,"[2, 1, 1]",0.02381,11170
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939293131071.373,1,7,22,5,34772,7,kernel,0,"[50, 1, 1]",0.595238,11186
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.36,25600,6939293131074.189,1,7,80,6,34802,7,kernel,0,"[8, 1, 8]",0.761905,11198
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.017,0,6939293131082.348,1,7,44,25,34803,7,kernel,0,"[16, 4, 1]",0.761905,11198
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939293131085.165,1,7,80,6,34825,7,kernel,0,"[64, 1, 1]",0.761905,11202
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939293131091.949,1,7,48,0,34837,7,kernel,0,"[1, 1, 1]",0.011905,11206
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939293131717.1,1,7,22,5,34900,7,kernel,0,"[50, 1, 1]",0.595238,11248
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939293131720.076,1,7,32,10,34914,7,kernel,0,"[25, 1, 1]",0.297619,11249
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.048,0,6939293131724.332,1,7,16,0,34927,7,kernel,0,"[2, 1, 1]",0.02381,11257
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.64,53504,6939293131727.148,1,7,236,0,34941,7,kernel,0,"[1, 8, 1]",0.095238,11242
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939293131764.652,1,7,16,10,34999,7,kernel,0,"[100, 1, 1]",1.190476,11307
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.408,0,6939293131959.628,1,7,16,10,35024,7,kernel,0,"[100, 1, 1]",1.190476,11317
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939293131964.652,1,7,22,10,35038,7,kernel,0,"[100, 1, 1]",1.190476,11321
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.944,0,6939293132181.547,1,7,16,20,35073,7,kernel,0,"[200, 1, 1]",2.380952,11342
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.951,16384,6939293132185.26,1,7,57,25,35099,7,kernel,0,"[4, 2, 16]",1.52381,11353
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939293132196.043,1,7,44,25,35101,7,kernel,0,"[16, 4, 1]",0.761905,11353
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.992,16384,6939293132415.691,1,7,57,25,35118,7,kernel,0,"[16, 8, 1]",1.52381,11357
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939293132425.419,1,7,48,0,35131,7,kernel,0,"[2, 1, 1]",0.02381,11361
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939293132433.963,1,7,22,5,35146,7,kernel,0,"[50, 1, 1]",0.595238,11372
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.944,25600,6939293132657.675,1,7,80,6,35178,7,kernel,0,"[8, 1, 8]",0.761905,11382
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.304,0,6939293132665.451,1,7,44,25,35179,7,kernel,0,"[16, 4, 1]",0.761905,11382
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.952,25600,6939293132668.523,1,7,80,6,35201,7,kernel,0,"[64, 1, 1]",0.761905,11386
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939293132675.275,1,7,48,0,35213,7,kernel,0,"[1, 1, 1]",0.011905,11390
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939293132910.346,1,7,22,5,35228,7,kernel,0,"[50, 1, 1]",0.595238,11401
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.432,0,6939293132913.163,1,7,30,0,35245,7,kernel,0,"[2, 2, 1]",0.047619,11404
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.401,0,6939293132916.298,1,7,30,100,35264,7,kernel,0,"[1024, 2, 1]",24.380953,11411
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.168,16,6939293133124.458,1,7,40,5,35301,7,kernel,0,"[50, 1, 1]",0.595238,11418
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.64,0,6939293133128.362,1,7,38,0,35303,7,kernel,0,"[2, 1, 1]",0.02381,11418
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939293133344.682,1,7,22,5,35332,7,kernel,0,"[50, 1, 1]",0.595238,11434
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.104,25600,6939293133347.498,1,7,80,6,35362,7,kernel,0,"[8, 1, 8]",0.761905,11446
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939293133355.434,1,7,44,25,35363,7,kernel,0,"[16, 4, 1]",0.761905,11446
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293133358.25,1,7,80,6,35385,7,kernel,0,"[64, 1, 1]",0.761905,11450
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.919,16,6939293133801.866,1,7,48,0,35397,7,kernel,0,"[1, 1, 1]",0.011905,11454
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939293133812.649,1,7,22,5,35460,7,kernel,0,"[50, 1, 1]",0.595238,11496
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.424,16,6939293133815.498,1,7,32,10,35474,7,kernel,0,"[25, 1, 1]",0.297619,11497
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.983,0,6939293133819.626,1,7,16,0,35487,7,kernel,0,"[2, 1, 1]",0.02381,11505
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.544,53504,6939293134067.657,1,7,236,0,35501,7,kernel,0,"[1, 8, 1]",0.095238,11490
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293136147.975,1,7,16,15,35559,7,kernel,0,"[150, 1, 1]",1.785714,11555
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293136153.351,1,7,16,15,35584,7,kernel,0,"[150, 1, 1]",1.785714,11565
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939293136157.863,1,7,22,15,35598,7,kernel,0,"[150, 1, 1]",1.785714,11569
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293136160.391,1,7,16,15,35618,7,kernel,0,"[150, 1, 1]",1.785714,11576
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939293136164.999,1,7,22,15,35632,7,kernel,0,"[150, 1, 1]",1.785714,11580
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939293136167.495,1,7,16,30,35667,7,kernel,0,"[300, 1, 1]",3.571429,11601
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.056,16384,6939293136170.599,1,7,57,38,35693,7,kernel,0,"[4, 2, 24]",2.285714,11612
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939293136184.455,1,7,44,25,35695,7,kernel,0,"[16, 4, 1]",0.761905,11612
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.16,16384,6939293136188.039,1,7,57,38,35712,7,kernel,0,"[16, 12, 1]",2.285714,11616
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939293136200.999,1,7,48,0,35725,7,kernel,0,"[3, 1, 1]",0.035714,11620
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939293136209.575,1,7,22,5,35748,7,kernel,0,"[50, 1, 1]",0.595238,11639
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939293136212.039,1,7,40,5,35783,7,kernel,0,"[50, 1, 1]",0.595238,11642
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939293136215.623,1,7,38,0,35785,7,kernel,0,"[2, 1, 1]",0.02381,11642
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939293136220.807,1,7,22,5,35814,7,kernel,0,"[50, 1, 1]",0.595238,11658
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.52,16384,6939293136223.271,1,7,57,25,35840,7,kernel,0,"[16, 2, 4]",1.52381,11670
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.072,0,6939293136239.559,1,7,44,67,35842,7,kernel,0,"[64, 4, 1]",3.047619,11670
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.208,16384,6939293136243.687,1,7,57,51,35859,7,kernel,0,"[16, 16, 1]",3.047619,11674
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.952,16,6939293136258.663,1,7,48,0,35872,7,kernel,0,"[1, 1, 1]",0.011905,11678
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.624,0,6939293136265.319,1,7,22,20,35905,7,kernel,0,"[200, 1, 1]",2.380952,11699
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.072,0,6939293136268.743,1,7,22,20,35919,7,kernel,0,"[200, 1, 1]",2.380952,11704
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.976,16384,6939293136272.519,1,7,57,44,35944,7,kernel,0,"[4, 2, 28]",2.666667,11714
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.648,0,6939293136288.263,1,7,44,25,35946,7,kernel,0,"[16, 4, 1]",0.761905,11714
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.888,16384,6939293136292.678,1,7,57,51,35963,7,kernel,0,"[16, 16, 1]",3.047619,11718
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.559,16,6939293136307.271,1,7,48,0,35976,7,kernel,0,"[4, 1, 1]",0.047619,11722
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939293136314.599,1,7,22,5,35999,7,kernel,0,"[50, 1, 1]",0.595238,11741
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939293136317.159,1,7,40,5,36034,7,kernel,0,"[50, 1, 1]",0.595238,11744
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.383,0,6939293136320.807,1,7,38,0,36036,7,kernel,0,"[2, 1, 1]",0.02381,11744
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939293136686.502,1,7,22,5,36065,7,kernel,0,"[50, 1, 1]",0.595238,11760
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939293136689.318,1,7,80,6,36095,7,kernel,0,"[8, 1, 8]",0.761905,11772
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939293136697.318,1,7,44,25,36096,7,kernel,0,"[16, 4, 1]",0.761905,11772
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939293136700.134,1,7,80,6,36118,7,kernel,0,"[64, 1, 1]",0.761905,11776
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.064,16,6939293136707.046,1,7,48,0,36130,7,kernel,0,"[1, 1, 1]",0.011905,11780
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939293137050.918,1,7,22,5,36193,7,kernel,0,"[50, 1, 1]",0.595238,11822
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939293137053.894,1,7,32,10,36207,7,kernel,0,"[25, 1, 1]",0.297619,11823
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.369,0,6939293137272.901,1,7,16,0,36220,7,kernel,0,"[2, 1, 1]",0.02381,11831
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.641,53504,6939293137276.069,1,7,236,0,36234,7,kernel,0,"[1, 8, 1]",0.095238,11816
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293137656.357,1,7,16,10,36292,7,kernel,0,"[100, 1, 1]",1.190476,11881
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939293137661.605,1,7,16,10,36317,7,kernel,0,"[100, 1, 1]",1.190476,11891
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.847,0,6939293138137.285,1,7,22,10,36331,7,kernel,0,"[100, 1, 1]",1.190476,11895
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.431,0,6939293138140.869,1,7,16,20,36366,7,kernel,0,"[200, 1, 1]",2.380952,11916
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.304,16384,6939293138144.005,1,7,57,25,36392,7,kernel,0,"[4, 2, 16]",1.52381,11927
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.337,0,6939293138155.044,1,7,44,25,36394,7,kernel,0,"[16, 4, 1]",0.761905,11927
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.095,16384,6939293138158.149,1,7,57,25,36411,7,kernel,0,"[16, 8, 1]",1.52381,11931
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939293138166.981,1,7,48,0,36424,7,kernel,0,"[2, 1, 1]",0.02381,11935
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939293138834.116,1,7,22,5,36439,7,kernel,0,"[50, 1, 1]",0.595238,11946
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.296,25600,6939293138837.028,1,7,80,6,36471,7,kernel,0,"[8, 1, 8]",0.761905,11956
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939293138845.092,1,7,44,25,36472,7,kernel,0,"[16, 4, 1]",0.761905,11956
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.952,25600,6939293138847.876,1,7,80,6,36494,7,kernel,0,"[64, 1, 1]",0.761905,11960
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.903,16,6939293138854.628,1,7,48,0,36506,7,kernel,0,"[1, 1, 1]",0.011905,11964
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939293138863.236,1,7,22,5,36521,7,kernel,0,"[50, 1, 1]",0.595238,11975
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.176,0,6939293138865.86,1,7,30,0,36538,7,kernel,0,"[2, 2, 1]",0.047619,11978
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",9.056,0,6939293138868.804,1,7,30,100,36557,7,kernel,0,"[1024, 2, 1]",24.380953,11985
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939293138878.628,1,7,40,5,36594,7,kernel,0,"[50, 1, 1]",0.595238,11992
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.385,0,6939293138882.211,1,7,38,0,36596,7,kernel,0,"[2, 1, 1]",0.02381,11992
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939293139393.603,1,7,22,5,36625,7,kernel,0,"[50, 1, 1]",0.595238,12008
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939293139396.387,1,7,80,6,36655,7,kernel,0,"[8, 1, 8]",0.761905,12020
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293139404.419,1,7,44,25,36656,7,kernel,0,"[16, 4, 1]",0.761905,12020
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939293139407.235,1,7,80,6,36678,7,kernel,0,"[64, 1, 1]",0.761905,12024
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939293139414.019,1,7,48,0,36690,7,kernel,0,"[1, 1, 1]",0.011905,12028
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939293139628.995,1,7,22,5,36753,7,kernel,0,"[50, 1, 1]",0.595238,12070
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939293139632.163,1,7,32,10,36767,7,kernel,0,"[25, 1, 1]",0.297619,12071
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293139636.451,1,7,16,0,36780,7,kernel,0,"[2, 1, 1]",0.02381,12079
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.512,53504,6939293139639.267,1,7,236,0,36794,7,kernel,0,"[1, 8, 1]",0.095238,12064
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293139919.906,1,7,16,15,36852,7,kernel,0,"[150, 1, 1]",1.785714,12129
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293140181.474,1,7,16,15,36877,7,kernel,0,"[150, 1, 1]",1.785714,12139
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.56,0,6939293140187.106,1,7,22,15,36891,7,kernel,0,"[150, 1, 1]",1.785714,12143
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293140190.37,1,7,16,15,36911,7,kernel,0,"[150, 1, 1]",1.785714,12150
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939293140194.818,1,7,22,15,36925,7,kernel,0,"[150, 1, 1]",1.785714,12154
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.944,0,6939293140433.922,1,7,16,30,36960,7,kernel,0,"[300, 1, 1]",3.571429,12175
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.728,16384,6939293140437.698,1,7,57,38,36986,7,kernel,0,"[4, 2, 24]",2.285714,12186
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939293140452.162,1,7,44,25,36988,7,kernel,0,"[16, 4, 1]",0.761905,12186
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.936,16384,6939293140455.618,1,7,57,38,37005,7,kernel,0,"[16, 12, 1]",2.285714,12190
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939293140468.29,1,7,48,0,37018,7,kernel,0,"[3, 1, 1]",0.035714,12194
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939293140686.69,1,7,22,5,37041,7,kernel,0,"[50, 1, 1]",0.595238,12213
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939293140689.57,1,7,40,5,37076,7,kernel,0,"[50, 1, 1]",0.595238,12216
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.385,0,6939293140693.505,1,7,38,0,37078,7,kernel,0,"[2, 1, 1]",0.02381,12216
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.103,16,6939293140889.346,1,7,40,5,37119,7,kernel,0,"[50, 1, 1]",0.595238,12230
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.864,0,6939293140893.281,1,7,38,0,37121,7,kernel,0,"[2, 1, 1]",0.02381,12230
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.791,0,6939293140898.978,1,7,22,5,37150,7,kernel,0,"[50, 1, 1]",0.595238,12246
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.44,16384,6939293141123.521,1,7,57,25,37176,7,kernel,0,"[16, 2, 4]",1.52381,12258
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.232,0,6939293141141.729,1,7,44,67,37178,7,kernel,0,"[64, 4, 1]",3.047619,12258
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.92,16384,6939293141145.665,1,7,57,51,37195,7,kernel,0,"[16, 16, 1]",3.047619,12262
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.808,16,6939293141160.417,1,7,48,0,37208,7,kernel,0,"[1, 1, 1]",0.011905,12266
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.232,0,6939293141774.337,1,7,22,20,37241,7,kernel,0,"[200, 1, 1]",2.380952,12287
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.008,0,6939293141778.401,1,7,22,20,37255,7,kernel,0,"[200, 1, 1]",2.380952,12292
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.384,16384,6939293141782.208,1,7,57,44,37280,7,kernel,0,"[4, 2, 28]",2.666667,12302
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.647,0,6939293141799.393,1,7,44,25,37282,7,kernel,0,"[16, 4, 1]",0.761905,12302
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.304,16384,6939293141803.84,1,7,57,51,37299,7,kernel,0,"[16, 16, 1]",3.047619,12306
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.488,16,6939293141818.912,1,7,48,0,37312,7,kernel,0,"[4, 1, 1]",0.047619,12310
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939293141827.168,1,7,22,5,37335,7,kernel,0,"[50, 1, 1]",0.595238,12329
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.072,16,6939293141829.792,1,7,40,5,37370,7,kernel,0,"[50, 1, 1]",0.595238,12332
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293141833.728,1,7,38,0,37372,7,kernel,0,"[2, 1, 1]",0.02381,12332
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939293142392.992,1,7,22,5,37401,7,kernel,0,"[50, 1, 1]",0.595238,12348
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.232,25600,6939293142395.968,1,7,80,6,37431,7,kernel,0,"[8, 1, 8]",0.761905,12360
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.049,0,6939293142404.031,1,7,44,25,37432,7,kernel,0,"[16, 4, 1]",0.761905,12360
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939293142406.88,1,7,80,6,37454,7,kernel,0,"[64, 1, 1]",0.761905,12364
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939293142413.76,1,7,48,0,37466,7,kernel,0,"[1, 1, 1]",0.011905,12368
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.441,0,6939293142422.399,1,7,22,5,37529,7,kernel,0,"[50, 1, 1]",0.595238,12410
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.296,16,6939293142424.832,1,7,32,10,37543,7,kernel,0,"[25, 1, 1]",0.297619,12411
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939293142882.367,1,7,16,0,37556,7,kernel,0,"[2, 1, 1]",0.02381,12419
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.96,53504,6939293142885.471,1,7,236,0,37570,7,kernel,0,"[1, 8, 1]",0.095238,12404
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.312,0,6939293142923.231,1,7,16,15,37628,7,kernel,0,"[150, 1, 1]",1.785714,12469
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293142927.711,1,7,16,15,37653,7,kernel,0,"[150, 1, 1]",1.785714,12479
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.912,0,6939293143168.191,1,7,22,15,37667,7,kernel,0,"[150, 1, 1]",1.785714,12483
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.28,0,6939293143171.807,1,7,16,15,37687,7,kernel,0,"[150, 1, 1]",1.785714,12490
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939293143176.799,1,7,22,15,37701,7,kernel,0,"[150, 1, 1]",1.785714,12494
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.168,0,6939293143382.942,1,7,16,30,37736,7,kernel,0,"[300, 1, 1]",3.571429,12515
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.504,16384,6939293143386.847,1,7,57,38,37762,7,kernel,0,"[4, 2, 24]",2.285714,12526
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939293143401.215,1,7,44,25,37764,7,kernel,0,"[16, 4, 1]",0.761905,12526
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.257,16384,6939293143404.798,1,7,57,38,37781,7,kernel,0,"[16, 12, 1]",2.285714,12530
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.824,16,6939293143649.662,1,7,48,0,37794,7,kernel,0,"[3, 1, 1]",0.035714,12534
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939293143660.35,1,7,22,5,37817,7,kernel,0,"[50, 1, 1]",0.595238,12553
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.2,16,6939293143972.638,1,7,40,5,37852,7,kernel,0,"[50, 1, 1]",0.595238,12556
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.8,0,6939293143976.574,1,7,38,0,37854,7,kernel,0,"[2, 1, 1]",0.02381,12556
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293143982.142,1,7,22,5,37883,7,kernel,0,"[50, 1, 1]",0.595238,12572
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.128,16384,6939293143984.606,1,7,57,25,37909,7,kernel,0,"[16, 2, 4]",1.52381,12584
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939293144001.566,1,7,44,67,37911,7,kernel,0,"[64, 4, 1]",3.047619,12584
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.112,16384,6939293144005.15,1,7,57,51,37928,7,kernel,0,"[16, 16, 1]",3.047619,12588
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939293144020.094,1,7,48,0,37941,7,kernel,0,"[1, 1, 1]",0.011905,12592
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.816,0,6939293144237.149,1,7,22,20,37974,7,kernel,0,"[200, 1, 1]",2.380952,12613
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.105,0,6939293144240.733,1,7,22,20,37988,7,kernel,0,"[200, 1, 1]",2.380952,12618
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.16,16384,6939293144434.461,1,7,57,44,38013,7,kernel,0,"[4, 2, 28]",2.666667,12628
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.744,0,6939293144451.389,1,7,44,25,38015,7,kernel,0,"[16, 4, 1]",0.761905,12628
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.984,16384,6939293144455.805,1,7,57,51,38032,7,kernel,0,"[16, 16, 1]",3.047619,12632
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939293144470.589,1,7,48,0,38045,7,kernel,0,"[4, 1, 1]",0.047619,12636
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939293144709.821,1,7,22,5,38068,7,kernel,0,"[50, 1, 1]",0.595238,12655
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.136,16,6939293144712.925,1,7,40,5,38103,7,kernel,0,"[50, 1, 1]",0.595238,12658
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293144716.861,1,7,38,0,38105,7,kernel,0,"[2, 1, 1]",0.02381,12658
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.081,0,6939293145046.428,1,7,22,5,38134,7,kernel,0,"[50, 1, 1]",0.595238,12674
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.169,25600,6939293145049.372,1,7,80,6,38164,7,kernel,0,"[8, 1, 8]",0.761905,12686
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293145057.245,1,7,44,25,38165,7,kernel,0,"[16, 4, 1]",0.761905,12686
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.049,25600,6939293145060.092,1,7,80,6,38187,7,kernel,0,"[64, 1, 1]",0.761905,12690
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939293145067.037,1,7,48,0,38199,7,kernel,0,"[1, 1, 1]",0.011905,12694
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939293147363.738,1,7,22,5,38262,7,kernel,0,"[50, 1, 1]",0.595238,12736
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939293147366.714,1,7,32,10,38276,7,kernel,0,"[25, 1, 1]",0.297619,12737
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939293147370.97,1,7,16,0,38289,7,kernel,0,"[2, 1, 1]",0.02381,12745
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.48,53504,6939293147373.786,1,7,236,0,38303,7,kernel,0,"[1, 8, 1]",0.095238,12730
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939293147411.13,1,7,16,15,38361,7,kernel,0,"[150, 1, 1]",1.785714,12795
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293147415.514,1,7,16,15,38386,7,kernel,0,"[150, 1, 1]",1.785714,12805
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293147419.994,1,7,22,15,38400,7,kernel,0,"[150, 1, 1]",1.785714,12809
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293147422.49,1,7,16,15,38420,7,kernel,0,"[150, 1, 1]",1.785714,12816
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939293147426.586,1,7,22,15,38434,7,kernel,0,"[150, 1, 1]",1.785714,12820
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.208,0,6939293147429.082,1,7,16,30,38469,7,kernel,0,"[300, 1, 1]",3.571429,12841
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.024,16384,6939293147432.026,1,7,57,38,38495,7,kernel,0,"[4, 2, 24]",2.285714,12852
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.816,0,6939293147445.85,1,7,44,25,38497,7,kernel,0,"[16, 4, 1]",0.761905,12852
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.84,16384,6939293147449.498,1,7,57,38,38514,7,kernel,0,"[16, 12, 1]",2.285714,12856
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939293147462.138,1,7,48,0,38527,7,kernel,0,"[3, 1, 1]",0.035714,12860
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.92,0,6939293147470.874,1,7,22,5,38550,7,kernel,0,"[50, 1, 1]",0.595238,12879
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.912,16,6939293147473.626,1,7,40,5,38585,7,kernel,0,"[50, 1, 1]",0.595238,12882
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939293147477.306,1,7,38,0,38587,7,kernel,0,"[2, 1, 1]",0.02381,12882
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939293147482.458,1,7,22,5,38616,7,kernel,0,"[50, 1, 1]",0.595238,12898
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.968,16384,6939293147485.082,1,7,57,25,38642,7,kernel,0,"[16, 2, 4]",1.52381,12910
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939293147501.786,1,7,44,67,38644,7,kernel,0,"[64, 4, 1]",3.047619,12910
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.424,16384,6939293147505.562,1,7,57,51,38661,7,kernel,0,"[16, 16, 1]",3.047619,12914
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.792,16,6939293147521.754,1,7,48,0,38674,7,kernel,0,"[1, 1, 1]",0.011905,12918
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.56,0,6939293147528.25,1,7,22,20,38707,7,kernel,0,"[200, 1, 1]",2.380952,12939
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.168,0,6939293147531.546,1,7,22,20,38721,7,kernel,0,"[200, 1, 1]",2.380952,12944
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.976,16384,6939293147535.482,1,7,57,44,38746,7,kernel,0,"[4, 2, 28]",2.666667,12954
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.232,0,6939293147551.162,1,7,44,25,38748,7,kernel,0,"[16, 4, 1]",0.761905,12954
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.728,16384,6939293147555.194,1,7,57,51,38765,7,kernel,0,"[16, 16, 1]",3.047619,12958
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.496,16,6939293147569.69,1,7,48,0,38778,7,kernel,0,"[4, 1, 1]",0.047619,12962
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939293147576.986,1,7,22,5,38801,7,kernel,0,"[50, 1, 1]",0.595238,12981
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.752,16,6939293147579.578,1,7,40,5,38836,7,kernel,0,"[50, 1, 1]",0.595238,12984
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.513,0,6939293147583.129,1,7,38,0,38838,7,kernel,0,"[2, 1, 1]",0.02381,12984
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939293149975.383,1,7,22,5,38867,7,kernel,0,"[50, 1, 1]",0.595238,13000
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939293149978.167,1,7,80,6,38897,7,kernel,0,"[8, 1, 8]",0.761905,13012
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939293149986.135,1,7,44,25,38898,7,kernel,0,"[16, 4, 1]",0.761905,13012
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939293149988.983,1,7,80,6,38920,7,kernel,0,"[64, 1, 1]",0.761905,13016
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.936,16,6939293149995.735,1,7,48,0,38932,7,kernel,0,"[1, 1, 1]",0.011905,13020
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939293150004.471,1,7,22,5,38995,7,kernel,0,"[50, 1, 1]",0.595238,13062
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.36,16,6939293150006.679,1,7,32,10,39009,7,kernel,0,"[25, 1, 1]",0.297619,13063
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939293150010.775,1,7,16,0,39022,7,kernel,0,"[2, 1, 1]",0.02381,13071
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.608,53504,6939293150013.591,1,7,236,0,39036,7,kernel,0,"[1, 8, 1]",0.095238,13056
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939293150051.191,1,7,16,15,39094,7,kernel,0,"[150, 1, 1]",1.785714,13121
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293150055.479,1,7,16,15,39119,7,kernel,0,"[150, 1, 1]",1.785714,13131
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293150059.991,1,7,22,15,39133,7,kernel,0,"[150, 1, 1]",1.785714,13135
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293150062.487,1,7,16,15,39153,7,kernel,0,"[150, 1, 1]",1.785714,13142
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939293150066.615,1,7,22,15,39167,7,kernel,0,"[150, 1, 1]",1.785714,13146
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939293150069.111,1,7,16,30,39202,7,kernel,0,"[300, 1, 1]",3.571429,13167
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.192,16384,6939293150072.055,1,7,57,38,39228,7,kernel,0,"[4, 2, 24]",2.285714,13178
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.712,0,6939293150085.079,1,7,44,25,39230,7,kernel,0,"[16, 4, 1]",0.761905,13178
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.424,16384,6939293150089.495,1,7,57,38,39247,7,kernel,0,"[16, 12, 1]",2.285714,13182
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939293150101.623,1,7,48,0,39260,7,kernel,0,"[3, 1, 1]",0.035714,13186
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939293150110.135,1,7,22,5,39283,7,kernel,0,"[50, 1, 1]",0.595238,13205
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939293150112.759,1,7,40,5,39318,7,kernel,0,"[50, 1, 1]",0.595238,13208
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939293150116.375,1,7,38,0,39320,7,kernel,0,"[2, 1, 1]",0.02381,13208
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939293150121.623,1,7,22,5,39349,7,kernel,0,"[50, 1, 1]",0.595238,13224
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.36,16384,6939293150124.055,1,7,57,25,39375,7,kernel,0,"[16, 2, 4]",1.52381,13236
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939293150140.215,1,7,44,67,39377,7,kernel,0,"[64, 4, 1]",3.047619,13236
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.616,16384,6939293150143.959,1,7,57,51,39394,7,kernel,0,"[16, 16, 1]",3.047619,13240
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.536,16,6939293150160.343,1,7,48,0,39407,7,kernel,0,"[1, 1, 1]",0.011905,13244
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.624,0,6939293150166.743,1,7,22,20,39440,7,kernel,0,"[200, 1, 1]",2.380952,13265
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.2,0,6939293150170.167,1,7,22,20,39454,7,kernel,0,"[200, 1, 1]",2.380952,13270
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.944,16384,6939293150174.103,1,7,57,44,39479,7,kernel,0,"[4, 2, 28]",2.666667,13280
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.552,0,6939293150189.879,1,7,44,25,39481,7,kernel,0,"[16, 4, 1]",0.761905,13280
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.983,16384,6939293150194.199,1,7,57,51,39498,7,kernel,0,"[16, 16, 1]",3.047619,13284
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.856,16,6939293152508.244,1,7,48,0,39511,7,kernel,0,"[4, 1, 1]",0.047619,13288
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939293152518.9,1,7,22,5,39534,7,kernel,0,"[50, 1, 1]",0.595238,13307
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939293152521.844,1,7,40,5,39569,7,kernel,0,"[50, 1, 1]",0.595238,13310
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939293152525.396,1,7,38,0,39571,7,kernel,0,"[2, 1, 1]",0.02381,13310
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939293152530.612,1,7,22,5,39600,7,kernel,0,"[50, 1, 1]",0.595238,13326
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939293152533.268,1,7,80,6,39630,7,kernel,0,"[8, 1, 8]",0.761905,13338
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939293152541.204,1,7,44,25,39631,7,kernel,0,"[16, 4, 1]",0.761905,13338
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.984,25600,6939293152543.924,1,7,80,6,39653,7,kernel,0,"[64, 1, 1]",0.761905,13342
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.336,16,6939293152550.74,1,7,48,0,39665,7,kernel,0,"[1, 1, 1]",0.011905,13346
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939293152557.844,1,7,22,5,39728,7,kernel,0,"[50, 1, 1]",0.595238,13388
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.36,16,6939293152560.084,1,7,32,10,39742,7,kernel,0,"[25, 1, 1]",0.297619,13389
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293152564.276,1,7,16,0,39755,7,kernel,0,"[2, 1, 1]",0.02381,13397
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.152,53504,6939293152567.092,1,7,236,0,39769,7,kernel,0,"[1, 8, 1]",0.095238,13382
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939293152605.236,1,7,16,15,39827,7,kernel,0,"[150, 1, 1]",1.785714,13447
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939293160481.419,1,7,16,15,39852,7,kernel,0,"[150, 1, 1]",1.785714,13457
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939293160486.635,1,7,22,15,39866,7,kernel,0,"[150, 1, 1]",1.785714,13461
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939293161361.194,1,7,16,15,39886,7,kernel,0,"[150, 1, 1]",1.785714,13468
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.528,0,6939293161366.666,1,7,22,15,39900,7,kernel,0,"[150, 1, 1]",1.785714,13472
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939293161369.994,1,7,16,30,39935,7,kernel,0,"[300, 1, 1]",3.571429,13493
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.184,16384,6939293161373.098,1,7,57,38,39961,7,kernel,0,"[4, 2, 24]",2.285714,13504
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939293161387.018,1,7,44,25,39963,7,kernel,0,"[16, 4, 1]",0.761905,13504
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.32,16384,6939293161390.506,1,7,57,38,39980,7,kernel,0,"[16, 12, 1]",2.285714,13508
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939293161403.562,1,7,48,0,39993,7,kernel,0,"[3, 1, 1]",0.035714,13512
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939293161412.17,1,7,22,5,40016,7,kernel,0,"[50, 1, 1]",0.595238,13531
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939293161414.73,1,7,40,5,40051,7,kernel,0,"[50, 1, 1]",0.595238,13534
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939293161418.346,1,7,38,0,40053,7,kernel,0,"[2, 1, 1]",0.02381,13534
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939293162975.368,1,7,22,5,40082,7,kernel,0,"[50, 1, 1]",0.595238,13550
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.216,16384,6939293162978.152,1,7,57,25,40108,7,kernel,0,"[16, 2, 4]",1.52381,13562
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939293162996.072,1,7,44,67,40110,7,kernel,0,"[64, 4, 1]",3.047619,13562
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.08,16384,6939293162999.72,1,7,57,51,40127,7,kernel,0,"[16, 16, 1]",3.047619,13566
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939293163014.632,1,7,48,0,40140,7,kernel,0,"[1, 1, 1]",0.011905,13570
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939293163023.24,1,7,22,20,40173,7,kernel,0,"[200, 1, 1]",2.380952,13591
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939293163026.344,1,7,22,20,40187,7,kernel,0,"[200, 1, 1]",2.380952,13596
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.88,16384,6939293163030.12,1,7,57,44,40212,7,kernel,0,"[4, 2, 28]",2.666667,13606
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.328,0,6939293163045.832,1,7,44,25,40214,7,kernel,0,"[16, 4, 1]",0.761905,13606
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.048,16384,6939293163049.928,1,7,57,51,40231,7,kernel,0,"[16, 16, 1]",3.047619,13610
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.008,16,6939293163064.744,1,7,48,0,40244,7,kernel,0,"[4, 1, 1]",0.047619,13614
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939293163072.552,1,7,22,5,40267,7,kernel,0,"[50, 1, 1]",0.595238,13633
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939293163075.176,1,7,40,5,40302,7,kernel,0,"[50, 1, 1]",0.595238,13636
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939293163078.76,1,7,38,0,40304,7,kernel,0,"[2, 1, 1]",0.02381,13636
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939293163084.104,1,7,22,5,40333,7,kernel,0,"[50, 1, 1]",0.595238,13652
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.04,25600,6939293163086.6,1,7,80,6,40363,7,kernel,0,"[8, 1, 8]",0.761905,13664
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.92,0,6939293163094.472,1,7,44,25,40364,7,kernel,0,"[16, 4, 1]",0.761905,13664
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.24,25600,6939293163097.128,1,7,80,6,40386,7,kernel,0,"[64, 1, 1]",0.761905,13668
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.816,16,6939293163104.168,1,7,48,0,40398,7,kernel,0,"[1, 1, 1]",0.011905,13672
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939293163734.151,1,7,22,5,40461,7,kernel,0,"[50, 1, 1]",0.595238,13714
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939293163737.127,1,7,32,10,40475,7,kernel,0,"[25, 1, 1]",0.297619,13715
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939293163741.415,1,7,16,0,40488,7,kernel,0,"[2, 1, 1]",0.02381,13723
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.672,53504,6939293163744.167,1,7,236,0,40502,7,kernel,0,"[1, 8, 1]",0.095238,13708
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939293163781.863,1,7,16,15,40560,7,kernel,0,"[150, 1, 1]",1.785714,13773
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939293164756.614,1,7,16,15,40585,7,kernel,0,"[150, 1, 1]",1.785714,13783
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.432,0,6939293164761.414,1,7,22,15,40599,7,kernel,0,"[150, 1, 1]",1.785714,13787
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293164764.55,1,7,16,15,40619,7,kernel,0,"[150, 1, 1]",1.785714,13794
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939293164769.126,1,7,22,15,40633,7,kernel,0,"[150, 1, 1]",1.785714,13798
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939293164771.494,1,7,16,30,40668,7,kernel,0,"[300, 1, 1]",3.571429,13819
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.088,16384,6939293164774.598,1,7,57,38,40694,7,kernel,0,"[4, 2, 24]",2.285714,13830
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939293164788.422,1,7,44,25,40696,7,kernel,0,"[16, 4, 1]",0.761905,13830
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.064,16384,6939293164792.07,1,7,57,38,40713,7,kernel,0,"[16, 12, 1]",2.285714,13834
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939293164804.998,1,7,48,0,40726,7,kernel,0,"[3, 1, 1]",0.035714,13838
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939293164813.478,1,7,22,5,40749,7,kernel,0,"[50, 1, 1]",0.595238,13857
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.136,16,6939293166095.044,1,7,40,5,40784,7,kernel,0,"[50, 1, 1]",0.595238,13860
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.64,0,6939293166098.948,1,7,38,0,40786,7,kernel,0,"[2, 1, 1]",0.02381,13860
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939293166104.292,1,7,22,5,40815,7,kernel,0,"[50, 1, 1]",0.595238,13876
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.64,16384,6939293166106.948,1,7,57,25,40841,7,kernel,0,"[16, 2, 4]",1.52381,13888
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.816,0,6939293166124.324,1,7,44,67,40843,7,kernel,0,"[64, 4, 1]",3.047619,13888
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.144,16384,6939293166127.908,1,7,57,51,40860,7,kernel,0,"[16, 16, 1]",3.047619,13892
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939293166142.852,1,7,48,0,40873,7,kernel,0,"[1, 1, 1]",0.011905,13896
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.336,0,6939293166151.428,1,7,22,20,40906,7,kernel,0,"[200, 1, 1]",2.380952,13917
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.072,0,6939293166154.564,1,7,22,20,40920,7,kernel,0,"[200, 1, 1]",2.380952,13922
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.896,16384,6939293181682.163,1,7,57,44,40945,7,kernel,0,"[4, 2, 28]",2.666667,13932
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.68,0,6939293181699.858,1,7,44,25,40947,7,kernel,0,"[16, 4, 1]",0.761905,13932
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.752,16384,6939293181704.306,1,7,57,51,40964,7,kernel,0,"[16, 16, 1]",3.047619,13936
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.504,16,6939293182137.234,1,7,48,0,40977,7,kernel,0,"[4, 1, 1]",0.047619,13940
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939293182147.506,1,7,22,5,41000,7,kernel,0,"[50, 1, 1]",0.595238,13959
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939293182150.322,1,7,40,5,41035,7,kernel,0,"[50, 1, 1]",0.595238,13962
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939293182153.938,1,7,38,0,41037,7,kernel,0,"[2, 1, 1]",0.02381,13962
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939293182159.154,1,7,22,5,41066,7,kernel,0,"[50, 1, 1]",0.595238,13978
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.912,25600,6939293182564.241,1,7,80,6,41096,7,kernel,0,"[8, 1, 8]",0.761905,13990
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939293182572.017,1,7,44,25,41097,7,kernel,0,"[16, 4, 1]",0.761905,13990
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939293182575.185,1,7,80,6,41119,7,kernel,0,"[64, 1, 1]",0.761905,13994
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939293182582.097,1,7,48,0,41131,7,kernel,0,"[1, 1, 1]",0.011905,13998
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939293183008.913,1,7,22,5,41194,7,kernel,0,"[50, 1, 1]",0.595238,14040
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.488,16,6939293183011.889,1,7,32,10,41208,7,kernel,0,"[25, 1, 1]",0.297619,14041
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939293183016.145,1,7,16,0,41221,7,kernel,0,"[2, 1, 1]",0.02381,14049
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.576,53504,6939293183018.961,1,7,236,0,41235,7,kernel,0,"[1, 8, 1]",0.095238,14034
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293183462.384,1,7,16,15,41293,7,kernel,0,"[150, 1, 1]",1.785714,14099
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939293183467.984,1,7,16,15,41318,7,kernel,0,"[150, 1, 1]",1.785714,14109
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939293183472.592,1,7,22,15,41332,7,kernel,0,"[150, 1, 1]",1.785714,14113
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939293183674.352,1,7,16,15,41352,7,kernel,0,"[150, 1, 1]",1.785714,14120
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939293183679.824,1,7,22,15,41366,7,kernel,0,"[150, 1, 1]",1.785714,14124
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939293183868.24,1,7,16,30,41401,7,kernel,0,"[300, 1, 1]",3.571429,14145
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.768,16384,6939293183880.752,1,7,57,38,41427,7,kernel,0,"[4, 2, 24]",2.285714,14156
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939293183894.32,1,7,44,25,41429,7,kernel,0,"[16, 4, 1]",0.761905,14156
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.352,16384,6939293183952.624,1,7,57,38,41446,7,kernel,0,"[16, 12, 1]",2.285714,14160
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.888,16,6939293184164.72,1,7,48,0,41459,7,kernel,0,"[3, 1, 1]",0.035714,14164
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939293184368.655,1,7,22,5,41482,7,kernel,0,"[50, 1, 1]",0.595238,14183
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.44,0,6939293184371.599,1,7,16,5,41514,7,kernel,0,"[50, 1, 1]",0.595238,14200
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.888,0,6939293184568.847,1,7,16,51,41539,7,kernel,0,"[512, 1, 1]",6.095238,14210
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939293184573.711,1,7,16,51,41564,7,kernel,0,"[512, 1, 1]",6.095238,14220
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",35.52,0,6939293184753.647,1,7,16,100,41591,7,kernel,0,"[10000, 1, 1]",119.047623,14232
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.736,8192,6939293184789.871,1,7,24,13,41598,7,kernel,0,"[16, 1, 1]",0.190476,14227
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.439,0,6939293185000.111,1,7,16,5,41624,7,kernel,0,"[50, 1, 1]",0.595238,14245
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.569,0,6939293185005.134,1,7,16,51,41649,7,kernel,0,"[512, 1, 1]",6.095238,14255
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.92,0,6939293185207.95,1,7,16,51,41674,7,kernel,0,"[512, 1, 1]",6.095238,14265
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.808,0,6939293185215.63,1,7,22,51,41688,7,kernel,0,"[512, 1, 1]",6.095238,14269
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",36.608,0,6939293185220.238,1,7,16,100,41714,7,kernel,0,"[10000, 1, 1]",119.047623,14282
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.992,8192,6939293185257.678,1,7,24,13,41721,7,kernel,0,"[16, 1, 1]",0.190476,14277
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",428.127,0,6939293215951.659,1,7,40,100,41733,7,kernel,0,"[320, 1, 1]",3.809524,8200
0,51.238094,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",325.376,0,6939293216380.554,1,7,40,100,41736,7,kernel,0,"[269, 1, 1]",3.202381,8200
0,54.285713,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",350.015,0,6939293216706.634,1,7,40,100,41739,7,kernel,0,"[285, 1, 1]",3.392857,8200
0,31.238094,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",203.648,0,6939293217057.481,1,7,40,65,41742,7,kernel,0,"[164, 1, 1]",1.952381,8200
