pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.472,0,6939565712147.097,1,7,16,0,78910,7,kernel,0,"[1, 1, 1]",0.011905,22534
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.775,0,6939565713382.551,1,7,16,100,78940,7,kernel,0,"[1954, 1, 1]",23.261906,23058
0,6.857143,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params),0,"[128, 1, 1]",50.688,30720,6939565713571.862,1,7,126,14,78958,7,kernel,0,"[4, 1, 36]",1.714286,23054
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.16,0,6939565713623.414,1,7,44,25,78959,7,kernel,0,"[16, 4, 1]",0.761905,23054
0,93.047623,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.712,0,6939565713823.83,1,7,16,100,78977,7,kernel,0,"[1954, 1, 1]",23.261906,23066
0,119.238098,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",46.656,16384,6939565713828.278,1,7,57,67,78991,7,kernel,0,"[4, 313, 1]",14.904762,23062
0,3.809524,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",4.256,16,6939565713875.766,1,7,32,8,79004,7,kernel,0,"[20, 1, 1]",0.238095,23070
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.073,16,6939565714439.38,1,7,40,5,79057,7,kernel,0,"[50, 1, 1]",0.595238,23095
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.736,0,6939565714443.285,1,7,38,0,79059,7,kernel,0,"[2, 1, 1]",0.02381,23095
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.072,16,6939565715107.988,1,7,40,5,79100,7,kernel,0,"[50, 1, 1]",0.595238,23109
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.736,0,6939565715111.892,1,7,38,0,79102,7,kernel,0,"[2, 1, 1]",0.02381,23109
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.791,0,6939565715117.428,1,7,22,5,79131,7,kernel,0,"[50, 1, 1]",0.595238,23125
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.704,16384,6939565715361.843,1,7,57,25,79157,7,kernel,0,"[16, 2, 4]",1.52381,23137
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.392,0,6939565715379.315,1,7,44,67,79159,7,kernel,0,"[64, 4, 1]",3.047619,23137
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.208,16384,6939565715383.571,1,7,57,51,79176,7,kernel,0,"[16, 16, 1]",3.047619,23141
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.08,16,6939565715665.715,1,7,48,0,79189,7,kernel,0,"[1, 1, 1]",0.011905,23145
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.296,0,6939565716897.649,1,7,22,20,79222,7,kernel,0,"[200, 1, 1]",2.380952,23166
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.135,0,6939565716901.681,1,7,22,20,79236,7,kernel,0,"[200, 1, 1]",2.380952,23171
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.352,16384,6939565716905.649,1,7,57,44,79261,7,kernel,0,"[4, 2, 28]",2.666667,23181
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.648,0,6939565716922.737,1,7,44,25,79263,7,kernel,0,"[16, 4, 1]",0.761905,23181
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.431,16384,6939565716927.185,1,7,57,51,79280,7,kernel,0,"[16, 16, 1]",3.047619,23185
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.584,16,6939565716942.417,1,7,48,0,79293,7,kernel,0,"[4, 1, 1]",0.047619,23189
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.92,0,6939565716950.768,1,7,22,5,79316,7,kernel,0,"[50, 1, 1]",0.595238,23208
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.975,16,6939565716953.425,1,7,40,5,79351,7,kernel,0,"[50, 1, 1]",0.595238,23211
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565716957.169,1,7,38,0,79353,7,kernel,0,"[2, 1, 1]",0.02381,23211
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.079,0,6939565718178.863,1,7,22,5,79382,7,kernel,0,"[50, 1, 1]",0.595238,23227
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.328,25600,6939565718181.679,1,7,80,6,79412,7,kernel,0,"[8, 1, 8]",0.761905,23239
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.049,0,6939565718189.71,1,7,44,25,79413,7,kernel,0,"[16, 4, 1]",0.761905,23239
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.113,25600,6939565718192.526,1,7,80,6,79435,7,kernel,0,"[64, 1, 1]",0.761905,23243
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.999,16,6939565718199.471,1,7,48,0,79447,7,kernel,0,"[1, 1, 1]",0.011905,23247
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.209,0,6939565718834.797,1,7,22,5,79510,7,kernel,0,"[50, 1, 1]",0.595238,23289
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.519,16,6939565718837.838,1,7,32,10,79524,7,kernel,0,"[25, 1, 1]",0.297619,23290
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.015,0,6939565718842.094,1,7,16,0,79537,7,kernel,0,"[2, 1, 1]",0.02381,23298
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.607,53504,6939565718844.91,1,7,236,0,79551,7,kernel,0,"[1, 8, 1]",0.095238,23283
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565720225.739,1,7,16,10,79609,7,kernel,0,"[100, 1, 1]",1.190476,23348
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565720231.371,1,7,16,10,79634,7,kernel,0,"[100, 1, 1]",1.190476,23358
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565720236.171,1,7,22,10,79648,7,kernel,0,"[100, 1, 1]",1.190476,23362
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.304,0,6939565720238.507,1,7,16,20,79683,7,kernel,0,"[200, 1, 1]",2.380952,23383
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.888,16384,6939565721205.738,1,7,57,25,79709,7,kernel,0,"[4, 2, 16]",1.52381,23394
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.689,0,6939565721216.361,1,7,44,25,79711,7,kernel,0,"[16, 4, 1]",0.761905,23394
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.192,16384,6939565721220.074,1,7,57,25,79728,7,kernel,0,"[16, 8, 1]",1.52381,23398
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.033,16,6939565721229.001,1,7,48,0,79741,7,kernel,0,"[2, 1, 1]",0.02381,23402
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939565721237.769,1,7,80,6,79779,7,kernel,0,"[8, 1, 8]",0.761905,23422
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.983,0,6939565721245.77,1,7,44,25,79780,7,kernel,0,"[16, 4, 1]",0.761905,23422
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.952,25600,6939565721248.522,1,7,80,6,79802,7,kernel,0,"[64, 1, 1]",0.761905,23426
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.984,16,6939565721255.305,1,7,48,0,79814,7,kernel,0,"[1, 1, 1]",0.011905,23430
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.857,0,6939565721262.121,1,7,22,5,79829,7,kernel,0,"[50, 1, 1]",0.595238,23441
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.4,0,6939565721572.265,1,7,30,0,79846,7,kernel,0,"[2, 2, 1]",0.047619,23444
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.688,0,6939565721575.433,1,7,30,100,79865,7,kernel,0,"[1024, 2, 1]",24.380953,23451
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.105,16,6939565721869.704,1,7,40,5,79902,7,kernel,0,"[50, 1, 1]",0.595238,23458
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.704,0,6939565721873.512,1,7,38,0,79904,7,kernel,0,"[2, 1, 1]",0.02381,23458
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939565722325.064,1,7,22,5,79933,7,kernel,0,"[50, 1, 1]",0.595238,23474
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.552,25600,6939565722327.944,1,7,80,6,79963,7,kernel,0,"[8, 1, 8]",0.761905,23486
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565722336.328,1,7,44,25,79964,7,kernel,0,"[16, 4, 1]",0.761905,23486
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565722339.144,1,7,80,6,79986,7,kernel,0,"[64, 1, 1]",0.761905,23490
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.08,16,6939565722548.903,1,7,48,0,79998,7,kernel,0,"[1, 1, 1]",0.011905,23494
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939565722848.231,1,7,22,5,80061,7,kernel,0,"[50, 1, 1]",0.595238,23536
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.552,16,6939565722851.207,1,7,32,10,80075,7,kernel,0,"[25, 1, 1]",0.297619,23537
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.304,0,6939565723068.327,1,7,16,0,80088,7,kernel,0,"[2, 1, 1]",0.02381,23545
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.472,53504,6939565723071.463,1,7,236,0,80102,7,kernel,0,"[1, 8, 1]",0.095238,23530
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939565723461.35,1,7,16,15,80160,7,kernel,0,"[150, 1, 1]",1.785714,23595
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.601,0,6939565723702.917,1,7,16,15,80185,7,kernel,0,"[150, 1, 1]",1.785714,23605
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.463,0,6939565723708.422,1,7,22,15,80199,7,kernel,0,"[150, 1, 1]",1.785714,23609
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.217,0,6939565723711.717,1,7,16,15,80219,7,kernel,0,"[150, 1, 1]",1.785714,23616
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.976,0,6939565723916.709,1,7,22,15,80233,7,kernel,0,"[150, 1, 1]",1.785714,23620
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939565724132.421,1,7,16,30,80268,7,kernel,0,"[300, 1, 1]",3.571429,23641
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.6,16384,6939565724136.165,1,7,57,38,80294,7,kernel,0,"[4, 2, 24]",2.285714,23652
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939565724150.501,1,7,44,25,80296,7,kernel,0,"[16, 4, 1]",0.761905,23652
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.288,16384,6939565724154.053,1,7,57,38,80313,7,kernel,0,"[16, 12, 1]",2.285714,23656
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.888,16,6939565724776.164,1,7,48,0,80326,7,kernel,0,"[3, 1, 1]",0.035714,23660
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565724786.852,1,7,22,5,80349,7,kernel,0,"[50, 1, 1]",0.595238,23679
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939565724789.764,1,7,40,5,80384,7,kernel,0,"[50, 1, 1]",0.595238,23682
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565724793.38,1,7,38,0,80386,7,kernel,0,"[2, 1, 1]",0.02381,23682
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565724798.532,1,7,22,5,80415,7,kernel,0,"[50, 1, 1]",0.595238,23698
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.376,16384,6939565725266.595,1,7,57,25,80441,7,kernel,0,"[16, 2, 4]",1.52381,23710
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.136,0,6939565725284.803,1,7,44,67,80443,7,kernel,0,"[64, 4, 1]",3.047619,23710
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.888,16384,6939565725288.707,1,7,57,51,80460,7,kernel,0,"[16, 16, 1]",3.047619,23714
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.936,16,6939565725303.395,1,7,48,0,80473,7,kernel,0,"[1, 1, 1]",0.011905,23718
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.496,0,6939565725312.163,1,7,22,20,80506,7,kernel,0,"[200, 1, 1]",2.380952,23739
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.072,0,6939565725315.427,1,7,22,20,80520,7,kernel,0,"[200, 1, 1]",2.380952,23744
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.44,16384,6939565725768.13,1,7,57,44,80545,7,kernel,0,"[4, 2, 28]",2.666667,23754
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.424,0,6939565725786.274,1,7,44,25,80547,7,kernel,0,"[16, 4, 1]",0.761905,23754
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.784,16384,6939565725790.402,1,7,57,51,80564,7,kernel,0,"[16, 16, 1]",3.047619,23758
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.68,16,6939565725805.986,1,7,48,0,80577,7,kernel,0,"[4, 1, 1]",0.047619,23762
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565725814.402,1,7,22,5,80600,7,kernel,0,"[50, 1, 1]",0.595238,23781
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.008,16,6939565725816.866,1,7,40,5,80635,7,kernel,0,"[50, 1, 1]",0.595238,23784
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565725820.642,1,7,38,0,80637,7,kernel,0,"[2, 1, 1]",0.02381,23784
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939565726043.874,1,7,22,5,80666,7,kernel,0,"[50, 1, 1]",0.595238,23800
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.201,25600,6939565726258.625,1,7,80,6,80696,7,kernel,0,"[8, 1, 8]",0.761905,23812
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.304,0,6939565726266.561,1,7,44,25,80697,7,kernel,0,"[16, 4, 1]",0.761905,23812
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565726269.697,1,7,80,6,80719,7,kernel,0,"[64, 1, 1]",0.761905,23816
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565726276.897,1,7,48,0,80731,7,kernel,0,"[1, 1, 1]",0.011905,23820
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939565726614.209,1,7,22,5,80794,7,kernel,0,"[50, 1, 1]",0.595238,23862
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.552,16,6939565726617.345,1,7,32,10,80808,7,kernel,0,"[25, 1, 1]",0.297619,23863
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.048,0,6939565726621.633,1,7,16,0,80821,7,kernel,0,"[2, 1, 1]",0.02381,23871
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.576,53504,6939565726804.993,1,7,236,0,80835,7,kernel,0,"[1, 8, 1]",0.095238,23856
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939565727095.552,1,7,16,10,80893,7,kernel,0,"[100, 1, 1]",1.190476,23921
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565727320.128,1,7,16,10,80918,7,kernel,0,"[100, 1, 1]",1.190476,23931
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.855,0,6939565727325.728,1,7,22,10,80932,7,kernel,0,"[100, 1, 1]",1.190476,23935
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.912,0,6939565727919.583,1,7,16,20,80967,7,kernel,0,"[200, 1, 1]",2.380952,23956
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.272,16384,6939565727923.231,1,7,57,25,80993,7,kernel,0,"[4, 2, 16]",1.52381,23967
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.368,0,6939565727934.302,1,7,44,25,80995,7,kernel,0,"[16, 4, 1]",0.761905,23967
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.159,16384,6939565727937.439,1,7,57,25,81012,7,kernel,0,"[16, 8, 1]",1.52381,23971
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.775,16,6939565727946.431,1,7,48,0,81025,7,kernel,0,"[2, 1, 1]",0.02381,23975
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.857,0,6939565727955.038,1,7,22,5,81044,7,kernel,0,"[50, 1, 1]",0.595238,23986
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.943,25600,6939565727957.695,1,7,80,6,81076,7,kernel,0,"[8, 1, 8]",0.761905,23996
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.985,0,6939565727965.342,1,7,44,25,81077,7,kernel,0,"[16, 4, 1]",0.761905,23996
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565727968.159,1,7,80,6,81099,7,kernel,0,"[64, 1, 1]",0.761905,24000
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.208,16,6939565727974.942,1,7,48,0,81111,7,kernel,0,"[1, 1, 1]",0.011905,24004
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565728348.766,1,7,22,5,81126,7,kernel,0,"[50, 1, 1]",0.595238,24015
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.432,0,6939565728351.742,1,7,30,0,81143,7,kernel,0,"[2, 2, 1]",0.047619,24018
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.912,0,6939565728355.006,1,7,30,100,81162,7,kernel,0,"[1024, 2, 1]",24.380953,24025
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.912,16,6939565728366.686,1,7,40,5,81199,7,kernel,0,"[50, 1, 1]",0.595238,24032
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565728370.334,1,7,38,0,81201,7,kernel,0,"[2, 1, 1]",0.02381,24032
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565728693.693,1,7,22,5,81230,7,kernel,0,"[50, 1, 1]",0.595238,24048
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.169,25600,6939565728696.925,1,7,80,6,81260,7,kernel,0,"[8, 1, 8]",0.761905,24060
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565728704.797,1,7,44,25,81261,7,kernel,0,"[16, 4, 1]",0.761905,24060
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565728707.613,1,7,80,6,81283,7,kernel,0,"[64, 1, 1]",0.761905,24064
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.159,16,6939565728714.366,1,7,48,0,81295,7,kernel,0,"[1, 1, 1]",0.011905,24068
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939565729306.428,1,7,22,5,81358,7,kernel,0,"[50, 1, 1]",0.595238,24110
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.521,16,6939565729309.468,1,7,32,10,81372,7,kernel,0,"[25, 1, 1]",0.297619,24111
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.985,0,6939565729313.756,1,7,16,0,81385,7,kernel,0,"[2, 1, 1]",0.02381,24119
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.864,53504,6939565729316.54,1,7,236,0,81399,7,kernel,0,"[1, 8, 1]",0.095238,24104
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565729567.324,1,7,16,15,81457,7,kernel,0,"[150, 1, 1]",1.785714,24169
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565729572.796,1,7,16,15,81482,7,kernel,0,"[150, 1, 1]",1.785714,24179
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.008,0,6939565729817.979,1,7,22,15,81496,7,kernel,0,"[150, 1, 1]",1.785714,24183
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.599,0,6939565729821.724,1,7,16,15,81516,7,kernel,0,"[150, 1, 1]",1.785714,24190
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565729827.1,1,7,22,15,81530,7,kernel,0,"[150, 1, 1]",1.785714,24194
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939565730043.323,1,7,16,30,81565,7,kernel,0,"[300, 1, 1]",3.571429,24215
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",14.08,16384,6939565730047.067,1,7,57,38,81591,7,kernel,0,"[4, 2, 24]",2.285714,24226
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939565730061.915,1,7,44,25,81593,7,kernel,0,"[16, 4, 1]",0.761905,24226
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.576,16384,6939565730065.371,1,7,57,38,81610,7,kernel,0,"[16, 12, 1]",2.285714,24230
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.016,16,6939565730280.699,1,7,48,0,81623,7,kernel,0,"[3, 1, 1]",0.035714,24234
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565730291.547,1,7,22,5,81646,7,kernel,0,"[50, 1, 1]",0.595238,24253
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.168,16,6939565730500.954,1,7,40,5,81681,7,kernel,0,"[50, 1, 1]",0.595238,24256
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.767,0,6939565730504.859,1,7,38,0,81683,7,kernel,0,"[2, 1, 1]",0.02381,24256
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565730510.395,1,7,22,5,81712,7,kernel,0,"[50, 1, 1]",0.595238,24272
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.12,16384,6939565730718.202,1,7,57,25,81738,7,kernel,0,"[16, 2, 4]",1.52381,24284
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.2,0,6939565730736.026,1,7,44,67,81740,7,kernel,0,"[64, 4, 1]",3.047619,24284
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.792,16384,6939565730739.962,1,7,57,51,81757,7,kernel,0,"[16, 16, 1]",3.047619,24288
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.968,16,6939565730754.49,1,7,48,0,81770,7,kernel,0,"[1, 1, 1]",0.011905,24292
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.848,0,6939565731220.857,1,7,22,20,81803,7,kernel,0,"[200, 1, 1]",2.380952,24313
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.584,0,6939565731224.473,1,7,22,20,81817,7,kernel,0,"[200, 1, 1]",2.380952,24318
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.608,16384,6939565731228.921,1,7,57,44,81842,7,kernel,0,"[4, 2, 28]",2.666667,24328
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.232,0,6939565731246.297,1,7,44,25,81844,7,kernel,0,"[16, 4, 1]",0.761905,24328
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.272,16384,6939565731250.233,1,7,57,51,81861,7,kernel,0,"[16, 16, 1]",3.047619,24332
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.552,16,6939565731265.337,1,7,48,0,81874,7,kernel,0,"[4, 1, 1]",0.047619,24336
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.984,0,6939565731273.625,1,7,22,5,81897,7,kernel,0,"[50, 1, 1]",0.595238,24355
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.04,16,6939565731653.592,1,7,40,5,81932,7,kernel,0,"[50, 1, 1]",0.595238,24358
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.896,0,6939565731657.72,1,7,38,0,81934,7,kernel,0,"[2, 1, 1]",0.02381,24358
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.665,0,6939565731663.448,1,7,22,5,81963,7,kernel,0,"[50, 1, 1]",0.595238,24374
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.943,25600,6939565731665.913,1,7,80,6,81993,7,kernel,0,"[8, 1, 8]",0.761905,24386
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.049,0,6939565731673.688,1,7,44,25,81994,7,kernel,0,"[16, 4, 1]",0.761905,24386
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.176,25600,6939565731676.536,1,7,80,6,82016,7,kernel,0,"[64, 1, 1]",0.761905,24390
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.92,16,6939565732469.687,1,7,48,0,82028,7,kernel,0,"[1, 1, 1]",0.011905,24394
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939565732480.311,1,7,22,5,82091,7,kernel,0,"[50, 1, 1]",0.595238,24436
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.296,16,6939565732483.575,1,7,32,10,82105,7,kernel,0,"[25, 1, 1]",0.297619,24437
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.048,0,6939565732487.671,1,7,16,0,82118,7,kernel,0,"[2, 1, 1]",0.02381,24445
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.64,53504,6939565732490.487,1,7,236,0,82132,7,kernel,0,"[1, 8, 1]",0.095238,24430
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.088,0,6939565732528.407,1,7,16,10,82190,7,kernel,0,"[100, 1, 1]",1.190476,24495
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565732532.407,1,7,16,10,82215,7,kernel,0,"[100, 1, 1]",1.190476,24505
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.464,0,6939565732738.615,1,7,22,10,82229,7,kernel,0,"[100, 1, 1]",1.190476,24509
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939565732980.886,1,7,16,20,82264,7,kernel,0,"[200, 1, 1]",2.380952,24530
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",10.464,16384,6939565732984.79,1,7,57,25,82290,7,kernel,0,"[4, 2, 16]",1.52381,24541
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.496,0,6939565732995.99,1,7,44,25,82292,7,kernel,0,"[16, 4, 1]",0.761905,24541
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.16,16384,6939565732999.286,1,7,57,25,82309,7,kernel,0,"[16, 8, 1]",1.52381,24545
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.064,16,6939565733008.31,1,7,48,0,82322,7,kernel,0,"[2, 1, 1]",0.02381,24549
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565733238.71,1,7,22,5,82337,7,kernel,0,"[50, 1, 1]",0.595238,24560
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939565733241.59,1,7,80,6,82369,7,kernel,0,"[8, 1, 8]",0.761905,24570
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.08,0,6939565733249.558,1,7,44,25,82370,7,kernel,0,"[16, 4, 1]",0.761905,24570
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.952,25600,6939565733252.342,1,7,80,6,82392,7,kernel,0,"[64, 1, 1]",0.761905,24574
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.016,16,6939565733477.814,1,7,48,0,82404,7,kernel,0,"[1, 1, 1]",0.011905,24578
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565733488.565,1,7,22,5,82419,7,kernel,0,"[50, 1, 1]",0.595238,24589
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.239,0,6939565733491.51,1,7,30,0,82436,7,kernel,0,"[2, 2, 1]",0.047619,24592
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.232,0,6939565733689.877,1,7,30,100,82455,7,kernel,0,"[1024, 2, 1]",24.380953,24599
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.456,16,6939565733701.909,1,7,40,5,82492,7,kernel,0,"[50, 1, 1]",0.595238,24606
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565733706.133,1,7,38,0,82494,7,kernel,0,"[2, 1, 1]",0.02381,24606
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565733924.981,1,7,22,5,82523,7,kernel,0,"[50, 1, 1]",0.595238,24622
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.88,25600,6939565734381.844,1,7,80,6,82553,7,kernel,0,"[8, 1, 8]",0.761905,24634
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939565734389.524,1,7,44,25,82554,7,kernel,0,"[16, 4, 1]",0.761905,24634
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.952,25600,6939565734392.628,1,7,80,6,82576,7,kernel,0,"[64, 1, 1]",0.761905,24638
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.0,16,6939565734399.38,1,7,48,0,82588,7,kernel,0,"[1, 1, 1]",0.011905,24642
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565734408.116,1,7,22,5,82651,7,kernel,0,"[50, 1, 1]",0.595238,24684
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565734410.324,1,7,32,10,82665,7,kernel,0,"[25, 1, 1]",0.297619,24685
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565734414.452,1,7,16,0,82678,7,kernel,0,"[2, 1, 1]",0.02381,24693
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.704,53504,6939565735121.427,1,7,236,0,82692,7,kernel,0,"[1, 8, 1]",0.095238,24678
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565735158.995,1,7,16,15,82750,7,kernel,0,"[150, 1, 1]",1.785714,24743
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565735163.507,1,7,16,15,82775,7,kernel,0,"[150, 1, 1]",1.785714,24753
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565735167.603,1,7,22,15,82789,7,kernel,0,"[150, 1, 1]",1.785714,24757
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939565735170.067,1,7,16,15,82809,7,kernel,0,"[150, 1, 1]",1.785714,24764
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565735174.195,1,7,22,15,82823,7,kernel,0,"[150, 1, 1]",1.785714,24768
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939565735176.691,1,7,16,30,82858,7,kernel,0,"[300, 1, 1]",3.571429,24789
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.728,16384,6939565735600.786,1,7,57,38,82884,7,kernel,0,"[4, 2, 24]",2.285714,24800
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.072,0,6939565735615.25,1,7,44,25,82886,7,kernel,0,"[16, 4, 1]",0.761905,24800
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.8,16384,6939565735619.186,1,7,57,38,82903,7,kernel,0,"[16, 12, 1]",2.285714,24804
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939565735632.722,1,7,48,0,82916,7,kernel,0,"[3, 1, 1]",0.035714,24808
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.952,0,6939565735641.266,1,7,22,5,82939,7,kernel,0,"[50, 1, 1]",0.595238,24827
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.848,16,6939565735643.89,1,7,40,5,82974,7,kernel,0,"[50, 1, 1]",0.595238,24830
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939565735647.506,1,7,38,0,82976,7,kernel,0,"[2, 1, 1]",0.02381,24830
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565735652.85,1,7,22,5,83005,7,kernel,0,"[50, 1, 1]",0.595238,24846
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.088,16384,6939565736310.609,1,7,57,25,83031,7,kernel,0,"[16, 2, 4]",1.52381,24858
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.136,0,6939565736328.433,1,7,44,67,83033,7,kernel,0,"[64, 4, 1]",3.047619,24858
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.984,16384,6939565736332.401,1,7,57,51,83050,7,kernel,0,"[16, 16, 1]",3.047619,24862
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.064,16,6939565736347.249,1,7,48,0,83063,7,kernel,0,"[1, 1, 1]",0.011905,24866
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.56,0,6939565736356.017,1,7,22,20,83096,7,kernel,0,"[200, 1, 1]",2.380952,24887
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939565736359.313,1,7,22,20,83110,7,kernel,0,"[200, 1, 1]",2.380952,24892
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.168,16384,6939565736363.089,1,7,57,44,83135,7,kernel,0,"[4, 2, 28]",2.666667,24902
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.2,0,6939565736379.057,1,7,44,25,83137,7,kernel,0,"[16, 4, 1]",0.761905,24902
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.976,16384,6939565736383.025,1,7,57,51,83154,7,kernel,0,"[16, 16, 1]",3.047619,24906
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.072,16,6939565736398.737,1,7,48,0,83167,7,kernel,0,"[4, 1, 1]",0.047619,24910
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.952,0,6939565736406.513,1,7,22,5,83190,7,kernel,0,"[50, 1, 1]",0.595238,24929
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939565736409.169,1,7,40,5,83225,7,kernel,0,"[50, 1, 1]",0.595238,24932
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565736412.785,1,7,38,0,83227,7,kernel,0,"[2, 1, 1]",0.02381,24932
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939565736977.616,1,7,22,5,83256,7,kernel,0,"[50, 1, 1]",0.595238,24948
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.264,25600,6939565736980.592,1,7,80,6,83286,7,kernel,0,"[8, 1, 8]",0.761905,24960
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565736988.624,1,7,44,25,83287,7,kernel,0,"[16, 4, 1]",0.761905,24960
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565736991.568,1,7,80,6,83309,7,kernel,0,"[64, 1, 1]",0.761905,24964
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.032,16,6939565736998.512,1,7,48,0,83321,7,kernel,0,"[1, 1, 1]",0.011905,24968
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565737007.28,1,7,22,5,83384,7,kernel,0,"[50, 1, 1]",0.595238,25010
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565737009.424,1,7,32,10,83398,7,kernel,0,"[25, 1, 1]",0.297619,25011
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.08,0,6939565737013.552,1,7,16,0,83411,7,kernel,0,"[2, 1, 1]",0.02381,25019
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.8,53504,6939565737302.799,1,7,236,0,83425,7,kernel,0,"[1, 8, 1]",0.095238,25004
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565737522.159,1,7,16,10,83483,7,kernel,0,"[100, 1, 1]",1.190476,25069
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.184,0,6939565737526.671,1,7,16,10,83508,7,kernel,0,"[100, 1, 1]",1.190476,25079
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565737530.767,1,7,22,10,83522,7,kernel,0,"[100, 1, 1]",1.190476,25083
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.879,0,6939565737740.975,1,7,16,20,83557,7,kernel,0,"[200, 1, 1]",2.380952,25104
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.888,16384,6939565737938.99,1,7,57,25,83583,7,kernel,0,"[4, 2, 16]",1.52381,25115
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.624,0,6939565737949.614,1,7,44,25,83585,7,kernel,0,"[16, 4, 1]",0.761905,25115
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.16,16384,6939565737953.07,1,7,57,25,83602,7,kernel,0,"[16, 8, 1]",1.52381,25119
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939565737962.03,1,7,48,0,83615,7,kernel,0,"[2, 1, 1]",0.02381,25123
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.92,0,6939565737970.638,1,7,22,5,83630,7,kernel,0,"[50, 1, 1]",0.595238,25134
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.848,25600,6939565738173.326,1,7,80,6,83662,7,kernel,0,"[8, 1, 8]",0.761905,25144
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939565738181.006,1,7,44,25,83663,7,kernel,0,"[16, 4, 1]",0.761905,25144
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",5.984,25600,6939565738184.142,1,7,80,6,83685,7,kernel,0,"[64, 1, 1]",0.761905,25148
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.872,16,6939565738190.958,1,7,48,0,83697,7,kernel,0,"[1, 1, 1]",0.011905,25152
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.952,0,6939565738199.534,1,7,22,5,83712,7,kernel,0,"[50, 1, 1]",0.595238,25163
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.208,0,6939565738239.662,1,7,30,0,83729,7,kernel,0,"[2, 2, 1]",0.047619,25166
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",10.784,0,6939565738445.837,1,7,30,100,83748,7,kernel,0,"[1024, 2, 1]",24.380953,25173
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.232,16,6939565738457.422,1,7,40,5,83785,7,kernel,0,"[50, 1, 1]",0.595238,25180
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565738461.357,1,7,38,0,83787,7,kernel,0,"[2, 1, 1]",0.02381,25180
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565738675.309,1,7,22,5,83816,7,kernel,0,"[50, 1, 1]",0.595238,25196
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.168,25600,6939565738678.285,1,7,80,6,83846,7,kernel,0,"[8, 1, 8]",0.761905,25208
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565738686.221,1,7,44,25,83847,7,kernel,0,"[16, 4, 1]",0.761905,25208
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565738689.037,1,7,80,6,83869,7,kernel,0,"[64, 1, 1]",0.761905,25212
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939565738879.149,1,7,48,0,83881,7,kernel,0,"[1, 1, 1]",0.011905,25216
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565739176.556,1,7,22,5,83944,7,kernel,0,"[50, 1, 1]",0.595238,25258
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939565739179.596,1,7,32,10,83958,7,kernel,0,"[25, 1, 1]",0.297619,25259
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565739183.884,1,7,16,0,83971,7,kernel,0,"[2, 1, 1]",0.02381,25267
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.832,53504,6939565739186.668,1,7,236,0,83985,7,kernel,0,"[1, 8, 1]",0.095238,25252
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565739464.908,1,7,16,15,84043,7,kernel,0,"[150, 1, 1]",1.785714,25317
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.536,0,6939565739888.139,1,7,16,15,84068,7,kernel,0,"[150, 1, 1]",1.785714,25327
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939565739893.707,1,7,22,15,84082,7,kernel,0,"[150, 1, 1]",1.785714,25331
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939565739896.491,1,7,16,15,84102,7,kernel,0,"[150, 1, 1]",1.785714,25338
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565739901.227,1,7,22,15,84116,7,kernel,0,"[150, 1, 1]",1.785714,25342
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939565739903.659,1,7,16,30,84151,7,kernel,0,"[300, 1, 1]",3.571429,25363
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.184,16384,6939565739906.795,1,7,57,38,84177,7,kernel,0,"[4, 2, 24]",2.285714,25374
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939565739920.811,1,7,44,25,84179,7,kernel,0,"[16, 4, 1]",0.761905,25374
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.696,16384,6939565740341.034,1,7,57,38,84196,7,kernel,0,"[16, 12, 1]",2.285714,25378
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.712,16,6939565740355.498,1,7,48,0,84209,7,kernel,0,"[3, 1, 1]",0.035714,25382
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.176,0,6939565740363.946,1,7,22,5,84232,7,kernel,0,"[50, 1, 1]",0.595238,25401
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939565740366.89,1,7,40,5,84267,7,kernel,0,"[50, 1, 1]",0.595238,25404
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.544,0,6939565740370.506,1,7,38,0,84269,7,kernel,0,"[2, 1, 1]",0.02381,25404
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565740375.818,1,7,22,5,84298,7,kernel,0,"[50, 1, 1]",0.595238,25420
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.472,16384,6939565741256.617,1,7,57,25,84324,7,kernel,0,"[16, 2, 4]",1.52381,25432
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.136,0,6939565741274.825,1,7,44,67,84326,7,kernel,0,"[64, 4, 1]",3.047619,25432
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",13.984,16384,6939565741278.729,1,7,57,51,84343,7,kernel,0,"[16, 16, 1]",3.047619,25436
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939565741293.513,1,7,48,0,84356,7,kernel,0,"[1, 1, 1]",0.011905,25440
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.4,0,6939565741302.185,1,7,22,20,84389,7,kernel,0,"[200, 1, 1]",2.380952,25461
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.008,0,6939565741305.449,1,7,22,20,84403,7,kernel,0,"[200, 1, 1]",2.380952,25466
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.137,16384,6939565741309.224,1,7,57,44,84428,7,kernel,0,"[4, 2, 28]",2.666667,25476
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.743,0,6939565741325.161,1,7,44,25,84430,7,kernel,0,"[16, 4, 1]",0.761905,25476
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.856,16384,6939565741329.609,1,7,57,51,84447,7,kernel,0,"[16, 16, 1]",3.047619,25480
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.04,16,6939565741344.169,1,7,48,0,84460,7,kernel,0,"[4, 1, 1]",0.047619,25484
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565741351.945,1,7,22,5,84483,7,kernel,0,"[50, 1, 1]",0.595238,25503
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.944,16,6939565741354.537,1,7,40,5,84518,7,kernel,0,"[50, 1, 1]",0.595238,25506
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.384,0,6939565741358.345,1,7,38,0,84520,7,kernel,0,"[2, 1, 1]",0.02381,25506
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.665,0,6939565741363.528,1,7,22,5,84549,7,kernel,0,"[50, 1, 1]",0.595238,25522
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.008,25600,6939565741366.025,1,7,80,6,84579,7,kernel,0,"[8, 1, 8]",0.761905,25534
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.953,0,6939565741373.832,1,7,44,25,84580,7,kernel,0,"[16, 4, 1]",0.761905,25534
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939565741376.489,1,7,80,6,84602,7,kernel,0,"[64, 1, 1]",0.761905,25538
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.848,16,6939565741383.432,1,7,48,0,84614,7,kernel,0,"[1, 1, 1]",0.011905,25542
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.239,0,6939565742708.903,1,7,22,5,84677,7,kernel,0,"[50, 1, 1]",0.595238,25584
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.553,16,6939565742711.942,1,7,32,10,84691,7,kernel,0,"[25, 1, 1]",0.297619,25585
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.017,0,6939565742716.23,1,7,16,0,84704,7,kernel,0,"[2, 1, 1]",0.02381,25593
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.768,53504,6939565742719.014,1,7,236,0,84718,7,kernel,0,"[1, 8, 1]",0.095238,25578
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.121,0,6939565742756.71,1,7,16,10,84776,7,kernel,0,"[100, 1, 1]",1.190476,25643
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.185,0,6939565742760.71,1,7,16,10,84801,7,kernel,0,"[100, 1, 1]",1.190476,25653
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565742765.062,1,7,22,10,84815,7,kernel,0,"[100, 1, 1]",1.190476,25657
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.144,0,6939565742767.463,1,7,16,20,84850,7,kernel,0,"[200, 1, 1]",2.380952,25678
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.824,16384,6939565742770.438,1,7,57,25,84876,7,kernel,0,"[4, 2, 16]",1.52381,25689
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.527,0,6939565742780.935,1,7,44,25,84878,7,kernel,0,"[16, 4, 1]",0.761905,25689
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.192,16384,6939565742784.23,1,7,57,25,84895,7,kernel,0,"[16, 8, 1]",1.52381,25693
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939565742793.542,1,7,48,0,84908,7,kernel,0,"[2, 1, 1]",0.02381,25697
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565742802.022,1,7,22,5,84923,7,kernel,0,"[50, 1, 1]",0.595238,25708
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.944,25600,6939565742804.646,1,7,80,6,84955,7,kernel,0,"[8, 1, 8]",0.761905,25718
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565742812.326,1,7,44,25,84956,7,kernel,0,"[16, 4, 1]",0.761905,25718
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565742815.11,1,7,80,6,84978,7,kernel,0,"[64, 1, 1]",0.761905,25722
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",10.112,16,6939565744792.035,1,7,48,0,84990,7,kernel,0,"[1, 1, 1]",0.011905,25726
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939565744802.915,1,7,22,5,85005,7,kernel,0,"[50, 1, 1]",0.595238,25737
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.24,0,6939565744805.987,1,7,30,0,85022,7,kernel,0,"[2, 2, 1]",0.047619,25740
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.36,0,6939565744808.931,1,7,30,100,85041,7,kernel,0,"[1024, 2, 1]",24.380953,25747
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.784,16,6939565744821.123,1,7,40,5,85078,7,kernel,0,"[50, 1, 1]",0.595238,25754
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939565744824.707,1,7,38,0,85080,7,kernel,0,"[2, 1, 1]",0.02381,25754
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565744830.083,1,7,22,5,85109,7,kernel,0,"[50, 1, 1]",0.595238,25770
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.976,25600,6939565744832.707,1,7,80,6,85139,7,kernel,0,"[8, 1, 8]",0.761905,25782
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565744840.419,1,7,44,25,85140,7,kernel,0,"[16, 4, 1]",0.761905,25782
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565744843.235,1,7,80,6,85162,7,kernel,0,"[64, 1, 1]",0.761905,25786
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.296,16,6939565744850.179,1,7,48,0,85174,7,kernel,0,"[1, 1, 1]",0.011905,25790
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565744858.243,1,7,22,5,85237,7,kernel,0,"[50, 1, 1]",0.595238,25832
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.392,16,6939565744860.707,1,7,32,10,85251,7,kernel,0,"[25, 1, 1]",0.297619,25833
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565744864.835,1,7,16,0,85264,7,kernel,0,"[2, 1, 1]",0.02381,25841
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.896,53504,6939565744867.651,1,7,236,0,85278,7,kernel,0,"[1, 8, 1]",0.095238,25826
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565744905.667,1,7,16,15,85336,7,kernel,0,"[150, 1, 1]",1.785714,25891
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565744909.475,1,7,16,15,85361,7,kernel,0,"[150, 1, 1]",1.785714,25901
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565744913.795,1,7,22,15,85375,7,kernel,0,"[150, 1, 1]",1.785714,25905
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565744916.259,1,7,16,15,85395,7,kernel,0,"[150, 1, 1]",1.785714,25912
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565744920.387,1,7,22,15,85409,7,kernel,0,"[150, 1, 1]",1.785714,25916
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565744922.883,1,7,16,30,85444,7,kernel,0,"[300, 1, 1]",3.571429,25937
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.28,16384,6939565745141.442,1,7,57,38,85470,7,kernel,0,"[4, 2, 24]",2.285714,25948
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.008,0,6939565745155.554,1,7,44,25,85472,7,kernel,0,"[16, 4, 1]",0.761905,25948
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.735,16384,6939565745159.331,1,7,57,38,85489,7,kernel,0,"[16, 12, 1]",2.285714,25952
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.743,16,6939565745172.835,1,7,48,0,85502,7,kernel,0,"[3, 1, 1]",0.035714,25956
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565745424.93,1,7,22,5,85525,7,kernel,0,"[50, 1, 1]",0.595238,25975
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.04,16,6939565745427.81,1,7,40,5,85560,7,kernel,0,"[50, 1, 1]",0.595238,25978
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565745431.586,1,7,38,0,85562,7,kernel,0,"[2, 1, 1]",0.02381,25978
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939565745631.266,1,7,22,5,85591,7,kernel,0,"[50, 1, 1]",0.595238,25994
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.312,16384,6939565745685.698,1,7,57,25,85617,7,kernel,0,"[16, 2, 4]",1.52381,26006
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.88,0,6939565745703.778,1,7,44,67,85619,7,kernel,0,"[64, 4, 1]",3.047619,26006
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.912,16384,6939565745945.793,1,7,57,51,85636,7,kernel,0,"[16, 16, 1]",3.047619,26010
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.096,16,6939565745961.537,1,7,48,0,85649,7,kernel,0,"[1, 1, 1]",0.011905,26014
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.848,0,6939565746167.713,1,7,22,20,85682,7,kernel,0,"[200, 1, 1]",2.380952,26035
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.976,0,6939565746171.329,1,7,22,20,85696,7,kernel,0,"[200, 1, 1]",2.380952,26040
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.64,16384,6939565746175.105,1,7,57,44,85721,7,kernel,0,"[4, 2, 28]",2.666667,26050
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.68,0,6939565746192.481,1,7,44,25,85723,7,kernel,0,"[16, 4, 1]",0.761905,26050
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.56,16384,6939565746196.897,1,7,57,51,85740,7,kernel,0,"[16, 16, 1]",3.047619,26054
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.472,16,6939565746426.112,1,7,48,0,85753,7,kernel,0,"[4, 1, 1]",0.047619,26058
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939565746436.288,1,7,22,5,85776,7,kernel,0,"[50, 1, 1]",0.595238,26077
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.105,16,6939565746883.647,1,7,40,5,85811,7,kernel,0,"[50, 1, 1]",0.595238,26080
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.768,0,6939565746887.552,1,7,38,0,85813,7,kernel,0,"[2, 1, 1]",0.02381,26080
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565746893.088,1,7,22,5,85842,7,kernel,0,"[50, 1, 1]",0.595238,26096
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.135,25600,6939565746895.712,1,7,80,6,85872,7,kernel,0,"[8, 1, 8]",0.761905,26108
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565746903.68,1,7,44,25,85873,7,kernel,0,"[16, 4, 1]",0.761905,26108
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.081,25600,6939565746906.527,1,7,80,6,85895,7,kernel,0,"[64, 1, 1]",0.761905,26112
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565746913.696,1,7,48,0,85907,7,kernel,0,"[1, 1, 1]",0.011905,26116
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.24,0,6939565747275.455,1,7,22,5,85970,7,kernel,0,"[50, 1, 1]",0.595238,26158
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939565747278.431,1,7,32,10,85984,7,kernel,0,"[25, 1, 1]",0.297619,26159
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939565748631.741,1,7,16,0,85997,7,kernel,0,"[2, 1, 1]",0.02381,26167
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.152,53504,6939565748634.877,1,7,236,0,86011,7,kernel,0,"[1, 8, 1]",0.095238,26152
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.312,0,6939565748672.925,1,7,16,10,86069,7,kernel,0,"[100, 1, 1]",1.190476,26217
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.217,0,6939565748677.116,1,7,16,10,86094,7,kernel,0,"[100, 1, 1]",1.190476,26227
0,4.761905,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565748681.245,1,7,22,10,86108,7,kernel,0,"[100, 1, 1]",1.190476,26231
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565748683.581,1,7,16,20,86143,7,kernel,0,"[200, 1, 1]",2.380952,26252
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",9.632,16384,6939565748686.524,1,7,57,25,86169,7,kernel,0,"[4, 2, 16]",1.52381,26263
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565748696.893,1,7,44,25,86171,7,kernel,0,"[16, 4, 1]",0.761905,26263
0,12.190476,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",8.192,16384,6939565748700.669,1,7,57,25,86188,7,kernel,0,"[16, 8, 1]",1.52381,26267
0,0.095238,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939565748709.661,1,7,48,0,86201,7,kernel,0,"[2, 1, 1]",0.02381,26271
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.791,0,6939565748718.269,1,7,22,5,86216,7,kernel,0,"[50, 1, 1]",0.595238,26282
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.977,25600,6939565748720.924,1,7,80,6,86248,7,kernel,0,"[8, 1, 8]",0.761905,26292
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.015,0,6939565748728.765,1,7,44,25,86249,7,kernel,0,"[16, 4, 1]",0.761905,26292
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565748731.517,1,7,80,6,86271,7,kernel,0,"[64, 1, 1]",0.761905,26296
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.855,16,6939565748738.397,1,7,48,0,86283,7,kernel,0,"[1, 1, 1]",0.011905,26300
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939565748745.053,1,7,22,5,86298,7,kernel,0,"[50, 1, 1]",0.595238,26311
0,0.190476,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",2.081,0,6939565748747.644,1,7,30,0,86315,7,kernel,0,"[2, 2, 1]",0.047619,26314
0,97.523811,X,"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 2, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)",0,"[128, 1, 1]",11.072,0,6939565749010.396,1,7,30,100,86334,7,kernel,0,"[1024, 2, 1]",24.380953,26321
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.456,16,6939565749022.172,1,7,40,5,86371,7,kernel,0,"[50, 1, 1]",0.595238,26328
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.672,0,6939565749026.396,1,7,38,0,86373,7,kernel,0,"[2, 1, 1]",0.02381,26328
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565749252.508,1,7,22,5,86402,7,kernel,0,"[50, 1, 1]",0.595238,26344
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.2,25600,6939565749255.324,1,7,80,6,86432,7,kernel,0,"[8, 1, 8]",0.761905,26356
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565749263.356,1,7,44,25,86433,7,kernel,0,"[16, 4, 1]",0.761905,26356
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.016,25600,6939565749280.348,1,7,80,6,86455,7,kernel,0,"[64, 1, 1]",0.761905,26360
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.064,16,6939565749328.636,1,7,48,0,86467,7,kernel,0,"[1, 1, 1]",0.011905,26364
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.08,0,6939565749747.387,1,7,22,5,86530,7,kernel,0,"[50, 1, 1]",0.595238,26406
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.52,16,6939565749750.235,1,7,32,10,86544,7,kernel,0,"[25, 1, 1]",0.297619,26407
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939565749962.811,1,7,16,0,86557,7,kernel,0,"[2, 1, 1]",0.02381,26415
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.248,53504,6939565749965.947,1,7,236,0,86571,7,kernel,0,"[1, 8, 1]",0.095238,26400
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939565750459.13,1,7,16,15,86629,7,kernel,0,"[150, 1, 1]",1.785714,26465
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565750464.602,1,7,16,15,86654,7,kernel,0,"[150, 1, 1]",1.785714,26475
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.729,0,6939565750469.081,1,7,22,15,86668,7,kernel,0,"[150, 1, 1]",1.785714,26479
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565750471.546,1,7,16,15,86688,7,kernel,0,"[150, 1, 1]",1.785714,26486
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565750476.122,1,7,22,15,86702,7,kernel,0,"[150, 1, 1]",1.785714,26490
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.136,0,6939565750729.945,1,7,16,30,86737,7,kernel,0,"[300, 1, 1]",3.571429,26511
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.727,16384,6939565751811.224,1,7,57,38,86763,7,kernel,0,"[4, 2, 24]",2.285714,26522
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.039,0,6939565751825.752,1,7,44,25,86765,7,kernel,0,"[16, 4, 1]",0.761905,26522
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.872,16384,6939565751829.527,1,7,57,38,86782,7,kernel,0,"[16, 12, 1]",2.285714,26526
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.873,16,6939565751842.263,1,7,48,0,86795,7,kernel,0,"[3, 1, 1]",0.035714,26530
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.887,0,6939565751850.936,1,7,22,5,86818,7,kernel,0,"[50, 1, 1]",0.595238,26549
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.847,16,6939565751853.56,1,7,40,5,86853,7,kernel,0,"[50, 1, 1]",0.595238,26552
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.447,0,6939565751857.144,1,7,38,0,86855,7,kernel,0,"[2, 1, 1]",0.02381,26552
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.753,16,6939565751862.359,1,7,40,5,86896,7,kernel,0,"[50, 1, 1]",0.595238,26566
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.415,0,6939565751865.944,1,7,38,0,86898,7,kernel,0,"[2, 1, 1]",0.02381,26566
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565751871.159,1,7,22,5,86927,7,kernel,0,"[50, 1, 1]",0.595238,26582
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.223,16384,6939565751873.624,1,7,57,25,86953,7,kernel,0,"[16, 2, 4]",1.52381,26594
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.913,0,6939565751890.647,1,7,44,67,86955,7,kernel,0,"[64, 4, 1]",3.047619,26594
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.336,16384,6939565751894.263,1,7,57,51,86972,7,kernel,0,"[16, 16, 1]",3.047619,26598
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.984,16,6939565751909.399,1,7,48,0,86985,7,kernel,0,"[1, 1, 1]",0.011905,26602
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.271,0,6939565751916.184,1,7,22,20,87018,7,kernel,0,"[200, 1, 1]",2.380952,26623
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.976,0,6939565751919.255,1,7,22,20,87032,7,kernel,0,"[200, 1, 1]",2.380952,26628
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.736,16384,6939565752156.727,1,7,57,44,87057,7,kernel,0,"[4, 2, 28]",2.666667,26638
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.648,0,6939565752174.167,1,7,44,25,87059,7,kernel,0,"[16, 4, 1]",0.761905,26638
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",15.072,16384,6939565752178.615,1,7,57,51,87076,7,kernel,0,"[16, 16, 1]",3.047619,26642
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939565752194.519,1,7,48,0,87089,7,kernel,0,"[4, 1, 1]",0.047619,26646
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.273,0,6939565752431.926,1,7,22,5,87112,7,kernel,0,"[50, 1, 1]",0.595238,26665
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.04,16,6939565752434.999,1,7,40,5,87147,7,kernel,0,"[50, 1, 1]",0.595238,26668
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565752438.774,1,7,38,0,87149,7,kernel,0,"[2, 1, 1]",0.02381,26668
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939565752660.15,1,7,22,5,87178,7,kernel,0,"[50, 1, 1]",0.595238,26684
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.104,25600,6939565752663.158,1,7,80,6,87208,7,kernel,0,"[8, 1, 8]",0.761905,26696
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565752670.998,1,7,44,25,87209,7,kernel,0,"[16, 4, 1]",0.761905,26696
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.144,25600,6939565752673.814,1,7,80,6,87231,7,kernel,0,"[64, 1, 1]",0.761905,26700
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",9.984,16,6939565752901.974,1,7,48,0,87243,7,kernel,0,"[1, 1, 1]",0.011905,26704
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565753126.262,1,7,22,5,87306,7,kernel,0,"[50, 1, 1]",0.595238,26746
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.551,16,6939565753129.238,1,7,32,10,87320,7,kernel,0,"[25, 1, 1]",0.297619,26747
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.015,0,6939565753133.526,1,7,16,0,87333,7,kernel,0,"[2, 1, 1]",0.02381,26755
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.735,53504,6939565753136.31,1,7,236,0,87347,7,kernel,0,"[1, 8, 1]",0.095238,26740
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939565753447.957,1,7,16,15,87405,7,kernel,0,"[150, 1, 1]",1.785714,26805
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.6,0,6939565753806.292,1,7,16,15,87430,7,kernel,0,"[150, 1, 1]",1.785714,26815
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939565753811.412,1,7,22,15,87444,7,kernel,0,"[150, 1, 1]",1.785714,26819
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565753814.356,1,7,16,15,87464,7,kernel,0,"[150, 1, 1]",1.785714,26826
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565753818.676,1,7,22,15,87478,7,kernel,0,"[150, 1, 1]",1.785714,26830
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939565753821.172,1,7,16,30,87513,7,kernel,0,"[300, 1, 1]",3.571429,26851
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.632,16384,6939565754159.86,1,7,57,38,87539,7,kernel,0,"[4, 2, 24]",2.285714,26862
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.104,0,6939565754174.356,1,7,44,25,87541,7,kernel,0,"[16, 4, 1]",0.761905,26862
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.095,16384,6939565754178.228,1,7,57,38,87558,7,kernel,0,"[16, 12, 1]",2.285714,26866
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.776,16,6939565754191.156,1,7,48,0,87571,7,kernel,0,"[3, 1, 1]",0.035714,26870
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565754199.7,1,7,22,5,87594,7,kernel,0,"[50, 1, 1]",0.595238,26889
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.849,16,6939565754202.323,1,7,40,5,87629,7,kernel,0,"[50, 1, 1]",0.595238,26892
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.511,0,6939565754205.908,1,7,38,0,87631,7,kernel,0,"[2, 1, 1]",0.02381,26892
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939565756470.928,1,7,22,5,87660,7,kernel,0,"[50, 1, 1]",0.595238,26908
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.248,16384,6939565756473.936,1,7,57,25,87686,7,kernel,0,"[16, 2, 4]",1.52381,26920
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.88,0,6939565756491.984,1,7,44,67,87688,7,kernel,0,"[64, 4, 1]",3.047619,26920
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.016,16384,6939565756495.664,1,7,57,51,87705,7,kernel,0,"[16, 16, 1]",3.047619,26924
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939565756510.448,1,7,48,0,87718,7,kernel,0,"[1, 1, 1]",0.011905,26928
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.496,0,6939565756519.152,1,7,22,20,87751,7,kernel,0,"[200, 1, 1]",2.380952,26949
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.072,0,6939565756522.448,1,7,22,20,87765,7,kernel,0,"[200, 1, 1]",2.380952,26954
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.136,16384,6939565756526.224,1,7,57,44,87790,7,kernel,0,"[4, 2, 28]",2.666667,26964
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.488,0,6939565756542.16,1,7,44,25,87792,7,kernel,0,"[16, 4, 1]",0.761905,26964
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",13.984,16384,6939565756546.416,1,7,57,51,87809,7,kernel,0,"[16, 16, 1]",3.047619,26968
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.944,16,6939565756561.136,1,7,48,0,87822,7,kernel,0,"[4, 1, 1]",0.047619,26972
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939565756568.752,1,7,22,5,87845,7,kernel,0,"[50, 1, 1]",0.595238,26991
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.88,16,6939565756571.408,1,7,40,5,87880,7,kernel,0,"[50, 1, 1]",0.595238,26994
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.448,0,6939565756575.152,1,7,38,0,87882,7,kernel,0,"[2, 1, 1]",0.02381,26994
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565756580.464,1,7,22,5,87911,7,kernel,0,"[50, 1, 1]",0.595238,27010
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.784,25600,6939565756582.8,1,7,80,6,87941,7,kernel,0,"[8, 1, 8]",0.761905,27022
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939565756590.384,1,7,44,25,87942,7,kernel,0,"[16, 4, 1]",0.761905,27022
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.048,25600,6939565756593.2,1,7,80,6,87964,7,kernel,0,"[64, 1, 1]",0.761905,27026
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.912,16,6939565756599.984,1,7,48,0,87976,7,kernel,0,"[1, 1, 1]",0.011905,27030
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.407,0,6939565756607.76,1,7,22,5,88039,7,kernel,0,"[50, 1, 1]",0.595238,27072
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.424,16,6939565756609.968,1,7,32,10,88053,7,kernel,0,"[25, 1, 1]",0.297619,27073
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.016,0,6939565756614.224,1,7,16,0,88066,7,kernel,0,"[2, 1, 1]",0.02381,27081
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.704,53504,6939565756617.04,1,7,236,0,88080,7,kernel,0,"[1, 8, 1]",0.095238,27066
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",0.96,0,6939565756654.896,1,7,16,15,88138,7,kernel,0,"[150, 1, 1]",1.785714,27131
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.215,0,6939565756658.864,1,7,16,15,88163,7,kernel,0,"[150, 1, 1]",1.785714,27141
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565756662.96,1,7,22,15,88177,7,kernel,0,"[150, 1, 1]",1.785714,27145
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.217,0,6939565756665.423,1,7,16,15,88197,7,kernel,0,"[150, 1, 1]",1.785714,27152
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565756669.552,1,7,22,15,88211,7,kernel,0,"[150, 1, 1]",1.785714,27156
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.241,0,6939565756672.047,1,7,16,30,88246,7,kernel,0,"[300, 1, 1]",3.571429,27177
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.959,16384,6939565756675.152,1,7,57,38,88272,7,kernel,0,"[4, 2, 24]",2.285714,27188
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.193,0,6939565756688.911,1,7,44,25,88274,7,kernel,0,"[16, 4, 1]",0.761905,27188
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.649,16384,6939565756693.839,1,7,57,38,88291,7,kernel,0,"[16, 12, 1]",2.285714,27192
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565756706.287,1,7,48,0,88304,7,kernel,0,"[3, 1, 1]",0.035714,27196
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.304,0,6939565756980.751,1,7,22,5,88327,7,kernel,0,"[50, 1, 1]",0.595238,27215
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.072,16,6939565756983.791,1,7,40,5,88362,7,kernel,0,"[50, 1, 1]",0.595238,27218
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939565756987.727,1,7,38,0,88364,7,kernel,0,"[2, 1, 1]",0.02381,27218
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.015,0,6939565757318.287,1,7,22,5,88393,7,kernel,0,"[50, 1, 1]",0.595238,27234
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.472,16384,6939565757321.039,1,7,57,25,88419,7,kernel,0,"[16, 2, 4]",1.52381,27246
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.816,0,6939565757339.278,1,7,44,67,88421,7,kernel,0,"[64, 4, 1]",3.047619,27246
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.496,16384,6939565757342.863,1,7,57,51,88438,7,kernel,0,"[16, 16, 1]",3.047619,27250
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.936,16,6939565757358.126,1,7,48,0,88451,7,kernel,0,"[1, 1, 1]",0.011905,27254
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.209,0,6939565757366.894,1,7,22,20,88484,7,kernel,0,"[200, 1, 1]",2.380952,27275
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.936,0,6939565758376.909,1,7,22,20,88498,7,kernel,0,"[200, 1, 1]",2.380952,27280
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.736,16384,6939565758381.645,1,7,57,44,88523,7,kernel,0,"[4, 2, 28]",2.666667,27290
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.456,0,6939565758399.213,1,7,44,25,88525,7,kernel,0,"[16, 4, 1]",0.761905,27290
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.368,16384,6939565758403.437,1,7,57,51,88542,7,kernel,0,"[16, 16, 1]",3.047619,27294
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.616,16,6939565758418.637,1,7,48,0,88555,7,kernel,0,"[4, 1, 1]",0.047619,27298
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565758426.957,1,7,22,5,88578,7,kernel,0,"[50, 1, 1]",0.595238,27317
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.232,16,6939565758429.453,1,7,40,5,88613,7,kernel,0,"[50, 1, 1]",0.595238,27320
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565758433.517,1,7,38,0,88615,7,kernel,0,"[2, 1, 1]",0.02381,27320
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565758438.893,1,7,22,5,88644,7,kernel,0,"[50, 1, 1]",0.595238,27336
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",6.976,25600,6939565758441.357,1,7,80,6,88674,7,kernel,0,"[8, 1, 8]",0.761905,27348
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939565758449.133,1,7,44,25,88675,7,kernel,0,"[16, 4, 1]",0.761905,27348
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.145,25600,6939565758451.82,1,7,80,6,88697,7,kernel,0,"[64, 1, 1]",0.761905,27352
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.624,16,6939565758458.733,1,7,48,0,88709,7,kernel,0,"[1, 1, 1]",0.011905,27356
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565758466.156,1,7,22,5,88772,7,kernel,0,"[50, 1, 1]",0.595238,27398
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.424,16,6939565758468.365,1,7,32,10,88786,7,kernel,0,"[25, 1, 1]",0.297619,27399
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.432,0,6939565758962.156,1,7,16,0,88799,7,kernel,0,"[2, 1, 1]",0.02381,27407
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.928,53504,6939565758965.292,1,7,236,0,88813,7,kernel,0,"[1, 8, 1]",0.095238,27392
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.344,0,6939565759003.084,1,7,16,15,88871,7,kernel,0,"[150, 1, 1]",1.785714,27457
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565759007.34,1,7,16,15,88896,7,kernel,0,"[150, 1, 1]",1.785714,27467
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565759011.436,1,7,22,15,88910,7,kernel,0,"[150, 1, 1]",1.785714,27471
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.248,0,6939565759013.9,1,7,16,15,88930,7,kernel,0,"[150, 1, 1]",1.785714,27478
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.04,0,6939565759258.475,1,7,22,15,88944,7,kernel,0,"[150, 1, 1]",1.785714,27482
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.56,0,6939565759262.252,1,7,16,30,88979,7,kernel,0,"[300, 1, 1]",3.571429,27503
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.664,16384,6939565759596.331,1,7,57,38,89005,7,kernel,0,"[4, 2, 24]",2.285714,27514
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.2,0,6939565759610.763,1,7,44,25,89007,7,kernel,0,"[16, 4, 1]",0.761905,27514
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.128,16384,6939565759614.731,1,7,57,38,89024,7,kernel,0,"[16, 12, 1]",2.285714,27518
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.488,16,6939565759627.627,1,7,48,0,89037,7,kernel,0,"[3, 1, 1]",0.035714,27522
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.823,0,6939565759635.883,1,7,22,5,89060,7,kernel,0,"[50, 1, 1]",0.595238,27541
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.912,16,6939565759638.507,1,7,40,5,89095,7,kernel,0,"[50, 1, 1]",0.595238,27544
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",8.193,0,6939565759848.81,1,7,38,0,89097,7,kernel,0,"[2, 1, 1]",0.02381,27544
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.049,0,6939565759857.77,1,7,22,5,89126,7,kernel,0,"[50, 1, 1]",0.595238,27560
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",17.152,16384,6939565759860.586,1,7,57,25,89152,7,kernel,0,"[16, 2, 4]",1.52381,27572
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939565759878.442,1,7,44,67,89154,7,kernel,0,"[64, 4, 1]",3.047619,27572
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",15.936,16384,6939565760092.554,1,7,57,51,89171,7,kernel,0,"[16, 16, 1]",3.047619,27576
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.16,16,6939565760109.258,1,7,48,0,89184,7,kernel,0,"[1, 1, 1]",0.011905,27580
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.424,0,6939565760118.122,1,7,22,20,89217,7,kernel,0,"[200, 1, 1]",2.380952,27601
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.551,0,6939565760345.482,1,7,22,20,89231,7,kernel,0,"[200, 1, 1]",2.380952,27606
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.992,16384,6939565760349.738,1,7,57,44,89256,7,kernel,0,"[4, 2, 28]",2.666667,27616
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.648,0,6939565760367.466,1,7,44,25,89258,7,kernel,0,"[16, 4, 1]",0.761905,27616
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.144,16384,6939565760371.913,1,7,57,51,89275,7,kernel,0,"[16, 16, 1]",3.047619,27620
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939565760386.826,1,7,48,0,89288,7,kernel,0,"[4, 1, 1]",0.047619,27624
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.207,0,6939565761054.857,1,7,22,5,89311,7,kernel,0,"[50, 1, 1]",0.595238,27643
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.136,16,6939565761057.8,1,7,40,5,89346,7,kernel,0,"[50, 1, 1]",0.595238,27646
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.447,0,6939565761061.737,1,7,38,0,89348,7,kernel,0,"[2, 1, 1]",0.02381,27646
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.633,0,6939565761066.92,1,7,22,5,89377,7,kernel,0,"[50, 1, 1]",0.595238,27662
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.36,25600,6939565761069.256,1,7,80,6,89407,7,kernel,0,"[8, 1, 8]",0.761905,27674
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.017,0,6939565761077.448,1,7,44,25,89408,7,kernel,0,"[16, 4, 1]",0.761905,27674
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565761080.2,1,7,80,6,89430,7,kernel,0,"[64, 1, 1]",0.761905,27678
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.904,16,6939565761087.112,1,7,48,0,89442,7,kernel,0,"[1, 1, 1]",0.011905,27682
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565761906.247,1,7,22,5,89505,7,kernel,0,"[50, 1, 1]",0.595238,27724
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.552,16,6939565761909.223,1,7,32,10,89519,7,kernel,0,"[25, 1, 1]",0.297619,27725
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.984,0,6939565761913.575,1,7,16,0,89532,7,kernel,0,"[2, 1, 1]",0.02381,27733
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.736,53504,6939565761916.391,1,7,236,0,89546,7,kernel,0,"[1, 8, 1]",0.095238,27718
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.152,0,6939565761953.991,1,7,16,15,89604,7,kernel,0,"[150, 1, 1]",1.785714,27783
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565761958.087,1,7,16,15,89629,7,kernel,0,"[150, 1, 1]",1.785714,27793
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565761962.215,1,7,22,15,89643,7,kernel,0,"[150, 1, 1]",1.785714,27797
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565761964.679,1,7,16,15,89663,7,kernel,0,"[150, 1, 1]",1.785714,27804
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565761968.807,1,7,22,15,89677,7,kernel,0,"[150, 1, 1]",1.785714,27808
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565761971.303,1,7,16,30,89712,7,kernel,0,"[300, 1, 1]",3.571429,27829
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.952,16384,6939565762208.774,1,7,57,38,89738,7,kernel,0,"[4, 2, 24]",2.285714,27840
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.073,0,6939565762223.59,1,7,44,25,89740,7,kernel,0,"[16, 4, 1]",0.761905,27840
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.161,16384,6939565762227.366,1,7,57,38,89757,7,kernel,0,"[16, 12, 1]",2.285714,27844
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.744,16,6939565762240.295,1,7,48,0,89770,7,kernel,0,"[3, 1, 1]",0.035714,27848
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939565762481.286,1,7,22,5,89793,7,kernel,0,"[50, 1, 1]",0.595238,27867
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.104,16,6939565762484.166,1,7,40,5,89828,7,kernel,0,"[50, 1, 1]",0.595238,27870
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.416,0,6939565762488.326,1,7,38,0,89830,7,kernel,0,"[2, 1, 1]",0.02381,27870
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.049,0,6939565762803.973,1,7,22,5,89859,7,kernel,0,"[50, 1, 1]",0.595238,27886
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.769,16384,6939565762806.757,1,7,57,25,89885,7,kernel,0,"[16, 2, 4]",1.52381,27898
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.848,0,6939565762824.39,1,7,44,67,89887,7,kernel,0,"[64, 4, 1]",3.047619,27898
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.272,16384,6939565762828.07,1,7,57,51,89904,7,kernel,0,"[16, 16, 1]",3.047619,27902
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.032,16,6939565762843.173,1,7,48,0,89917,7,kernel,0,"[1, 1, 1]",0.011905,27906
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939565762851.909,1,7,22,20,89950,7,kernel,0,"[200, 1, 1]",2.380952,27927
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",3.456,0,6939565763061.285,1,7,22,20,89964,7,kernel,0,"[200, 1, 1]",2.380952,27932
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",16.992,16384,6939565763065.541,1,7,57,44,89989,7,kernel,0,"[4, 2, 28]",2.666667,27942
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.584,0,6939565763083.301,1,7,44,25,89991,7,kernel,0,"[16, 4, 1]",0.761905,27942
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.368,16384,6939565763087.717,1,7,57,51,90008,7,kernel,0,"[16, 16, 1]",3.047619,27946
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.648,16,6939565763102.917,1,7,48,0,90021,7,kernel,0,"[4, 1, 1]",0.047619,27950
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939565763348.325,1,7,22,5,90044,7,kernel,0,"[50, 1, 1]",0.595238,27969
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",3.168,16,6939565763351.397,1,7,40,5,90079,7,kernel,0,"[50, 1, 1]",0.595238,27972
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.512,0,6939565763355.365,1,7,38,0,90081,7,kernel,0,"[2, 1, 1]",0.02381,27972
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.016,0,6939565763560.26,1,7,22,5,90110,7,kernel,0,"[50, 1, 1]",0.595238,27988
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.135,25600,6939565763563.109,1,7,80,6,90140,7,kernel,0,"[8, 1, 8]",0.761905,28000
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565763571.076,1,7,44,25,90141,7,kernel,0,"[16, 4, 1]",0.761905,28000
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.08,25600,6939565763573.924,1,7,80,6,90163,7,kernel,0,"[64, 1, 1]",0.761905,28004
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.0,16,6939565763580.996,1,7,48,0,90175,7,kernel,0,"[1, 1, 1]",0.011905,28008
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939565765860.065,1,7,22,5,90238,7,kernel,0,"[50, 1, 1]",0.595238,28050
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.521,16,6939565765863.136,1,7,32,10,90252,7,kernel,0,"[25, 1, 1]",0.297619,28051
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.049,0,6939565765867.392,1,7,16,0,90265,7,kernel,0,"[2, 1, 1]",0.02381,28059
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",37.057,53504,6939565765870.176,1,7,236,0,90279,7,kernel,0,"[1, 8, 1]",0.095238,28044
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565765908.192,1,7,16,15,90337,7,kernel,0,"[150, 1, 1]",1.785714,28109
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.217,0,6939565765912.288,1,7,16,15,90362,7,kernel,0,"[150, 1, 1]",1.785714,28119
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.729,0,6939565765916.416,1,7,22,15,90376,7,kernel,0,"[150, 1, 1]",1.785714,28123
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.217,0,6939565765918.912,1,7,16,15,90396,7,kernel,0,"[150, 1, 1]",1.785714,28130
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565765923.008,1,7,22,15,90410,7,kernel,0,"[150, 1, 1]",1.785714,28134
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.273,0,6939565765925.504,1,7,16,30,90445,7,kernel,0,"[300, 1, 1]",3.571429,28155
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",13.151,16384,6939565765928.641,1,7,57,38,90471,7,kernel,0,"[4, 2, 24]",2.285714,28166
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.784,0,6939565765942.593,1,7,44,25,90473,7,kernel,0,"[16, 4, 1]",0.761905,28166
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",12.127,16384,6939565765946.177,1,7,57,38,90490,7,kernel,0,"[16, 12, 1]",2.285714,28170
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.681,16,6939565765959.072,1,7,48,0,90503,7,kernel,0,"[3, 1, 1]",0.035714,28174
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565765967.456,1,7,22,5,90526,7,kernel,0,"[50, 1, 1]",0.595238,28193
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.816,16,6939565765970.08,1,7,40,5,90561,7,kernel,0,"[50, 1, 1]",0.595238,28196
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.544,0,6939565765973.664,1,7,38,0,90563,7,kernel,0,"[2, 1, 1]",0.02381,28196
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565765979.008,1,7,22,5,90592,7,kernel,0,"[50, 1, 1]",0.595238,28212
0,12.190476,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.712,16384,6939565765981.632,1,7,57,25,90618,7,kernel,0,"[16, 2, 4]",1.52381,28224
0,48.761906,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.2,0,6939565765998.177,1,7,44,67,90620,7,kernel,0,"[64, 4, 1]",3.047619,28224
0,24.380953,X,ampere_sgemm_128x32_nt,0,"[256, 1, 1]",14.368,16384,6939565766002.144,1,7,57,51,90637,7,kernel,0,"[16, 16, 1]",3.047619,28228
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",5.792,16,6939565766017.28,1,7,48,0,90650,7,kernel,0,"[1, 1, 1]",0.011905,28232
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.592,0,6939565766023.936,1,7,22,20,90683,7,kernel,0,"[200, 1, 1]",2.380952,28253
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.88,0,6939565766027.2,1,7,22,20,90697,7,kernel,0,"[200, 1, 1]",2.380952,28258
0,21.333334,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",15.232,16384,6939565766030.848,1,7,57,44,90722,7,kernel,0,"[4, 2, 28]",2.666667,28268
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.36,0,6939565766046.784,1,7,44,25,90724,7,kernel,0,"[16, 4, 1]",0.761905,28268
0,24.380953,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",14.72,16384,6939565766050.912,1,7,57,51,90741,7,kernel,0,"[16, 16, 1]",3.047619,28272
0,0.190476,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",6.912,16,6939565766066.496,1,7,48,0,90754,7,kernel,0,"[4, 1, 1]",0.047619,28276
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.888,0,6939565766074.208,1,7,22,5,90777,7,kernel,0,"[50, 1, 1]",0.595238,28295
0,2.380952,X,"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)",0,"[128, 1, 1]",2.752,16,6939565766076.832,1,7,40,5,90812,7,kernel,0,"[50, 1, 1]",0.595238,28298
0,0.190476,X,"void at::native::(anonymous namespace)::GammaBetaBackwardSimpleCUDAKernel<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)",0,"[256, 1, 1]",4.48,0,6939565766080.448,1,7,38,0,90814,7,kernel,0,"[2, 1, 1]",0.02381,28298
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.079,0,6939565768433.053,1,7,22,5,90843,7,kernel,0,"[50, 1, 1]",0.595238,28314
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,"[128, 1, 1]",7.136,25600,6939565768435.996,1,7,80,6,90873,7,kernel,0,"[8, 1, 8]",0.761905,28326
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.048,0,6939565768443.868,1,7,44,25,90874,7,kernel,0,"[16, 4, 1]",0.761905,28326
0,3.047619,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nt_align1>(cutlass_80_simt_sgemm_128x32_8x5_nt_align1::Params),0,"[128, 1, 1]",6.047,25600,6939565768446.941,1,7,80,6,90896,7,kernel,0,"[64, 1, 1]",0.761905,28330
0,0.047619,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",8.128,16,6939565768453.724,1,7,48,0,90908,7,kernel,0,"[1, 1, 1]",0.011905,28334
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565768462.62,1,7,22,5,90971,7,kernel,0,"[50, 1, 1]",0.595238,28376
0,4.761905,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 16, 1]",3.424,16,6939565768464.828,1,7,32,10,90985,7,kernel,0,"[25, 1, 1]",0.297619,28377
0,0.095238,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",1.985,0,6939565768469.116,1,7,16,0,90998,7,kernel,0,"[2, 1, 1]",0.02381,28385
0,0.380952,X,"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)",0,"[128, 1, 1]",36.864,53504,6939565768471.9,1,7,236,0,91012,7,kernel,0,"[1, 8, 1]",0.095238,28370
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.12,0,6939565768509.692,1,7,16,15,91070,7,kernel,0,"[150, 1, 1]",1.785714,28435
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565768513.82,1,7,16,15,91095,7,kernel,0,"[150, 1, 1]",1.785714,28445
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.728,0,6939565768518.108,1,7,22,15,91109,7,kernel,0,"[150, 1, 1]",1.785714,28449
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.216,0,6939565768520.572,1,7,16,15,91129,7,kernel,0,"[150, 1, 1]",1.785714,28456
0,7.142857,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939565768524.668,1,7,22,15,91143,7,kernel,0,"[150, 1, 1]",1.785714,28460
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565768527.196,1,7,16,30,91178,7,kernel,0,"[300, 1, 1]",3.571429,28481
0,18.285715,X,ampere_sgemm_128x32_nn,0,"[256, 1, 1]",12.32,16384,6939565768530.268,1,7,57,38,91204,7,kernel,0,"[4, 2, 24]",2.285714,28492
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.872,0,6939565768543.356,1,7,44,25,91206,7,kernel,0,"[16, 4, 1]",0.761905,28492
0,18.285715,X,ampere_sgemm_32x128_nt,0,"[256, 1, 1]",11.232,16384,6939565768547.964,1,7,57,38,91223,7,kernel,0,"[16, 12, 1]",2.285714,28496
0,0.142857,X,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,"[32, 4, 1]",7.84,16,6939565768559.996,1,7,48,0,91236,7,kernel,0,"[3, 1, 1]",0.035714,28500
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565768568.572,1,7,22,5,91259,7,kernel,0,"[50, 1, 1]",0.595238,28519
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.152,0,6939565768571.004,1,7,16,5,91291,7,kernel,0,"[50, 1, 1]",0.595238,28536
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565768575.772,1,7,16,51,91316,7,kernel,0,"[512, 1, 1]",6.095238,28546
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.952,0,6939565768580.188,1,7,16,51,91341,7,kernel,0,"[512, 1, 1]",6.095238,28556
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",35.392,0,6939565768585.628,1,7,16,100,91368,7,kernel,0,"[10000, 1, 1]",119.047623,28568
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.8,8192,6939565768621.788,1,7,24,13,91375,7,kernel,0,"[16, 1, 1]",0.190476,28563
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.472,0,6939565768627.324,1,7,16,5,91401,7,kernel,0,"[50, 1, 1]",0.595238,28581
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.824,0,6939565768632.092,1,7,16,51,91426,7,kernel,0,"[512, 1, 1]",6.095238,28591
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",1.568,0,6939565768636.892,1,7,16,51,91451,7,kernel,0,"[512, 1, 1]",6.095238,28601
0,24.380953,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",4.224,0,6939565768641.98,1,7,22,51,91465,7,kernel,0,"[512, 1, 1]",6.095238,28605
0,476.190491,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,"[128, 1, 1]",35.904,0,6939565768646.94,1,7,16,100,91491,7,kernel,0,"[10000, 1, 1]",119.047623,28618
0,6.095238,X,"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)",0,"[32, 32, 1]",4.8,8192,6939565768683.644,1,7,24,13,91498,7,kernel,0,"[16, 1, 1]",0.190476,28613
0,60.952381,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",431.743,0,6939565773132.661,1,7,40,100,91510,7,kernel,0,"[320, 1, 1]",3.809524,22536
0,51.238094,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",325.696,0,6939565773565.204,1,7,40,100,91513,7,kernel,0,"[269, 1, 1]",3.202381,22536
0,54.285713,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",350.88,0,6939565773891.635,1,7,40,100,91516,7,kernel,0,"[285, 1, 1]",3.392857,22536
0,31.238094,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,"[512, 1, 1]",203.648,0,6939565774243.315,1,7,40,65,91519,7,kernel,0,"[164, 1, 1]",1.952381,22536
