pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,9.523809,X,"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)",0,"[128, 1, 1]",3.232,0,6939292365018.852,1,7,32,20,16,7,kernel,0,"[200, 1, 1]",2.380952,5
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.272,0,6939292365350.787,1,7,22,5,29,7,kernel,0,"[50, 1, 1]",0.595238,15
0,9.523809,X,"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)",0,"[128, 1, 1]",3.232,0,6939292365353.796,1,7,32,20,48,7,kernel,0,"[200, 1, 1]",2.380952,19
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.368,0,6939292365574.051,1,7,22,5,61,7,kernel,0,"[50, 1, 1]",0.595238,29
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.521,26624,6939292366204.034,1,7,82,29,81,7,kernel,0,"[24, 2, 3]",1.714286,40
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.392,0,6939292366220.419,1,7,44,67,83,7,kernel,0,"[48, 4, 1]",2.285714,40
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.232,0,6939292366452.674,1,7,16,30,97,7,kernel,0,"[300, 1, 1]",3.571429,54
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.616,36352,6939292367895.873,1,7,168,1,150,7,kernel,0,"[1, 8, 1]",0.095238,81
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.896,26624,6939292368472.096,1,7,82,13,178,7,kernel,0,"[8, 2, 4]",0.761905,95
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.496,0,6939292368481.824,1,7,44,25,180,7,kernel,0,"[16, 4, 1]",0.761905,95
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.56,0,6939292368816.319,1,7,47,20,211,7,kernel,0,"[100, 1, 1]",1.190476,98
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.984,0,6939292368819.679,1,7,22,5,221,7,kernel,0,"[50, 1, 1]",0.595238,103
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.032,24,6939292369089.695,1,7,43,5,250,7,kernel,0,"[50, 1, 1]",0.595238,105
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",21.216,26624,6939292369309.663,1,7,82,13,270,7,kernel,0,"[32, 2, 1]",0.761905,117
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.952,0,6939292369331.647,1,7,18,20,281,7,kernel,0,"[200, 1, 1]",2.380952,120
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.424,0,6939292369527.039,1,7,47,79,314,7,kernel,0,"[400, 1, 1]",4.761905,122
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",20.065,26624,6939292369733.79,1,7,82,16,333,7,kernel,0,"[8, 2, 5]",0.952381,133
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.657,0,6939292369754.59,1,7,44,25,335,7,kernel,0,"[16, 4, 1]",0.761905,133
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.72,0,6939292377940.79,1,7,47,20,366,7,kernel,0,"[100, 1, 1]",1.190476,136
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.112,0,6939292377944.374,1,7,22,5,376,7,kernel,0,"[50, 1, 1]",0.595238,141
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.84,24,6939292377947.254,1,7,43,5,405,7,kernel,0,"[50, 1, 1]",0.595238,143
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.616,26624,6939292378377.269,1,7,82,29,425,7,kernel,0,"[24, 2, 3]",1.714286,155
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.36,0,6939292378393.653,1,7,44,67,427,7,kernel,0,"[48, 4, 1]",2.285714,155
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939292378397.813,1,7,16,30,441,7,kernel,0,"[300, 1, 1]",3.571429,169
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.36,36352,6939292379022.836,1,7,168,1,494,7,kernel,0,"[1, 8, 1]",0.095238,196
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.448,26624,6939292379038.932,1,7,82,13,518,7,kernel,0,"[8, 2, 4]",0.761905,210
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292379048.181,1,7,44,25,520,7,kernel,0,"[16, 4, 1]",0.761905,210
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292379051.157,1,7,47,20,551,7,kernel,0,"[100, 1, 1]",1.190476,213
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.696,0,6939292379054.197,1,7,22,5,561,7,kernel,0,"[50, 1, 1]",0.595238,218
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.576,24,6939292379494.9,1,7,43,5,590,7,kernel,0,"[50, 1, 1]",0.595238,220
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",21.984,26624,6939292380492.563,1,7,82,13,614,7,kernel,0,"[32, 2, 1]",0.761905,232
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.92,0,6939292380515.379,1,7,18,20,625,7,kernel,0,"[200, 1, 1]",2.380952,235
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.008,0,6939292380518.131,1,7,47,79,658,7,kernel,0,"[400, 1, 1]",4.761905,237
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.088,26624,6939292380521.907,1,7,82,16,677,7,kernel,0,"[8, 2, 5]",0.952381,248
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.368,0,6939292380539.731,1,7,44,25,679,7,kernel,0,"[16, 4, 1]",0.761905,248
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.304,0,6939292380543.091,1,7,47,20,710,7,kernel,0,"[100, 1, 1]",1.190476,251
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292380546.163,1,7,22,5,720,7,kernel,0,"[50, 1, 1]",0.595238,256
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.84,24,6939292380548.595,1,7,43,5,749,7,kernel,0,"[50, 1, 1]",0.595238,258
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.008,26624,6939292380553.171,1,7,82,29,769,7,kernel,0,"[24, 2, 3]",1.714286,270
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939292380569.043,1,7,44,67,771,7,kernel,0,"[48, 4, 1]",2.285714,270
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.136,0,6939292382153.425,1,7,16,30,785,7,kernel,0,"[300, 1, 1]",3.571429,284
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.584,36352,6939292382157.361,1,7,168,1,838,7,kernel,0,"[1, 8, 1]",0.095238,311
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.224,26624,6939292382173.777,1,7,82,13,862,7,kernel,0,"[8, 2, 4]",0.761905,325
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.208,0,6939292382182.737,1,7,44,25,864,7,kernel,0,"[16, 4, 1]",0.761905,325
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292382185.713,1,7,47,20,895,7,kernel,0,"[100, 1, 1]",1.190476,328
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939292382188.817,1,7,22,5,905,7,kernel,0,"[50, 1, 1]",0.595238,333
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.224,24,6939292382191.441,1,7,43,5,934,7,kernel,0,"[50, 1, 1]",0.595238,335
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",20.32,26624,6939292382196.497,1,7,82,13,954,7,kernel,0,"[32, 2, 1]",0.761905,347
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.664,0,6939292382217.585,1,7,18,20,965,7,kernel,0,"[200, 1, 1]",2.380952,350
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.944,0,6939292382220.113,1,7,47,79,998,7,kernel,0,"[400, 1, 1]",4.761905,352
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.808,26624,6939292382444.497,1,7,82,16,1021,7,kernel,0,"[8, 2, 5]",0.952381,363
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.624,0,6939292382465.105,1,7,44,25,1023,7,kernel,0,"[16, 4, 1]",0.761905,363
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.721,0,6939292382685.648,1,7,47,20,1054,7,kernel,0,"[100, 1, 1]",1.190476,366
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.175,0,6939292382689.201,1,7,22,5,1064,7,kernel,0,"[50, 1, 1]",0.595238,371
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.096,24,6939292382911.28,1,7,43,5,1093,7,kernel,0,"[50, 1, 1]",0.595238,373
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.648,26624,6939292382992.72,1,7,82,29,1113,7,kernel,0,"[24, 2, 3]",1.714286,385
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",4.992,0,6939292383212.944,1,7,44,67,1115,7,kernel,0,"[48, 4, 1]",2.285714,385
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.592,0,6939292383218.736,1,7,16,30,1129,7,kernel,0,"[300, 1, 1]",3.571429,399
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.551,36352,6939292383594.032,1,7,168,1,1182,7,kernel,0,"[1, 8, 1]",0.095238,426
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.8,26624,6939292383909.231,1,7,82,13,1206,7,kernel,0,"[8, 2, 4]",0.761905,440
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.496,0,6939292383918.735,1,7,44,25,1208,7,kernel,0,"[16, 4, 1]",0.761905,440
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292383922.063,1,7,47,20,1239,7,kernel,0,"[100, 1, 1]",1.190476,443
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292383925.167,1,7,22,5,1249,7,kernel,0,"[50, 1, 1]",0.595238,448
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.128,24,6939292384312.238,1,7,43,5,1278,7,kernel,0,"[50, 1, 1]",0.595238,450
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",20.864,26624,6939292384317.166,1,7,82,13,1298,7,kernel,0,"[32, 2, 1]",0.761905,462
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939292384338.798,1,7,18,20,1309,7,kernel,0,"[200, 1, 1]",2.380952,465
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",4.064,0,6939292385722.093,1,7,47,79,1342,7,kernel,0,"[400, 1, 1]",4.761905,467
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.648,26624,6939292385726.989,1,7,82,16,1365,7,kernel,0,"[8, 2, 5]",0.952381,478
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939292385747.373,1,7,44,25,1367,7,kernel,0,"[16, 4, 1]",0.761905,478
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.304,0,6939292385750.541,1,7,47,20,1398,7,kernel,0,"[100, 1, 1]",1.190476,481
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.953,0,6939292385753.644,1,7,22,5,1408,7,kernel,0,"[50, 1, 1]",0.595238,486
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.161,24,6939292385756.428,1,7,43,5,1437,7,kernel,0,"[50, 1, 1]",0.595238,488
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",14.784,26624,6939292385761.421,1,7,82,29,1457,7,kernel,0,"[24, 2, 3]",1.714286,500
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939292385776.941,1,7,44,67,1459,7,kernel,0,"[48, 4, 1]",2.285714,500
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939292385780.749,1,7,16,30,1473,7,kernel,0,"[300, 1, 1]",3.571429,514
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.424,36352,6939292386096.172,1,7,168,1,1526,7,kernel,0,"[1, 8, 1]",0.095238,541
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.64,26624,6939292386328.62,1,7,82,13,1550,7,kernel,0,"[8, 2, 4]",0.761905,555
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.464,0,6939292386337.996,1,7,44,25,1552,7,kernel,0,"[16, 4, 1]",0.761905,555
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.72,0,6939292386561.996,1,7,47,20,1583,7,kernel,0,"[100, 1, 1]",1.190476,558
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292386565.42,1,7,22,5,1593,7,kernel,0,"[50, 1, 1]",0.595238,563
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.84,24,6939292386568.364,1,7,43,5,1622,7,kernel,0,"[50, 1, 1]",0.595238,565
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",21.632,26624,6939292386865.163,1,7,82,13,1642,7,kernel,0,"[32, 2, 1]",0.761905,577
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.888,0,6939292386887.659,1,7,18,20,1653,7,kernel,0,"[200, 1, 1]",2.380952,580
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.008,0,6939292386890.316,1,7,47,79,1686,7,kernel,0,"[400, 1, 1]",4.761905,582
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",20.128,26624,6939292387312.843,1,7,82,16,1709,7,kernel,0,"[8, 2, 5]",0.952381,593
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.656,0,6939292387333.707,1,7,44,25,1711,7,kernel,0,"[16, 4, 1]",0.761905,593
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.719,0,6939292387784.075,1,7,47,20,1742,7,kernel,0,"[100, 1, 1]",1.190476,596
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292387787.882,1,7,22,5,1752,7,kernel,0,"[50, 1, 1]",0.595238,601
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.903,24,6939292387790.763,1,7,43,5,1781,7,kernel,0,"[50, 1, 1]",0.595238,603
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.424,26624,6939292388022.154,1,7,82,29,1801,7,kernel,0,"[24, 2, 3]",1.714286,615
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.488,0,6939292388038.57,1,7,44,67,1803,7,kernel,0,"[48, 4, 1]",2.285714,615
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939292388042.858,1,7,16,30,1817,7,kernel,0,"[300, 1, 1]",3.571429,629
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.649,36352,6939292388876.585,1,7,168,1,1870,7,kernel,0,"[1, 8, 1]",0.095238,656
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.152,26624,6939292388893.033,1,7,82,13,1894,7,kernel,0,"[8, 2, 4]",0.761905,670
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292388903.017,1,7,44,25,1896,7,kernel,0,"[16, 4, 1]",0.761905,670
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292388905.993,1,7,47,20,1927,7,kernel,0,"[100, 1, 1]",1.190476,673
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939292388909.225,1,7,22,5,1937,7,kernel,0,"[50, 1, 1]",0.595238,678
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.16,24,6939292388911.817,1,7,43,5,1966,7,kernel,0,"[50, 1, 1]",0.595238,680
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",21.376,26624,6939292389402.729,1,7,82,13,1986,7,kernel,0,"[32, 2, 1]",0.761905,692
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.952,0,6939292389424.841,1,7,18,20,1997,7,kernel,0,"[200, 1, 1]",2.380952,695
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.071,0,6939292389427.945,1,7,47,79,2030,7,kernel,0,"[400, 1, 1]",4.761905,697
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.184,26624,6939292389431.721,1,7,82,16,2049,7,kernel,0,"[8, 2, 5]",0.952381,708
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939292389449.769,1,7,44,25,2051,7,kernel,0,"[16, 4, 1]",0.761905,708
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.304,0,6939292389452.937,1,7,47,20,2082,7,kernel,0,"[100, 1, 1]",1.190476,711
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.823,0,6939292389635.369,1,7,22,5,2092,7,kernel,0,"[50, 1, 1]",0.595238,716
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.903,24,6939292389637.993,1,7,43,5,2121,7,kernel,0,"[50, 1, 1]",0.595238,718
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.096,24,6939292389877.416,1,7,43,5,2150,7,kernel,0,"[50, 1, 1]",0.595238,725
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.68,26624,6939292390425.0,1,7,82,29,2174,7,kernel,0,"[24, 2, 3]",1.714286,737
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.296,0,6939292390441.448,1,7,44,67,2176,7,kernel,0,"[48, 4, 1]",2.285714,737
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.04,0,6939292390655.047,1,7,16,30,2190,7,kernel,0,"[300, 1, 1]",3.571429,751
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.392,36352,6939292390973.639,1,7,168,1,2243,7,kernel,0,"[1, 8, 1]",0.095238,778
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.704,26624,6939292391285.607,1,7,82,13,2267,7,kernel,0,"[8, 2, 4]",0.761905,792
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.464,0,6939292391295.015,1,7,44,25,2269,7,kernel,0,"[16, 4, 1]",0.761905,792
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.337,0,6939292391298.342,1,7,47,20,2300,7,kernel,0,"[100, 1, 1]",1.190476,795
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.856,0,6939292391301.447,1,7,22,5,2310,7,kernel,0,"[50, 1, 1]",0.595238,800
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.128,24,6939292391680.134,1,7,43,5,2339,7,kernel,0,"[50, 1, 1]",0.595238,802
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.344,26624,6939292393739.364,1,7,82,13,2359,7,kernel,0,"[8, 2, 4]",0.761905,820
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.528,0,6939292393749.412,1,7,44,25,2361,7,kernel,0,"[16, 4, 1]",0.761905,820
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.872,26624,6939292393752.708,1,7,82,25,2381,7,kernel,0,"[16, 2, 4]",1.52381,828
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939292393765.316,1,7,44,51,2383,7,kernel,0,"[32, 4, 1]",1.52381,828
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939292393768.484,1,7,16,20,2397,7,kernel,0,"[200, 1, 1]",2.380952,842
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.2,36352,6939292393771.428,1,7,168,1,2447,7,kernel,0,"[1, 8, 1]",0.095238,867
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.096,26624,6939292393787.492,1,7,82,13,2471,7,kernel,0,"[8, 2, 4]",0.761905,881
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939292393796.452,1,7,44,25,2473,7,kernel,0,"[16, 4, 1]",0.761905,881
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.432,0,6939292393799.396,1,7,47,20,2504,7,kernel,0,"[100, 1, 1]",1.190476,884
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939292393802.66,1,7,22,5,2514,7,kernel,0,"[50, 1, 1]",0.595238,889
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.872,24,6939292393804.964,1,7,43,5,2543,7,kernel,0,"[50, 1, 1]",0.595238,891
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.744,26624,6939292393809.7,1,7,82,13,2563,7,kernel,0,"[32, 2, 1]",0.761905,903
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.664,0,6939292393830.244,1,7,18,20,2574,7,kernel,0,"[200, 1, 1]",2.380952,906
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.944,0,6939292393832.772,1,7,47,79,2607,7,kernel,0,"[400, 1, 1]",4.761905,908
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.184,26624,6939292393836.548,1,7,82,16,2630,7,kernel,0,"[8, 2, 5]",0.952381,919
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939292393854.564,1,7,44,25,2632,7,kernel,0,"[16, 4, 1]",0.761905,919
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.753,0,6939292394154.435,1,7,47,20,2663,7,kernel,0,"[100, 1, 1]",1.190476,922
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939292394158.02,1,7,22,5,2673,7,kernel,0,"[50, 1, 1]",0.595238,927
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.84,24,6939292394160.964,1,7,43,5,2702,7,kernel,0,"[50, 1, 1]",0.595238,929
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.552,26624,6939292394420.547,1,7,82,29,2722,7,kernel,0,"[24, 2, 3]",1.714286,941
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.328,0,6939292394436.803,1,7,44,67,2724,7,kernel,0,"[48, 4, 1]",2.285714,941
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.552,0,6939292394647.011,1,7,16,30,2738,7,kernel,0,"[300, 1, 1]",3.571429,955
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.552,36352,6939292394920.259,1,7,168,1,2791,7,kernel,0,"[1, 8, 1]",0.095238,982
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.056,26624,6939292395128.515,1,7,82,13,2815,7,kernel,0,"[8, 2, 4]",0.761905,996
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.56,0,6939292395138.371,1,7,44,25,2817,7,kernel,0,"[16, 4, 1]",0.761905,996
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.72,0,6939292395747.522,1,7,47,20,2848,7,kernel,0,"[100, 1, 1]",1.190476,999
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.048,0,6939292395751.074,1,7,22,5,2858,7,kernel,0,"[50, 1, 1]",0.595238,1004
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.808,24,6939292395753.89,1,7,43,5,2887,7,kernel,0,"[50, 1, 1]",0.595238,1006
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.96,26624,6939292395758.402,1,7,82,13,2907,7,kernel,0,"[8, 2, 4]",0.761905,1024
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292395768.098,1,7,44,25,2909,7,kernel,0,"[16, 4, 1]",0.761905,1024
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.936,26624,6939292396428.225,1,7,82,25,2929,7,kernel,0,"[16, 2, 4]",1.52381,1032
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.752,0,6939292396440.961,1,7,44,51,2931,7,kernel,0,"[32, 4, 1]",1.52381,1032
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939292396444.545,1,7,16,20,2945,7,kernel,0,"[200, 1, 1]",2.380952,1046
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.424,36352,6939292396447.649,1,7,168,1,2995,7,kernel,0,"[1, 8, 1]",0.095238,1071
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.537,26624,6939292396936.992,1,7,82,13,3019,7,kernel,0,"[8, 2, 4]",0.761905,1085
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.495,0,6939292396947.297,1,7,44,25,3021,7,kernel,0,"[16, 4, 1]",0.761905,1085
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.431,0,6939292396950.561,1,7,47,20,3052,7,kernel,0,"[100, 1, 1]",1.190476,1088
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939292396953.856,1,7,22,5,3062,7,kernel,0,"[50, 1, 1]",0.595238,1093
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.808,24,6939292396956.48,1,7,43,5,3091,7,kernel,0,"[50, 1, 1]",0.595238,1095
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",21.536,26624,6939292397195.84,1,7,82,13,3111,7,kernel,0,"[32, 2, 1]",0.761905,1107
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.92,0,6939292397218.144,1,7,18,20,3122,7,kernel,0,"[200, 1, 1]",2.380952,1110
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.944,0,6939292397220.832,1,7,47,79,3155,7,kernel,0,"[400, 1, 1]",4.761905,1112
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",20.32,26624,6939292397585.536,1,7,82,16,3178,7,kernel,0,"[8, 2, 5]",0.952381,1123
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.656,0,6939292397606.656,1,7,44,25,3180,7,kernel,0,"[16, 4, 1]",0.761905,1123
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.784,0,6939292397920.736,1,7,47,20,3211,7,kernel,0,"[100, 1, 1]",1.190476,1126
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.079,0,6939292397924.32,1,7,22,5,3221,7,kernel,0,"[50, 1, 1]",0.595238,1131
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.808,24,6939292397927.263,1,7,43,5,3250,7,kernel,0,"[50, 1, 1]",0.595238,1133
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",16.448,26624,6939292398250.847,1,7,82,29,3270,7,kernel,0,"[24, 2, 3]",1.714286,1145
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.328,0,6939292398268.127,1,7,44,67,3272,7,kernel,0,"[48, 4, 1]",2.285714,1145
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.168,0,6939292398473.439,1,7,16,30,3286,7,kernel,0,"[300, 1, 1]",3.571429,1159
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.52,36352,6939292398743.295,1,7,168,1,3339,7,kernel,0,"[1, 8, 1]",0.095238,1186
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.088,26624,6939292399349.278,1,7,82,13,3363,7,kernel,0,"[8, 2, 4]",0.761905,1200
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.432,0,6939292399359.134,1,7,44,25,3365,7,kernel,0,"[16, 4, 1]",0.761905,1200
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292399362.302,1,7,47,20,3396,7,kernel,0,"[100, 1, 1]",1.190476,1203
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939292399365.406,1,7,22,5,3406,7,kernel,0,"[50, 1, 1]",0.595238,1208
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.224,24,6939292399367.838,1,7,43,5,3435,7,kernel,0,"[50, 1, 1]",0.595238,1210
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.216,26624,6939292399616.062,1,7,82,13,3455,7,kernel,0,"[8, 2, 4]",0.761905,1228
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.495,0,6939292399626.078,1,7,44,25,3457,7,kernel,0,"[16, 4, 1]",0.761905,1228
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.68,26624,6939292399629.374,1,7,82,25,3477,7,kernel,0,"[16, 2, 4]",1.52381,1236
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.401,0,6939292399641.821,1,7,44,51,3479,7,kernel,0,"[32, 4, 1]",1.52381,1236
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.072,0,6939292400426.877,1,7,16,20,3493,7,kernel,0,"[200, 1, 1]",2.380952,1250
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.776,36352,6939292400430.749,1,7,168,1,3543,7,kernel,0,"[1, 8, 1]",0.095238,1275
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.928,26624,6939292400447.293,1,7,82,13,3567,7,kernel,0,"[8, 2, 4]",0.761905,1289
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292400456.957,1,7,44,25,3569,7,kernel,0,"[16, 4, 1]",0.761905,1289
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939292400459.901,1,7,47,20,3600,7,kernel,0,"[100, 1, 1]",1.190476,1292
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939292400463.005,1,7,22,5,3610,7,kernel,0,"[50, 1, 1]",0.595238,1297
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.096,24,6939292400703.132,1,7,43,5,3639,7,kernel,0,"[50, 1, 1]",0.595238,1299
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",21.216,26624,6939292400963.772,1,7,82,13,3663,7,kernel,0,"[32, 2, 1]",0.761905,1311
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.56,0,6939292401197.948,1,7,18,20,3674,7,kernel,0,"[200, 1, 1]",2.380952,1314
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.136,0,6939292401201.308,1,7,47,79,3707,7,kernel,0,"[400, 1, 1]",4.761905,1316
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.968,26624,6939292401481.468,1,7,82,16,3726,7,kernel,0,"[8, 2, 5]",0.952381,1327
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.656,0,6939292401502.204,1,7,44,25,3728,7,kernel,0,"[16, 4, 1]",0.761905,1327
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939292401505.628,1,7,47,20,3759,7,kernel,0,"[100, 1, 1]",1.190476,1330
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.857,0,6939292401509.147,1,7,22,5,3769,7,kernel,0,"[50, 1, 1]",0.595238,1335
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.128,24,6939292401747.675,1,7,43,5,3798,7,kernel,0,"[50, 1, 1]",0.595238,1337
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",16.288,26624,6939292401986.235,1,7,82,29,3818,7,kernel,0,"[24, 2, 3]",1.714286,1349
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.328,0,6939292402003.259,1,7,44,67,3820,7,kernel,0,"[48, 4, 1]",2.285714,1349
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",3.072,0,6939292402208.891,1,7,16,30,3834,7,kernel,0,"[300, 1, 1]",3.571429,1363
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.519,36352,6939292402437.723,1,7,168,1,3887,7,kernel,0,"[1, 8, 1]",0.095238,1390
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",9.248,26624,6939292403050.65,1,7,82,13,3911,7,kernel,0,"[8, 2, 4]",0.761905,1404
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.432,0,6939292403060.634,1,7,44,25,3913,7,kernel,0,"[16, 4, 1]",0.761905,1404
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292403063.802,1,7,47,20,3944,7,kernel,0,"[100, 1, 1]",1.190476,1407
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939292403066.906,1,7,22,5,3954,7,kernel,0,"[50, 1, 1]",0.595238,1412
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.808,24,6939292403069.53,1,7,43,5,3983,7,kernel,0,"[50, 1, 1]",0.595238,1414
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.64,26624,6939292405451.351,1,7,82,13,4003,7,kernel,0,"[8, 2, 4]",0.761905,1432
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.497,0,6939292405460.759,1,7,44,25,4005,7,kernel,0,"[16, 4, 1]",0.761905,1432
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.776,26624,6939292405464.023,1,7,82,25,4025,7,kernel,0,"[16, 2, 4]",1.52381,1440
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939292405476.631,1,7,44,51,4027,7,kernel,0,"[32, 4, 1]",1.52381,1440
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.272,0,6939292405479.767,1,7,16,20,4041,7,kernel,0,"[200, 1, 1]",2.380952,1454
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.136,36352,6939292405482.871,1,7,168,1,4091,7,kernel,0,"[1, 8, 1]",0.095238,1479
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.448,26624,6939292405498.775,1,7,82,13,4119,7,kernel,0,"[8, 2, 4]",0.761905,1493
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.112,0,6939292405508.087,1,7,44,25,4121,7,kernel,0,"[16, 4, 1]",0.761905,1493
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292405511.063,1,7,47,20,4152,7,kernel,0,"[100, 1, 1]",1.190476,1496
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939292405514.167,1,7,22,5,4162,7,kernel,0,"[50, 1, 1]",0.595238,1501
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.84,24,6939292405516.631,1,7,43,5,4191,7,kernel,0,"[50, 1, 1]",0.595238,1503
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.68,26624,6939292405521.335,1,7,82,13,4211,7,kernel,0,"[32, 2, 1]",0.761905,1515
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.696,0,6939292405541.751,1,7,18,20,4222,7,kernel,0,"[200, 1, 1]",2.380952,1518
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.944,0,6939292405544.279,1,7,47,79,4255,7,kernel,0,"[400, 1, 1]",4.761905,1520
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",16.864,26624,6939292405548.055,1,7,82,16,4274,7,kernel,0,"[8, 2, 5]",0.952381,1531
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292405565.751,1,7,44,25,4276,7,kernel,0,"[16, 4, 1]",0.761905,1531
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292405568.663,1,7,47,20,4307,7,kernel,0,"[100, 1, 1]",1.190476,1534
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939292405571.767,1,7,22,5,4317,7,kernel,0,"[50, 1, 1]",0.595238,1539
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.936,24,6939292405574.231,1,7,43,5,4346,7,kernel,0,"[50, 1, 1]",0.595238,1541
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.936,26624,6939292407872.596,1,7,82,29,4366,7,kernel,0,"[24, 2, 3]",1.714286,1553
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.328,0,6939292407889.268,1,7,44,67,4368,7,kernel,0,"[48, 4, 1]",2.285714,1553
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939292407893.364,1,7,16,30,4382,7,kernel,0,"[300, 1, 1]",3.571429,1567
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.296,36352,6939292407896.468,1,7,168,1,4435,7,kernel,0,"[1, 8, 1]",0.095238,1594
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.32,26624,6939292407912.628,1,7,82,13,4459,7,kernel,0,"[8, 2, 4]",0.761905,1608
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939292407921.748,1,7,44,25,4461,7,kernel,0,"[16, 4, 1]",0.761905,1608
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939292407924.724,1,7,47,20,4492,7,kernel,0,"[100, 1, 1]",1.190476,1611
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.504,0,6939292407927.828,1,7,22,5,4502,7,kernel,0,"[50, 1, 1]",0.595238,1616
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.808,24,6939292407930.1,1,7,43,5,4531,7,kernel,0,"[50, 1, 1]",0.595238,1618
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.0,26624,6939292407934.804,1,7,82,13,4555,7,kernel,0,"[8, 2, 4]",0.761905,1636
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939292407943.572,1,7,44,25,4557,7,kernel,0,"[16, 4, 1]",0.761905,1636
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.008,26624,6939292407946.388,1,7,82,25,4577,7,kernel,0,"[16, 2, 4]",1.52381,1644
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939292407958.164,1,7,44,51,4579,7,kernel,0,"[32, 4, 1]",1.52381,1644
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939292407961.396,1,7,16,20,4593,7,kernel,0,"[200, 1, 1]",2.380952,1658
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.24,36352,6939292407964.372,1,7,168,1,4643,7,kernel,0,"[1, 8, 1]",0.095238,1683
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.904,26624,6939292407979.764,1,7,82,13,4667,7,kernel,0,"[8, 2, 4]",0.761905,1697
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939292407988.436,1,7,44,25,4669,7,kernel,0,"[16, 4, 1]",0.761905,1697
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.689,0,6939292410347.313,1,7,47,20,4700,7,kernel,0,"[100, 1, 1]",1.190476,1700
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.208,0,6939292410350.737,1,7,22,5,4710,7,kernel,0,"[50, 1, 1]",0.595238,1705
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.84,24,6939292410353.682,1,7,43,5,4739,7,kernel,0,"[50, 1, 1]",0.595238,1707
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",20.895,26624,6939292410358.386,1,7,82,13,4759,7,kernel,0,"[32, 2, 1]",0.761905,1719
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.665,0,6939292410380.049,1,7,18,20,4770,7,kernel,0,"[200, 1, 1]",2.380952,1722
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.944,0,6939292410382.578,1,7,47,79,4803,7,kernel,0,"[400, 1, 1]",4.761905,1724
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",16.801,26624,6939292410386.289,1,7,82,16,4822,7,kernel,0,"[8, 2, 5]",0.952381,1735
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.336,0,6939292410403.954,1,7,44,25,4824,7,kernel,0,"[16, 4, 1]",0.761905,1735
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292410406.993,1,7,47,20,4855,7,kernel,0,"[100, 1, 1]",1.190476,1738
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.631,0,6939292410410.13,1,7,22,5,4865,7,kernel,0,"[50, 1, 1]",0.595238,1743
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.521,24,6939292410412.593,1,7,43,5,4894,7,kernel,0,"[50, 1, 1]",0.595238,1745
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.072,26624,6939292410416.849,1,7,82,29,4918,7,kernel,0,"[24, 2, 3]",1.714286,1757
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939292410432.721,1,7,44,67,4920,7,kernel,0,"[48, 4, 1]",2.285714,1757
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.4,0,6939292410436.529,1,7,16,30,4934,7,kernel,0,"[300, 1, 1]",3.571429,1771
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.2,36352,6939292410439.666,1,7,168,1,4987,7,kernel,0,"[1, 8, 1]",0.095238,1798
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.743,26624,6939292410455.922,1,7,82,13,5011,7,kernel,0,"[8, 2, 4]",0.761905,1812
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.145,0,6939292410464.465,1,7,44,25,5013,7,kernel,0,"[16, 4, 1]",0.761905,1812
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292410467.441,1,7,47,20,5044,7,kernel,0,"[100, 1, 1]",1.190476,1815
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.432,0,6939292412740.271,1,7,22,5,5054,7,kernel,0,"[50, 1, 1]",0.595238,1820
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.0,24,6939292412743.759,1,7,43,5,5083,7,kernel,0,"[50, 1, 1]",0.595238,1822
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.576,26624,6939292412748.623,1,7,82,13,5103,7,kernel,0,"[8, 2, 4]",0.761905,1840
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292412758.095,1,7,44,25,5105,7,kernel,0,"[16, 4, 1]",0.761905,1840
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.36,26624,6939292412761.039,1,7,82,25,5125,7,kernel,0,"[16, 2, 4]",1.52381,1848
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939292412773.135,1,7,44,51,5127,7,kernel,0,"[32, 4, 1]",1.52381,1848
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.272,0,6939292412776.335,1,7,16,20,5141,7,kernel,0,"[200, 1, 1]",2.380952,1862
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",15.392,36352,6939292412779.407,1,7,168,1,5191,7,kernel,0,"[1, 8, 1]",0.095238,1887
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.064,26624,6939292412795.695,1,7,82,13,5215,7,kernel,0,"[8, 2, 4]",0.761905,1901
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939292412804.527,1,7,44,25,5217,7,kernel,0,"[16, 4, 1]",0.761905,1901
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939292412807.503,1,7,47,20,5248,7,kernel,0,"[100, 1, 1]",1.190476,1904
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939292412810.607,1,7,22,5,5258,7,kernel,0,"[50, 1, 1]",0.595238,1909
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939292412812.911,1,7,43,5,5287,7,kernel,0,"[50, 1, 1]",0.595238,1911
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.744,26624,6939292412817.295,1,7,82,13,5307,7,kernel,0,"[32, 2, 1]",0.761905,1923
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939292412837.871,1,7,18,20,5318,7,kernel,0,"[200, 1, 1]",2.380952,1926
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.944,0,6939292412840.367,1,7,47,79,5351,7,kernel,0,"[400, 1, 1]",4.761905,1928
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",16.896,26624,6939292412844.143,1,7,82,16,5370,7,kernel,0,"[8, 2, 5]",0.952381,1939
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939292412861.871,1,7,44,25,5372,7,kernel,0,"[16, 4, 1]",0.761905,1939
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939292412864.815,1,7,47,20,5403,7,kernel,0,"[100, 1, 1]",1.190476,1942
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939292412867.951,1,7,22,5,5413,7,kernel,0,"[50, 1, 1]",0.595238,1947
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.52,24,6939292412870.255,1,7,43,5,5442,7,kernel,0,"[50, 1, 1]",0.595238,1949
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.639,24,6939292414988.781,1,7,43,5,5471,7,kernel,0,"[50, 1, 1]",0.595238,1956
0,15.047619,X,ampere_sgemm_128x32_tn,0,"[256, 1, 1]",57.215,16384,6939292414994.157,1,7,57,31,5495,7,kernel,0,"[79, 2, 1]",1.880952,1970
