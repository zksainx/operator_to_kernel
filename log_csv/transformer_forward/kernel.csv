pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,9.523809,X,"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)",0,"[128, 1, 1]",3.2,0,6939565294282.014,1,7,32,20,49929,7,kernel,0,"[200, 1, 1]",2.380952,14341
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",2.144,0,6939565294559.486,1,7,22,5,49942,7,kernel,0,"[50, 1, 1]",0.595238,14351
0,9.523809,X,"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)",0,"[128, 1, 1]",2.688,0,6939565294716.285,1,7,32,20,49961,7,kernel,0,"[200, 1, 1]",2.380952,14355
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565294835.517,1,7,22,5,49974,7,kernel,0,"[50, 1, 1]",0.595238,14365
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.264,26624,6939565295438.172,1,7,82,29,49994,7,kernel,0,"[24, 2, 3]",1.714286,14376
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565295454.748,1,7,44,67,49996,7,kernel,0,"[48, 4, 1]",2.285714,14376
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.24,0,6939565295745.436,1,7,16,30,50010,7,kernel,0,"[300, 1, 1]",3.571429,14390
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.912,36352,6939565296115.067,1,7,168,1,50063,7,kernel,0,"[1, 8, 1]",0.095238,14417
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.0,26624,6939565296287.547,1,7,82,13,50087,7,kernel,0,"[8, 2, 4]",0.761905,14431
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565296301.787,1,7,44,25,50089,7,kernel,0,"[16, 4, 1]",0.761905,14431
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.4,0,6939565296514.299,1,7,47,20,50120,7,kernel,0,"[100, 1, 1]",1.190476,14434
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565296576.155,1,7,22,5,50130,7,kernel,0,"[50, 1, 1]",0.595238,14439
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.776,24,6939565296764.89,1,7,43,5,50159,7,kernel,0,"[50, 1, 1]",0.595238,14441
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.68,26624,6939565296964.538,1,7,82,13,50179,7,kernel,0,"[32, 2, 1]",0.761905,14453
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.599,0,6939565297065.082,1,7,18,20,50190,7,kernel,0,"[200, 1, 1]",2.380952,14456
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.04,0,6939565297199.097,1,7,47,79,50223,7,kernel,0,"[400, 1, 1]",4.761905,14458
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.312,26624,6939565297331.161,1,7,82,16,50242,7,kernel,0,"[8, 2, 5]",0.952381,14469
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565297349.273,1,7,44,25,50244,7,kernel,0,"[16, 4, 1]",0.761905,14469
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565297462.265,1,7,47,20,50275,7,kernel,0,"[100, 1, 1]",1.190476,14472
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565297512.633,1,7,22,5,50285,7,kernel,0,"[50, 1, 1]",0.595238,14477
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565297674.489,1,7,43,5,50314,7,kernel,0,"[50, 1, 1]",0.595238,14479
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.136,26624,6939565297934.072,1,7,82,29,50334,7,kernel,0,"[24, 2, 3]",1.714286,14491
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565297949.944,1,7,44,67,50336,7,kernel,0,"[48, 4, 1]",2.285714,14491
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939565298125.528,1,7,16,30,50350,7,kernel,0,"[300, 1, 1]",3.571429,14505
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.529,36352,6939565298442.327,1,7,168,1,50403,7,kernel,0,"[1, 8, 1]",0.095238,14532
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.064,26624,6939565298588.407,1,7,82,13,50427,7,kernel,0,"[8, 2, 4]",0.761905,14546
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565298600.919,1,7,44,25,50429,7,kernel,0,"[16, 4, 1]",0.761905,14546
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565298770.807,1,7,47,20,50460,7,kernel,0,"[100, 1, 1]",1.190476,14549
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565298824.631,1,7,22,5,50470,7,kernel,0,"[50, 1, 1]",0.595238,14554
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.648,24,6939565298947.191,1,7,43,5,50499,7,kernel,0,"[50, 1, 1]",0.595238,14556
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.68,26624,6939565299113.046,1,7,82,13,50519,7,kernel,0,"[32, 2, 1]",0.761905,14568
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939565299177.526,1,7,18,20,50530,7,kernel,0,"[200, 1, 1]",2.380952,14571
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.008,0,6939565299292.726,1,7,47,79,50563,7,kernel,0,"[400, 1, 1]",4.761905,14573
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.152,26624,6939565299409.366,1,7,82,16,50582,7,kernel,0,"[8, 2, 5]",0.952381,14584
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565299427.254,1,7,44,25,50584,7,kernel,0,"[16, 4, 1]",0.761905,14584
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565299529.43,1,7,47,20,50615,7,kernel,0,"[100, 1, 1]",1.190476,14587
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.697,0,6939565299575.733,1,7,22,5,50625,7,kernel,0,"[50, 1, 1]",0.595238,14592
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.551,24,6939565299690.71,1,7,43,5,50654,7,kernel,0,"[50, 1, 1]",0.595238,14594
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.104,26624,6939565299929.877,1,7,82,29,50674,7,kernel,0,"[24, 2, 3]",1.714286,14606
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939565299945.749,1,7,44,67,50676,7,kernel,0,"[48, 4, 1]",2.285714,14606
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.272,0,6939565300105.269,1,7,16,30,50690,7,kernel,0,"[300, 1, 1]",3.571429,14620
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.431,36352,6939565300425.813,1,7,168,1,50743,7,kernel,0,"[1, 8, 1]",0.095238,14647
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.84,26624,6939565300563.348,1,7,82,13,50767,7,kernel,0,"[8, 2, 4]",0.761905,14661
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565300575.924,1,7,44,25,50769,7,kernel,0,"[16, 4, 1]",0.761905,14661
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565300724.724,1,7,47,20,50800,7,kernel,0,"[100, 1, 1]",1.190476,14664
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565300775.348,1,7,22,5,50810,7,kernel,0,"[50, 1, 1]",0.595238,14669
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.616,24,6939565300895.827,1,7,43,5,50839,7,kernel,0,"[50, 1, 1]",0.595238,14671
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.52,26624,6939565301043.571,1,7,82,13,50859,7,kernel,0,"[32, 2, 1]",0.761905,14683
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939565301106.419,1,7,18,20,50870,7,kernel,0,"[200, 1, 1]",2.380952,14686
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.008,0,6939565301220.467,1,7,47,79,50903,7,kernel,0,"[400, 1, 1]",4.761905,14688
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.216,26624,6939565301336.051,1,7,82,16,50922,7,kernel,0,"[8, 2, 5]",0.952381,14699
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565301353.971,1,7,44,25,50924,7,kernel,0,"[16, 4, 1]",0.761905,14699
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565301460.787,1,7,47,20,50955,7,kernel,0,"[100, 1, 1]",1.190476,14702
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565301502.995,1,7,22,5,50965,7,kernel,0,"[50, 1, 1]",0.595238,14707
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.519,24,6939565301627.859,1,7,43,5,50994,7,kernel,0,"[50, 1, 1]",0.595238,14709
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.392,26624,6939565301884.306,1,7,82,29,51014,7,kernel,0,"[24, 2, 3]",1.714286,14721
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939565301900.466,1,7,44,67,51016,7,kernel,0,"[48, 4, 1]",2.285714,14721
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939565302060.818,1,7,16,30,51030,7,kernel,0,"[300, 1, 1]",3.571429,14735
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.528,36352,6939565302380.593,1,7,168,1,51083,7,kernel,0,"[1, 8, 1]",0.095238,14762
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.936,26624,6939565302519.345,1,7,82,13,51107,7,kernel,0,"[8, 2, 4]",0.761905,14776
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565302531.473,1,7,44,25,51109,7,kernel,0,"[16, 4, 1]",0.761905,14776
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565302681.617,1,7,47,20,51140,7,kernel,0,"[100, 1, 1]",1.190476,14779
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.568,0,6939565302734.193,1,7,22,5,51150,7,kernel,0,"[50, 1, 1]",0.595238,14784
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.648,24,6939565302850.801,1,7,43,5,51179,7,kernel,0,"[50, 1, 1]",0.595238,14786
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.776,26624,6939565302994.16,1,7,82,13,51199,7,kernel,0,"[32, 2, 1]",0.761905,14798
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939565303056.528,1,7,18,20,51210,7,kernel,0,"[200, 1, 1]",2.380952,14801
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.008,0,6939565303169.072,1,7,47,79,51243,7,kernel,0,"[400, 1, 1]",4.761905,14803
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.28,26624,6939565303287.024,1,7,82,16,51262,7,kernel,0,"[8, 2, 5]",0.952381,14814
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565303305.136,1,7,44,25,51264,7,kernel,0,"[16, 4, 1]",0.761905,14814
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565303414.448,1,7,47,20,51295,7,kernel,0,"[100, 1, 1]",1.190476,14817
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.663,0,6939565303457.936,1,7,22,5,51305,7,kernel,0,"[50, 1, 1]",0.595238,14822
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.52,24,6939565303574.959,1,7,43,5,51334,7,kernel,0,"[50, 1, 1]",0.595238,14824
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",14.816,26624,6939565303806.063,1,7,82,29,51354,7,kernel,0,"[24, 2, 3]",1.714286,14836
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939565303821.615,1,7,44,67,51356,7,kernel,0,"[48, 4, 1]",2.285714,14836
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.304,0,6939565304067.054,1,7,16,30,51370,7,kernel,0,"[300, 1, 1]",3.571429,14850
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.24,36352,6939565304382.094,1,7,168,1,51423,7,kernel,0,"[1, 8, 1]",0.095238,14877
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.808,26624,6939565304518.35,1,7,82,13,51447,7,kernel,0,"[8, 2, 4]",0.761905,14891
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565304530.702,1,7,44,25,51449,7,kernel,0,"[16, 4, 1]",0.761905,14891
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565304698.03,1,7,47,20,51480,7,kernel,0,"[100, 1, 1]",1.190476,14894
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565304751.598,1,7,22,5,51490,7,kernel,0,"[50, 1, 1]",0.595238,14899
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.616,24,6939565304872.846,1,7,43,5,51519,7,kernel,0,"[50, 1, 1]",0.595238,14901
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.84,26624,6939565305021.197,1,7,82,13,51539,7,kernel,0,"[32, 2, 1]",0.761905,14913
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939565305084.141,1,7,18,20,51550,7,kernel,0,"[200, 1, 1]",2.380952,14916
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.976,0,6939565305196.621,1,7,47,79,51583,7,kernel,0,"[400, 1, 1]",4.761905,14918
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.215,26624,6939565305316.845,1,7,82,16,51602,7,kernel,0,"[8, 2, 5]",0.952381,14929
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565305334.829,1,7,44,25,51604,7,kernel,0,"[16, 4, 1]",0.761905,14929
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565305427.34,1,7,47,20,51635,7,kernel,0,"[100, 1, 1]",1.190476,14932
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565305469.452,1,7,22,5,51645,7,kernel,0,"[50, 1, 1]",0.595238,14937
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.52,24,6939565305596.236,1,7,43,5,51674,7,kernel,0,"[50, 1, 1]",0.595238,14939
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.072,26624,6939565305850.156,1,7,82,29,51694,7,kernel,0,"[24, 2, 3]",1.714286,14951
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",3.04,0,6939565305865.964,1,7,44,67,51696,7,kernel,0,"[48, 4, 1]",2.285714,14951
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939565306038.444,1,7,16,30,51710,7,kernel,0,"[300, 1, 1]",3.571429,14965
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.432,36352,6939565306361.323,1,7,168,1,51763,7,kernel,0,"[1, 8, 1]",0.095238,14992
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.904,26624,6939565306500.491,1,7,82,13,51787,7,kernel,0,"[8, 2, 4]",0.761905,15006
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565306513.259,1,7,44,25,51789,7,kernel,0,"[16, 4, 1]",0.761905,15006
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.432,0,6939565306666.187,1,7,47,20,51820,7,kernel,0,"[100, 1, 1]",1.190476,15009
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.44,0,6939565306718.667,1,7,22,5,51830,7,kernel,0,"[50, 1, 1]",0.595238,15014
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.584,24,6939565306841.45,1,7,43,5,51859,7,kernel,0,"[50, 1, 1]",0.595238,15016
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.84,26624,6939565306987.978,1,7,82,13,51879,7,kernel,0,"[32, 2, 1]",0.761905,15028
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.664,0,6939565307053.578,1,7,18,20,51890,7,kernel,0,"[200, 1, 1]",2.380952,15031
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.976,0,6939565307169.45,1,7,47,79,51923,7,kernel,0,"[400, 1, 1]",4.761905,15033
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.023,26624,6939565307294.762,1,7,82,16,51942,7,kernel,0,"[8, 2, 5]",0.952381,15044
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565307312.586,1,7,44,25,51944,7,kernel,0,"[16, 4, 1]",0.761905,15044
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565307416.841,1,7,47,20,51975,7,kernel,0,"[100, 1, 1]",1.190476,15047
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565307464.137,1,7,22,5,51985,7,kernel,0,"[50, 1, 1]",0.595238,15052
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565307578.057,1,7,43,5,52014,7,kernel,0,"[50, 1, 1]",0.595238,15054
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565307710.281,1,7,43,5,52043,7,kernel,0,"[50, 1, 1]",0.595238,15061
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.137,26624,6939565308029.992,1,7,82,29,52063,7,kernel,0,"[24, 2, 3]",1.714286,15073
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.976,0,6939565308045.832,1,7,44,67,52065,7,kernel,0,"[48, 4, 1]",2.285714,15073
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565308212.008,1,7,16,30,52079,7,kernel,0,"[300, 1, 1]",3.571429,15087
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.657,36352,6939565308538.407,1,7,168,1,52132,7,kernel,0,"[1, 8, 1]",0.095238,15114
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.904,26624,6939565308674.311,1,7,82,13,52156,7,kernel,0,"[8, 2, 4]",0.761905,15128
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565308686.984,1,7,44,25,52158,7,kernel,0,"[16, 4, 1]",0.761905,15128
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565308838.343,1,7,47,20,52189,7,kernel,0,"[100, 1, 1]",1.190476,15131
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565308891.591,1,7,22,5,52199,7,kernel,0,"[50, 1, 1]",0.595238,15136
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.064,24,6939565309047.911,1,7,43,5,52228,7,kernel,0,"[50, 1, 1]",0.595238,15138
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.224,26624,6939565309416.39,1,7,82,13,52248,7,kernel,0,"[8, 2, 4]",0.761905,15156
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565309429.702,1,7,44,25,52250,7,kernel,0,"[16, 4, 1]",0.761905,15156
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.36,26624,6939565309529.19,1,7,82,25,52270,7,kernel,0,"[16, 2, 4]",1.52381,15164
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939565309541.446,1,7,44,51,52272,7,kernel,0,"[32, 4, 1]",1.52381,15164
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565309758.758,1,7,16,20,52286,7,kernel,0,"[200, 1, 1]",2.380952,15178
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.272,36352,6939565310076.037,1,7,168,1,52336,7,kernel,0,"[1, 8, 1]",0.095238,15203
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.064,26624,6939565310218.437,1,7,82,13,52360,7,kernel,0,"[8, 2, 4]",0.761905,15217
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565310230.597,1,7,44,25,52362,7,kernel,0,"[16, 4, 1]",0.761905,15217
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.337,0,6939565310392.132,1,7,47,20,52393,7,kernel,0,"[100, 1, 1]",1.190476,15220
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.761,0,6939565310447.556,1,7,22,5,52403,7,kernel,0,"[50, 1, 1]",0.595238,15225
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565310572.708,1,7,43,5,52432,7,kernel,0,"[50, 1, 1]",0.595238,15227
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.84,26624,6939565310835.684,1,7,82,13,52452,7,kernel,0,"[32, 2, 1]",0.761905,15239
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.6,0,6939565310904.004,1,7,18,20,52463,7,kernel,0,"[200, 1, 1]",2.380952,15242
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.007,0,6939565311023.716,1,7,47,79,52496,7,kernel,0,"[400, 1, 1]",4.761905,15244
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.217,26624,6939565311144.195,1,7,82,16,52515,7,kernel,0,"[8, 2, 5]",0.952381,15255
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565311162.275,1,7,44,25,52517,7,kernel,0,"[16, 4, 1]",0.761905,15255
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565311272.323,1,7,47,20,52548,7,kernel,0,"[100, 1, 1]",1.190476,15258
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.632,0,6939565311319.971,1,7,22,5,52558,7,kernel,0,"[50, 1, 1]",0.595238,15263
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.968,24,6939565311440.803,1,7,43,5,52587,7,kernel,0,"[50, 1, 1]",0.595238,15265
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.232,26624,6939565311676.547,1,7,82,29,52607,7,kernel,0,"[24, 2, 3]",1.714286,15277
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.943,0,6939565311692.611,1,7,44,67,52609,7,kernel,0,"[48, 4, 1]",2.285714,15277
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939565311853.059,1,7,16,30,52623,7,kernel,0,"[300, 1, 1]",3.571429,15291
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.368,36352,6939565312176.962,1,7,168,1,52676,7,kernel,0,"[1, 8, 1]",0.095238,15318
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.873,26624,6939565312319.649,1,7,82,13,52700,7,kernel,0,"[8, 2, 4]",0.761905,15332
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565312330.498,1,7,44,25,52702,7,kernel,0,"[16, 4, 1]",0.761905,15332
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565312485.473,1,7,47,20,52733,7,kernel,0,"[100, 1, 1]",1.190476,15335
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.473,0,6939565312538.369,1,7,22,5,52743,7,kernel,0,"[50, 1, 1]",0.595238,15340
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565312658.529,1,7,43,5,52772,7,kernel,0,"[50, 1, 1]",0.595238,15342
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.128,26624,6939565312929.185,1,7,82,13,52792,7,kernel,0,"[8, 2, 4]",0.761905,15360
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",1.984,0,6939565312941.505,1,7,44,25,52794,7,kernel,0,"[16, 4, 1]",0.761905,15360
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.233,26624,6939565313108.192,1,7,82,25,52814,7,kernel,0,"[16, 2, 4]",1.52381,15368
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.401,0,6939565313120.256,1,7,44,51,52816,7,kernel,0,"[32, 4, 1]",1.52381,15368
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.208,0,6939565313274.272,1,7,16,20,52830,7,kernel,0,"[200, 1, 1]",2.380952,15382
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.56,36352,6939565313586.976,1,7,168,1,52880,7,kernel,0,"[1, 8, 1]",0.095238,15407
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.032,26624,6939565313723.391,1,7,82,13,52904,7,kernel,0,"[8, 2, 4]",0.761905,15421
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565313735.103,1,7,44,25,52906,7,kernel,0,"[16, 4, 1]",0.761905,15421
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565313890.495,1,7,47,20,52937,7,kernel,0,"[100, 1, 1]",1.190476,15424
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565313942.879,1,7,22,5,52947,7,kernel,0,"[50, 1, 1]",0.595238,15429
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565314073.599,1,7,43,5,52976,7,kernel,0,"[50, 1, 1]",0.595238,15431
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.617,26624,6939565314221.054,1,7,82,13,52996,7,kernel,0,"[32, 2, 1]",0.761905,15443
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.632,0,6939565314283.231,1,7,18,20,53007,7,kernel,0,"[200, 1, 1]",2.380952,15446
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.073,0,6939565314399.262,1,7,47,79,53040,7,kernel,0,"[400, 1, 1]",4.761905,15448
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.344,26624,6939565314519.646,1,7,82,16,53059,7,kernel,0,"[8, 2, 5]",0.952381,15459
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565314537.822,1,7,44,25,53061,7,kernel,0,"[16, 4, 1]",0.761905,15459
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565314654.27,1,7,47,20,53092,7,kernel,0,"[100, 1, 1]",1.190476,15462
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.824,0,6939565314699.646,1,7,22,5,53102,7,kernel,0,"[50, 1, 1]",0.595238,15467
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.489,24,6939565314817.565,1,7,43,5,53131,7,kernel,0,"[50, 1, 1]",0.595238,15469
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.2,26624,6939565315046.718,1,7,82,29,53151,7,kernel,0,"[24, 2, 3]",1.714286,15481
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565315062.685,1,7,44,67,53153,7,kernel,0,"[48, 4, 1]",2.285714,15481
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.336,0,6939565315220.253,1,7,16,30,53167,7,kernel,0,"[300, 1, 1]",3.571429,15495
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.464,36352,6939565315532.605,1,7,168,1,53220,7,kernel,0,"[1, 8, 1]",0.095238,15522
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.777,26624,6939565315667.132,1,7,82,13,53244,7,kernel,0,"[8, 2, 4]",0.761905,15536
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.112,0,6939565315679.9,1,7,44,25,53246,7,kernel,0,"[16, 4, 1]",0.761905,15536
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565315831.292,1,7,47,20,53277,7,kernel,0,"[100, 1, 1]",1.190476,15539
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565315882.3,1,7,22,5,53287,7,kernel,0,"[50, 1, 1]",0.595238,15544
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.032,24,6939565315999.068,1,7,43,5,53316,7,kernel,0,"[50, 1, 1]",0.595238,15546
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.16,26624,6939565316263.579,1,7,82,13,53336,7,kernel,0,"[8, 2, 4]",0.761905,15564
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.015,0,6939565316275.74,1,7,44,25,53338,7,kernel,0,"[16, 4, 1]",0.761905,15564
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.232,26624,6939565316365.883,1,7,82,25,53358,7,kernel,0,"[16, 2, 4]",1.52381,15572
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.432,0,6939565316377.915,1,7,44,51,53360,7,kernel,0,"[32, 4, 1]",1.52381,15572
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.208,0,6939565316526.747,1,7,16,20,53374,7,kernel,0,"[200, 1, 1]",2.380952,15586
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.4,36352,6939565316831.099,1,7,168,1,53424,7,kernel,0,"[1, 8, 1]",0.095238,15611
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.256,26624,6939565316961.306,1,7,82,13,53448,7,kernel,0,"[8, 2, 4]",0.761905,15625
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565316972.731,1,7,44,25,53450,7,kernel,0,"[16, 4, 1]",0.761905,15625
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565317122.522,1,7,47,20,53481,7,kernel,0,"[100, 1, 1]",1.190476,15628
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.408,0,6939565317172.538,1,7,22,5,53491,7,kernel,0,"[50, 1, 1]",0.595238,15633
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.52,24,6939565317295.29,1,7,43,5,53520,7,kernel,0,"[50, 1, 1]",0.595238,15635
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.487,26624,6939565317437.786,1,7,82,13,53540,7,kernel,0,"[32, 2, 1]",0.761905,15647
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.633,0,6939565317503.257,1,7,18,20,53551,7,kernel,0,"[200, 1, 1]",2.380952,15650
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.04,0,6939565317634.777,1,7,47,79,53584,7,kernel,0,"[400, 1, 1]",4.761905,15652
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.216,26624,6939565317761.337,1,7,82,16,53603,7,kernel,0,"[8, 2, 5]",0.952381,15663
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565317779.289,1,7,44,25,53605,7,kernel,0,"[16, 4, 1]",0.761905,15663
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565317899.865,1,7,47,20,53636,7,kernel,0,"[100, 1, 1]",1.190476,15666
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565317946.457,1,7,22,5,53646,7,kernel,0,"[50, 1, 1]",0.595238,15671
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.488,24,6939565318066.265,1,7,43,5,53675,7,kernel,0,"[50, 1, 1]",0.595238,15673
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.328,26624,6939565318301.496,1,7,82,29,53695,7,kernel,0,"[24, 2, 3]",1.714286,15685
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565318317.592,1,7,44,67,53697,7,kernel,0,"[48, 4, 1]",2.285714,15685
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.368,0,6939565318476.856,1,7,16,30,53711,7,kernel,0,"[300, 1, 1]",3.571429,15699
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.495,36352,6939565318726.968,1,7,168,1,53764,7,kernel,0,"[1, 8, 1]",0.095238,15726
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.841,26624,6939565318860.535,1,7,82,13,53788,7,kernel,0,"[8, 2, 4]",0.761905,15740
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565318873.496,1,7,44,25,53790,7,kernel,0,"[16, 4, 1]",0.761905,15740
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565319037.463,1,7,47,20,53821,7,kernel,0,"[100, 1, 1]",1.190476,15743
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565319091.447,1,7,22,5,53831,7,kernel,0,"[50, 1, 1]",0.595238,15748
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.584,24,6939565319211.831,1,7,43,5,53860,7,kernel,0,"[50, 1, 1]",0.595238,15750
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.064,26624,6939565319479.831,1,7,82,13,53880,7,kernel,0,"[8, 2, 4]",0.761905,15768
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.016,0,6939565319492.215,1,7,44,25,53882,7,kernel,0,"[16, 4, 1]",0.761905,15768
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.296,26624,6939565319583.575,1,7,82,25,53902,7,kernel,0,"[16, 2, 4]",1.52381,15776
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.4,0,6939565319595.703,1,7,44,51,53904,7,kernel,0,"[32, 4, 1]",1.52381,15776
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.144,0,6939565319758.263,1,7,16,20,53918,7,kernel,0,"[200, 1, 1]",2.380952,15790
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.656,36352,6939565320044.566,1,7,168,1,53968,7,kernel,0,"[1, 8, 1]",0.095238,15815
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.192,26624,6939565320176.822,1,7,82,13,53992,7,kernel,0,"[8, 2, 4]",0.761905,15829
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565320188.15,1,7,44,25,53994,7,kernel,0,"[16, 4, 1]",0.761905,15829
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565320337.174,1,7,47,20,54025,7,kernel,0,"[100, 1, 1]",1.190476,15832
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.536,0,6939565320390.357,1,7,22,5,54035,7,kernel,0,"[50, 1, 1]",0.595238,15837
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.584,24,6939565320508.277,1,7,43,5,54064,7,kernel,0,"[50, 1, 1]",0.595238,15839
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.776,26624,6939565320653.589,1,7,82,13,54084,7,kernel,0,"[32, 2, 1]",0.761905,15851
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.664,0,6939565320715.669,1,7,18,20,54095,7,kernel,0,"[200, 1, 1]",2.380952,15854
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.104,0,6939565320824.309,1,7,47,79,54128,7,kernel,0,"[400, 1, 1]",4.761905,15856
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.183,26624,6939565320950.229,1,7,82,16,54147,7,kernel,0,"[8, 2, 5]",0.952381,15867
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.143,0,6939565320968.213,1,7,44,25,54149,7,kernel,0,"[16, 4, 1]",0.761905,15867
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565321147.124,1,7,47,20,54180,7,kernel,0,"[100, 1, 1]",1.190476,15870
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.76,0,6939565321195.988,1,7,22,5,54190,7,kernel,0,"[50, 1, 1]",0.595238,15875
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.744,24,6939565321307.828,1,7,43,5,54219,7,kernel,0,"[50, 1, 1]",0.595238,15877
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.008,26624,6939565321539.731,1,7,82,29,54239,7,kernel,0,"[24, 2, 3]",1.714286,15889
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565321555.508,1,7,44,67,54241,7,kernel,0,"[48, 4, 1]",2.285714,15889
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.432,0,6939565321748.883,1,7,16,30,54255,7,kernel,0,"[300, 1, 1]",3.571429,15903
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.496,36352,6939565322058.195,1,7,168,1,54308,7,kernel,0,"[1, 8, 1]",0.095238,15930
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.841,26624,6939565322197.234,1,7,82,13,54332,7,kernel,0,"[8, 2, 4]",0.761905,15944
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565322208.691,1,7,44,25,54334,7,kernel,0,"[16, 4, 1]",0.761905,15944
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565322363.474,1,7,47,20,54365,7,kernel,0,"[100, 1, 1]",1.190476,15947
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565322415.154,1,7,22,5,54375,7,kernel,0,"[50, 1, 1]",0.595238,15952
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.584,24,6939565322532.658,1,7,43,5,54404,7,kernel,0,"[50, 1, 1]",0.595238,15954
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.192,26624,6939565322806.482,1,7,82,13,54424,7,kernel,0,"[8, 2, 4]",0.761905,15972
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.047,0,6939565322818.226,1,7,44,25,54426,7,kernel,0,"[16, 4, 1]",0.761905,15972
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.2,26624,6939565322911.218,1,7,82,25,54446,7,kernel,0,"[16, 2, 4]",1.52381,15980
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.433,0,6939565322923.153,1,7,44,51,54448,7,kernel,0,"[32, 4, 1]",1.52381,15980
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565323080.241,1,7,16,20,54462,7,kernel,0,"[200, 1, 1]",2.380952,15994
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.496,36352,6939565323378.961,1,7,168,1,54512,7,kernel,0,"[1, 8, 1]",0.095238,16019
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.0,26624,6939565323511.569,1,7,82,13,54536,7,kernel,0,"[8, 2, 4]",0.761905,16033
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.175,0,6939565323522.801,1,7,44,25,54538,7,kernel,0,"[16, 4, 1]",0.761905,16033
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565323675.76,1,7,47,20,54569,7,kernel,0,"[100, 1, 1]",1.190476,16036
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565323728.112,1,7,22,5,54579,7,kernel,0,"[50, 1, 1]",0.595238,16041
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",4.064,24,6939565323844.784,1,7,43,5,54608,7,kernel,0,"[50, 1, 1]",0.595238,16043
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.648,26624,6939565323987.472,1,7,82,13,54628,7,kernel,0,"[32, 2, 1]",0.761905,16055
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.664,0,6939565324050.096,1,7,18,20,54639,7,kernel,0,"[200, 1, 1]",2.380952,16058
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.04,0,6939565324165.135,1,7,47,79,54672,7,kernel,0,"[400, 1, 1]",4.761905,16060
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.12,26624,6939565324280.944,1,7,82,16,54691,7,kernel,0,"[8, 2, 5]",0.952381,16071
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565324298.799,1,7,44,25,54693,7,kernel,0,"[16, 4, 1]",0.761905,16071
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565324402.095,1,7,47,20,54724,7,kernel,0,"[100, 1, 1]",1.190476,16074
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.6,0,6939565324448.367,1,7,22,5,54734,7,kernel,0,"[50, 1, 1]",0.595238,16079
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565324554.351,1,7,43,5,54763,7,kernel,0,"[50, 1, 1]",0.595238,16081
0,13.714286,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",15.232,26624,6939565324778.639,1,7,82,29,54783,7,kernel,0,"[24, 2, 3]",1.714286,16093
0,36.57143,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.944,0,6939565324794.638,1,7,44,67,54785,7,kernel,0,"[48, 4, 1]",2.285714,16093
0,14.285714,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.304,0,6939565324965.742,1,7,16,30,54799,7,kernel,0,"[300, 1, 1]",3.571429,16107
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.56,36352,6939565325297.998,1,7,168,1,54852,7,kernel,0,"[1, 8, 1]",0.095238,16134
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",7.841,26624,6939565325437.325,1,7,82,13,54876,7,kernel,0,"[8, 2, 4]",0.761905,16148
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.112,0,6939565325449.933,1,7,44,25,54878,7,kernel,0,"[16, 4, 1]",0.761905,16148
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6939565325624.557,1,7,47,20,54909,7,kernel,0,"[100, 1, 1]",1.190476,16151
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.472,0,6939565325683.629,1,7,22,5,54919,7,kernel,0,"[50, 1, 1]",0.595238,16156
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.584,24,6939565325808.237,1,7,43,5,54948,7,kernel,0,"[50, 1, 1]",0.595238,16158
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.033,26624,6939565326091.82,1,7,82,13,54968,7,kernel,0,"[8, 2, 4]",0.761905,16176
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.015,0,6939565326104.045,1,7,44,25,54970,7,kernel,0,"[16, 4, 1]",0.761905,16176
0,12.190476,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",11.296,26624,6939565326204.236,1,7,82,25,54990,7,kernel,0,"[16, 2, 4]",1.52381,16184
0,24.380953,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.401,0,6939565326216.332,1,7,44,51,54992,7,kernel,0,"[32, 4, 1]",1.52381,16184
0,9.523809,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.176,0,6939565326371.468,1,7,16,20,55006,7,kernel,0,"[200, 1, 1]",2.380952,16198
0,0.380952,X,"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)",0,"[32, 4, 1]",14.401,36352,6939565326660.939,1,7,168,1,55056,7,kernel,0,"[1, 8, 1]",0.095238,16223
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",8.193,26624,6939565326793.579,1,7,82,13,55080,7,kernel,0,"[8, 2, 4]",0.761905,16237
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.144,0,6939565326804.748,1,7,44,25,55082,7,kernel,0,"[16, 4, 1]",0.761905,16237
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565326956.427,1,7,47,20,55113,7,kernel,0,"[100, 1, 1]",1.190476,16240
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.664,0,6939565327008.843,1,7,22,5,55123,7,kernel,0,"[50, 1, 1]",0.595238,16245
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.552,24,6939565327127.787,1,7,43,5,55152,7,kernel,0,"[50, 1, 1]",0.595238,16247
0,6.095238,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",19.745,26624,6939565327315.818,1,7,82,13,55172,7,kernel,0,"[32, 2, 1]",0.761905,16259
0,9.523809,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.631,0,6939565327384.171,1,7,18,20,55183,7,kernel,0,"[200, 1, 1]",2.380952,16262
0,38.095238,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.008,0,6939565327487.178,1,7,47,79,55216,7,kernel,0,"[400, 1, 1]",4.761905,16264
0,7.619048,X,ampere_sgemm_64x32_sliced1x4_tn,0,"[256, 1, 1]",17.056,26624,6939565327588.746,1,7,82,16,55235,7,kernel,0,"[8, 2, 5]",0.952381,16275
0,12.190476,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, true, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,"[32, 16, 1]",2.176,0,6939565327606.538,1,7,44,25,55237,7,kernel,0,"[16, 4, 1]",0.761905,16275
0,9.523809,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.336,0,6939565327698.442,1,7,47,20,55268,7,kernel,0,"[100, 1, 1]",1.190476,16278
0,2.380952,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,"[128, 1, 1]",1.792,0,6939565327741.962,1,7,22,5,55278,7,kernel,0,"[50, 1, 1]",0.595238,16283
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.52,24,6939565327840.234,1,7,43,5,55307,7,kernel,0,"[50, 1, 1]",0.595238,16285
0,2.380952,X,"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)",0,"[32, 4, 1]",3.519,24,6939565327977.29,1,7,43,5,55336,7,kernel,0,"[50, 1, 1]",0.595238,16292
0,15.047619,X,ampere_sgemm_128x32_tn,0,"[256, 1, 1]",57.792,16384,6939565328169.161,1,7,57,31,55356,7,kernel,0,"[79, 2, 1]",1.880952,16306
