ph,shared memory,grid,correlation,block,blocks per SM,stream,name,context,queued,cat,pid,est. achieved occupancy %,registers per thread,ts,External id,dur,device,tid,warps per SM
X,0,"[197, 1, 1]",15,"[256, 1, 1]",2.345238,7,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",1,0,kernel,0,39,16,6083647120702.857,5,2.209,0,7,18.761906
X,16384,"[392, 1, 1]",18,"[128, 1, 1]",4.666667,7,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,1,0,kernel,0,33,128,6083647120705.801,5,39.52,0,7,18.666666
X,0,"[12544, 1, 1]",26,"[128, 1, 1]",149.333328,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647120746.122,8,46.015,0,7,597.333313
X,0,"[1, 1, 1]",32,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647120792.905,9,2.272,0,7,0.047619
X,144,"[64, 1, 1]",84,"[512, 1, 1]",0.761905,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,25,40,6083647120795.913,12,64.096,0,7,12.190476
X,0,"[6272, 1, 1]",104,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647120907.945,25,46.368,0,7,298.666656
X,8704,"[2, 16, 1]",127,"[32, 4, 1]",0.380952,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",1,0,kernel,0,3,40,6083647120955.113,30,3.136,0,7,1.52381
X,49152,"[2, 28, 14]",129,"[256, 1, 1]",9.333333,7,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,1,0,kernel,0,33,126,6083647120959.049,30,144.192,0,7,74.666664
X,0,"[12544, 1, 1]",137,"[128, 1, 1]",149.333328,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647121104.137,33,46.016,0,7,597.333313
X,0,"[1, 1, 1]",143,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647121150.857,34,2.112,0,7,0.047619
X,144,"[64, 1, 1]",195,"[512, 1, 1]",0.761905,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,25,40,6083647121153.736,37,64.705,0,7,12.190476
X,0,"[6272, 1, 1]",215,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647121265.929,50,46.271,0,7,298.666656
X,0,"[3136, 1, 1]",234,"[256, 1, 1]",37.333332,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,100,26,6083647121313.0,53,44.417,0,7,298.666656
X,4224,"[392, 2, 1]",252,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647121358.216,57,10.336,0,7,74.666664
X,4224,"[1, 2, 128]",254,"[256, 1, 1]",3.047619,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,51,38,6083647121369.352,57,4.0,0,7,24.380953
X,98304,"[1, 49, 1]",259,"[256, 1, 1]",0.583333,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize256x128x32_stage2_warpsize4x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,0,254,6083647121374.12,57,62.336,0,7,4.666667
X,0,"[6272, 1, 1]",268,"[128, 1, 1]",74.666664,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647121437.608,60,17.568,0,7,298.666656
X,0,"[1, 1, 1]",274,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647121455.912,61,2.24,0,7,0.047619
X,144,"[128, 1, 1]",326,"[512, 1, 1]",1.52381,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,51,40,6083647121458.952,64,22.048,0,7,24.380953
X,0,"[3136, 1, 1]",346,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647121505.8,77,23.552,0,7,149.333328
X,4224,"[392, 4, 1]",368,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647121530.152,82,21.376,0,7,149.333328
X,4224,"[1, 4, 128]",370,"[256, 1, 1]",6.095238,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647121552.712,82,4.96,0,7,48.761906
X,49152,"[1, 98, 2]",374,"[128, 1, 1]",2.333333,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,17,230,6083647121560.872,82,102.08,0,7,9.333333
X,0,"[6272, 1, 1]",383,"[128, 1, 1]",74.666664,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647121663.752,85,20.384,0,7,298.666656
X,0,"[1, 1, 1]",389,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647121684.936,86,2.304,0,7,0.047619
X,144,"[128, 1, 1]",441,"[512, 1, 1]",1.52381,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,51,40,6083647121688.136,89,22.24,0,7,24.380953
X,0,"[3136, 1, 1]",461,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647121735.208,102,24.0,0,7,149.333328
X,0,"[1568, 1, 1]",480,"[256, 1, 1]",18.666666,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,100,26,6083647121759.943,105,20.48,0,7,149.333328
X,4224,"[98, 4, 1]",498,"[256, 1, 1]",4.666667,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,78,38,6083647121781.16,109,4.736,0,7,37.333332
X,4224,"[1, 4, 256]",500,"[256, 1, 1]",12.190476,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647121786.663,109,6.945,0,7,97.523811
X,49152,"[2, 25, 1]",503,"[128, 1, 1]",0.595238,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,5,230,6083647121794.343,109,53.28,0,7,2.380952
X,0,"[3136, 1, 1]",512,"[128, 1, 1]",37.333332,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647121848.52,112,6.943,0,7,149.333328
X,0,"[1, 1, 1]",518,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647121856.264,113,1.983,0,7,0.047619
X,14480,"[256, 1, 1]",571,"[512, 1, 1]",3.047619,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647121859.143,116,11.232,0,7,48.761906
X,0,"[1568, 1, 1]",592,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647121880.775,129,6.657,0,7,74.666664
X,4224,"[98, 8, 1]",614,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647121888.263,134,7.488,0,7,74.666664
X,4224,"[1, 8, 256]",616,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647121896.519,134,11.072,0,7,195.047623
X,49152,"[2, 25, 8]",620,"[128, 1, 1]",4.761905,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,17,230,6083647121910.536,134,83.967,0,7,19.047619
X,0,"[3136, 1, 1]",629,"[128, 1, 1]",37.333332,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647121995.367,137,7.296,0,7,149.333328
X,0,"[1, 1, 1]",635,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647122003.399,138,1.952,0,7,0.047619
X,14480,"[256, 1, 1]",688,"[512, 1, 1]",3.047619,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647122006.119,141,10.56,0,7,48.761906
X,0,"[1568, 1, 1]",709,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647122026.695,154,7.168,0,7,74.666664
X,4224,"[98, 8, 1]",731,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647122034.631,159,6.464,0,7,74.666664
X,4224,"[1, 8, 256]",733,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647122041.895,159,10.784,0,7,195.047623
X,49152,"[2, 25, 8]",737,"[128, 1, 1]",4.761905,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,17,230,6083647122056.007,159,88.416,0,7,19.047619
X,0,"[3136, 1, 1]",746,"[128, 1, 1]",37.333332,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647122145.255,162,7.616,0,7,149.333328
X,0,"[1, 1, 1]",752,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647122153.735,163,1.92,0,7,0.047619
X,14480,"[256, 1, 1]",805,"[512, 1, 1]",3.047619,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647122156.423,166,10.112,0,7,48.761906
X,0,"[1568, 1, 1]",826,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6083647122176.583,179,6.944,0,7,74.666664
X,0,"[784, 1, 1]",845,"[256, 1, 1]",9.333333,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,100,26,6083647122184.423,182,6.688,0,7,74.666664
X,4224,"[25, 8, 1]",863,"[256, 1, 1]",2.380952,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,40,38,6083647122191.847,186,2.464,0,7,19.047619
X,4224,"[1, 8, 512]",865,"[256, 1, 1]",48.761906,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647122195.111,186,18.848,0,7,390.095245
X,73728,"[28, 2, 1]",869,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),1,0,kernel,0,0,162,6083647122214.695,186,51.168,0,7,2.666667
X,4224,"[25, 16, 1]",873,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6083647122266.631,186,3.392,0,7,38.095238
X,0,"[1568, 1, 1]",881,"[128, 1, 1]",18.666666,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647122270.855,189,4.512,0,7,74.666664
X,0,"[1, 1, 1]",887,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647122276.135,190,1.568,0,7,0.047619
X,4240,"[512, 1, 1]",940,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647122278.503,193,9.856,0,7,97.523811
X,0,"[784, 1, 1]",961,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,78,18,6083647122292.423,206,2.431,0,7,37.333332
X,4224,"[25, 16, 1]",983,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6083647122295.591,211,2.976,0,7,38.095238
X,4224,"[1, 16, 512]",985,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647122299.366,211,33.857,0,7,780.190491
X,73728,"[28, 2, 1]",989,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),1,0,kernel,0,0,168,6083647122333.959,211,96.063,0,7,2.666667
X,4224,"[25, 16, 1]",993,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6083647122430.854,211,3.424,0,7,38.095238
X,0,"[1568, 1, 1]",1001,"[128, 1, 1]",18.666666,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647122435.11,214,4.096,0,7,74.666664
X,0,"[1, 1, 1]",1007,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647122440.07,215,1.601,0,7,0.047619
X,4240,"[512, 1, 1]",1060,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647122442.47,218,9.728,0,7,97.523811
X,0,"[784, 1, 1]",1081,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,78,18,6083647122456.326,231,2.433,0,7,37.333332
X,4224,"[25, 16, 1]",1103,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6083647122459.494,236,2.976,0,7,38.095238
X,4224,"[1, 16, 512]",1105,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647122463.27,236,34.016,0,7,780.190491
X,73728,"[28, 2, 1]",1109,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),1,0,kernel,0,0,168,6083647122498.054,236,95.648,0,7,2.666667
X,4224,"[25, 16, 1]",1113,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6083647122594.47,236,3.296,0,7,38.095238
X,0,"[1568, 1, 1]",1121,"[128, 1, 1]",18.666666,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6083647122598.566,239,4.192,0,7,74.666664
X,0,"[1, 1, 1]",1127,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647122603.526,240,1.536,0,7,0.047619
X,4240,"[512, 1, 1]",1180,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647122605.894,243,9.952,0,7,97.523811
X,0,"[784, 1, 1]",1201,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,78,18,6083647122619.974,256,2.432,0,7,37.333332
X,0,"[392, 1, 1]",1220,"[256, 1, 1]",4.666667,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,78,26,6083647122623.142,259,4.096,0,7,37.333332
X,4224,"[7, 16, 1]",1238,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6083647122627.942,263,2.176,0,7,10.666667
X,4224,"[1, 16, 512]",1240,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647122630.854,263,33.856,0,7,780.190491
X,100352,"[8, 2, 4]",1246,"[128, 1, 1]",0.761905,7,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,198,6083647122667.27,263,38.4,0,7,3.047619
X,4224,"[7, 16, 1]",1249,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6083647122706.406,263,2.752,0,7,10.666667
X,0,"[392, 1, 1]",1257,"[128, 1, 1]",4.666667,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,39,16,6083647122710.054,266,2.944,0,7,18.666666
X,0,"[1, 1, 1]",1263,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647122713.894,267,1.568,0,7,0.047619
X,2192,"[512, 1, 1]",1316,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647127310.301,270,9.793,0,7,97.523811
X,0,"[196, 1, 1]",1337,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,19,18,6083647127323.901,283,1.728,0,7,9.333333
X,4224,"[7, 16, 1]",1359,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6083647127326.397,288,2.144,0,7,10.666667
X,4224,"[1, 16, 512]",1361,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647127329.405,288,33.952,0,7,780.190491
X,100352,"[8, 2, 4]",1367,"[128, 1, 1]",0.761905,7,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,198,6083647127366.621,288,38.56,0,7,3.047619
X,4224,"[7, 16, 1]",1370,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6083647127405.949,288,2.88,0,7,10.666667
X,0,"[392, 1, 1]",1378,"[128, 1, 1]",4.666667,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,39,16,6083647127409.629,291,2.848,0,7,18.666666
X,0,"[1, 1, 1]",1384,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647127413.277,292,1.568,0,7,0.047619
X,2192,"[512, 1, 1]",1437,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647127415.645,295,8.704,0,7,97.523811
X,0,"[196, 1, 1]",1458,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,19,18,6083647127427.581,308,1.696,0,7,9.333333
X,4224,"[7, 16, 1]",1480,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6083647127430.109,313,2.112,0,7,10.666667
X,4224,"[1, 16, 512]",1482,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6083647127433.469,313,33.184,0,7,780.190491
X,100352,"[8, 2, 4]",1488,"[128, 1, 1]",0.761905,7,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,198,6083647127469.981,313,38.496,0,7,3.047619
X,4224,"[7, 16, 1]",1491,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6083647127509.629,313,2.464,0,7,10.666667
X,0,"[392, 1, 1]",1499,"[128, 1, 1]",4.666667,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,39,16,6083647127512.861,316,2.88,0,7,18.666666
X,0,"[1, 1, 1]",1505,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6083647127516.541,317,1.568,0,7,0.047619
X,2192,"[512, 1, 1]",1558,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6083647127518.909,320,8.672,0,7,97.523811
X,0,"[196, 1, 1]",1579,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,19,18,6083647127531.005,333,1.664,0,7,9.333333
X,0,"[98, 1, 1]",1598,"[256, 1, 1]",1.166667,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,19,26,6083647127533.533,336,2.72,0,7,9.333333
X,528,"[1024, 1, 1]",1617,"[32, 4, 1]",12.190476,7,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,kernel,0,25,159,6083647127537.117,342,692.991,0,7,48.761906
X,0,"[16, 1, 1]",1648,"[256, 1, 1]",0.190476,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",1,0,kernel,0,3,47,6083647128230.94,344,2.368,0,7,1.52381
X,2560,"[512, 1, 1]",1667,"[128, 1, 1]",6.095238,7,"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, false, true, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>, float, float)",1,0,kernel,0,51,58,6083647128234.14,353,115.807,0,7,24.380953
X,0,"[16, 1, 1]",1698,"[256, 1, 1]",0.190476,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",1,0,kernel,0,3,47,6083647128350.779,355,3.265,0,7,1.52381
X,528,"[250, 1, 1]",1717,"[32, 4, 1]",2.976191,7,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,kernel,0,25,159,6083647128354.875,364,30.336,0,7,11.904762
