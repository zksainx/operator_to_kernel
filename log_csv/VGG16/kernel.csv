pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,18.761906,X,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",0,"[256, 1, 1]",2.209,0,6083647120702.857,1,7,16,39,15,7,kernel,0,"[197, 1, 1]",2.345238,5
0,18.666666,X,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,0,"[128, 1, 1]",39.52,16384,6083647120705.801,1,7,128,33,18,7,kernel,0,"[392, 1, 1]",4.666667,5
0,597.333313,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",46.015,0,6083647120746.122,1,7,16,100,26,7,kernel,0,"[12544, 1, 1]",149.333328,8
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.272,0,6083647120792.905,1,7,24,0,32,7,kernel,0,"[1, 1, 1]",0.011905,9
0,12.190476,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",64.096,144,6083647120795.913,1,7,40,25,84,7,kernel,0,"[64, 1, 1]",0.761905,12
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",46.368,0,6083647120907.945,1,7,18,100,104,7,kernel,0,"[6272, 1, 1]",74.666664,25
0,1.52381,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,"[32, 4, 1]",3.136,8704,6083647120955.113,1,7,40,3,127,7,kernel,0,"[2, 16, 1]",0.380952,30
0,74.666664,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,"[256, 1, 1]",144.192,49152,6083647120959.049,1,7,126,33,129,7,kernel,0,"[2, 28, 14]",9.333333,30
0,597.333313,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",46.016,0,6083647121104.137,1,7,16,100,137,7,kernel,0,"[12544, 1, 1]",149.333328,33
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.112,0,6083647121150.857,1,7,24,0,143,7,kernel,0,"[1, 1, 1]",0.011905,34
0,12.190476,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",64.705,144,6083647121153.736,1,7,40,25,195,7,kernel,0,"[64, 1, 1]",0.761905,37
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",46.271,0,6083647121265.929,1,7,18,100,215,7,kernel,0,"[6272, 1, 1]",74.666664,50
0,298.666656,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",44.417,0,6083647121313.0,1,7,26,100,234,7,kernel,0,"[3136, 1, 1]",37.333332,53
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",10.336,4224,6083647121358.216,1,7,38,100,252,7,kernel,0,"[392, 2, 1]",9.333333,57
0,24.380953,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.0,4224,6083647121369.352,1,7,38,51,254,7,kernel,0,"[1, 2, 128]",3.047619,57
0,4.666667,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize256x128x32_stage2_warpsize4x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[256, 1, 1]",62.336,98304,6083647121374.12,1,7,254,0,259,7,kernel,0,"[1, 49, 1]",0.583333,57
0,298.666656,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",17.568,0,6083647121437.608,1,7,16,100,268,7,kernel,0,"[6272, 1, 1]",74.666664,60
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.24,0,6083647121455.912,1,7,24,0,274,7,kernel,0,"[1, 1, 1]",0.011905,61
0,24.380953,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",22.048,144,6083647121458.952,1,7,40,51,326,7,kernel,0,"[128, 1, 1]",1.52381,64
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",23.552,0,6083647121505.8,1,7,18,100,346,7,kernel,0,"[3136, 1, 1]",37.333332,77
0,149.333328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",21.376,4224,6083647121530.152,1,7,38,100,368,7,kernel,0,"[392, 4, 1]",18.666666,82
0,48.761906,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.96,4224,6083647121552.712,1,7,38,100,370,7,kernel,0,"[1, 4, 128]",6.095238,82
0,9.333333,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",102.08,49152,6083647121560.872,1,7,230,17,374,7,kernel,0,"[1, 98, 2]",2.333333,82
0,298.666656,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",20.384,0,6083647121663.752,1,7,16,100,383,7,kernel,0,"[6272, 1, 1]",74.666664,85
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.304,0,6083647121684.936,1,7,24,0,389,7,kernel,0,"[1, 1, 1]",0.011905,86
0,24.380953,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",22.24,144,6083647121688.136,1,7,40,51,441,7,kernel,0,"[128, 1, 1]",1.52381,89
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",24.0,0,6083647121735.208,1,7,18,100,461,7,kernel,0,"[3136, 1, 1]",37.333332,102
0,149.333328,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",20.48,0,6083647121759.943,1,7,26,100,480,7,kernel,0,"[1568, 1, 1]",18.666666,105
0,37.333332,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.736,4224,6083647121781.16,1,7,38,78,498,7,kernel,0,"[98, 4, 1]",4.666667,109
0,97.523811,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.945,4224,6083647121786.663,1,7,38,100,500,7,kernel,0,"[1, 4, 256]",12.190476,109
0,2.380952,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",53.28,49152,6083647121794.343,1,7,230,5,503,7,kernel,0,"[2, 25, 1]",0.595238,109
0,149.333328,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",6.943,0,6083647121848.52,1,7,16,100,512,7,kernel,0,"[3136, 1, 1]",37.333332,112
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.983,0,6083647121856.264,1,7,24,0,518,7,kernel,0,"[1, 1, 1]",0.011905,113
0,48.761906,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",11.232,14480,6083647121859.143,1,7,40,100,571,7,kernel,0,"[256, 1, 1]",3.047619,116
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",6.657,0,6083647121880.775,1,7,18,100,592,7,kernel,0,"[1568, 1, 1]",18.666666,129
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.488,4224,6083647121888.263,1,7,38,100,614,7,kernel,0,"[98, 8, 1]",9.333333,134
0,195.047623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",11.072,4224,6083647121896.519,1,7,38,100,616,7,kernel,0,"[1, 8, 256]",24.380953,134
0,19.047619,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",83.967,49152,6083647121910.536,1,7,230,17,620,7,kernel,0,"[2, 25, 8]",4.761905,134
0,149.333328,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",7.296,0,6083647121995.367,1,7,16,100,629,7,kernel,0,"[3136, 1, 1]",37.333332,137
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.952,0,6083647122003.399,1,7,24,0,635,7,kernel,0,"[1, 1, 1]",0.011905,138
0,48.761906,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",10.56,14480,6083647122006.119,1,7,40,100,688,7,kernel,0,"[256, 1, 1]",3.047619,141
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",7.168,0,6083647122026.695,1,7,18,100,709,7,kernel,0,"[1568, 1, 1]",18.666666,154
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.464,4224,6083647122034.631,1,7,38,100,731,7,kernel,0,"[98, 8, 1]",9.333333,159
0,195.047623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",10.784,4224,6083647122041.895,1,7,38,100,733,7,kernel,0,"[1, 8, 256]",24.380953,159
0,19.047619,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",88.416,49152,6083647122056.007,1,7,230,17,737,7,kernel,0,"[2, 25, 8]",4.761905,159
0,149.333328,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",7.616,0,6083647122145.255,1,7,16,100,746,7,kernel,0,"[3136, 1, 1]",37.333332,162
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.92,0,6083647122153.735,1,7,24,0,752,7,kernel,0,"[1, 1, 1]",0.011905,163
0,48.761906,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",10.112,14480,6083647122156.423,1,7,40,100,805,7,kernel,0,"[256, 1, 1]",3.047619,166
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",6.944,0,6083647122176.583,1,7,18,100,826,7,kernel,0,"[1568, 1, 1]",18.666666,179
0,74.666664,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",6.688,0,6083647122184.423,1,7,26,100,845,7,kernel,0,"[784, 1, 1]",9.333333,182
0,19.047619,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.464,4224,6083647122191.847,1,7,38,40,863,7,kernel,0,"[25, 8, 1]",2.380952,186
0,390.095245,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",18.848,4224,6083647122195.111,1,7,38,100,865,7,kernel,0,"[1, 8, 512]",48.761906,186
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,"[128, 1, 1]",51.168,73728,6083647122214.695,1,7,162,0,869,7,kernel,0,"[28, 2, 1]",0.666667,186
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.392,4224,6083647122266.631,1,7,40,79,873,7,kernel,0,"[25, 16, 1]",4.761905,186
0,74.666664,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",4.512,0,6083647122270.855,1,7,16,100,881,7,kernel,0,"[1568, 1, 1]",18.666666,189
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.568,0,6083647122276.135,1,7,24,0,887,7,kernel,0,"[1, 1, 1]",0.011905,190
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.856,4240,6083647122278.503,1,7,40,100,940,7,kernel,0,"[512, 1, 1]",6.095238,193
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.431,0,6083647122292.423,1,7,18,78,961,7,kernel,0,"[784, 1, 1]",9.333333,206
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.976,4224,6083647122295.591,1,7,38,79,983,7,kernel,0,"[25, 16, 1]",4.761905,211
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.857,4224,6083647122299.366,1,7,38,100,985,7,kernel,0,"[1, 16, 512]",97.523811,211
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),0,"[128, 1, 1]",96.063,73728,6083647122333.959,1,7,168,0,989,7,kernel,0,"[28, 2, 1]",0.666667,211
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.424,4224,6083647122430.854,1,7,40,79,993,7,kernel,0,"[25, 16, 1]",4.761905,211
0,74.666664,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",4.096,0,6083647122435.11,1,7,16,100,1001,7,kernel,0,"[1568, 1, 1]",18.666666,214
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.601,0,6083647122440.07,1,7,24,0,1007,7,kernel,0,"[1, 1, 1]",0.011905,215
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.728,4240,6083647122442.47,1,7,40,100,1060,7,kernel,0,"[512, 1, 1]",6.095238,218
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.433,0,6083647122456.326,1,7,18,78,1081,7,kernel,0,"[784, 1, 1]",9.333333,231
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.976,4224,6083647122459.494,1,7,38,79,1103,7,kernel,0,"[25, 16, 1]",4.761905,236
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",34.016,4224,6083647122463.27,1,7,38,100,1105,7,kernel,0,"[1, 16, 512]",97.523811,236
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),0,"[128, 1, 1]",95.648,73728,6083647122498.054,1,7,168,0,1109,7,kernel,0,"[28, 2, 1]",0.666667,236
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.296,4224,6083647122594.47,1,7,40,79,1113,7,kernel,0,"[25, 16, 1]",4.761905,236
0,74.666664,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",4.192,0,6083647122598.566,1,7,16,100,1121,7,kernel,0,"[1568, 1, 1]",18.666666,239
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.536,0,6083647122603.526,1,7,24,0,1127,7,kernel,0,"[1, 1, 1]",0.011905,240
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.952,4240,6083647122605.894,1,7,40,100,1180,7,kernel,0,"[512, 1, 1]",6.095238,243
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.432,0,6083647122619.974,1,7,18,78,1201,7,kernel,0,"[784, 1, 1]",9.333333,256
0,37.333332,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",4.096,0,6083647122623.142,1,7,26,78,1220,7,kernel,0,"[392, 1, 1]",4.666667,259
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.176,4224,6083647122627.942,1,7,38,22,1238,7,kernel,0,"[7, 16, 1]",1.333333,263
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.856,4224,6083647122630.854,1,7,38,100,1240,7,kernel,0,"[1, 16, 512]",97.523811,263
0,3.047619,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",38.4,100352,6083647122667.27,1,7,198,0,1246,7,kernel,0,"[8, 2, 4]",0.761905,263
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.752,4224,6083647122706.406,1,7,40,22,1249,7,kernel,0,"[7, 16, 1]",1.333333,263
0,18.666666,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.944,0,6083647122710.054,1,7,16,39,1257,7,kernel,0,"[392, 1, 1]",4.666667,266
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.568,0,6083647122713.894,1,7,24,0,1263,7,kernel,0,"[1, 1, 1]",0.011905,267
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.793,2192,6083647127310.301,1,7,40,100,1316,7,kernel,0,"[512, 1, 1]",6.095238,270
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.728,0,6083647127323.901,1,7,18,19,1337,7,kernel,0,"[196, 1, 1]",2.333333,283
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.144,4224,6083647127326.397,1,7,38,22,1359,7,kernel,0,"[7, 16, 1]",1.333333,288
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.952,4224,6083647127329.405,1,7,38,100,1361,7,kernel,0,"[1, 16, 512]",97.523811,288
0,3.047619,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",38.56,100352,6083647127366.621,1,7,198,0,1367,7,kernel,0,"[8, 2, 4]",0.761905,288
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.88,4224,6083647127405.949,1,7,40,22,1370,7,kernel,0,"[7, 16, 1]",1.333333,288
0,18.666666,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.848,0,6083647127409.629,1,7,16,39,1378,7,kernel,0,"[392, 1, 1]",4.666667,291
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.568,0,6083647127413.277,1,7,24,0,1384,7,kernel,0,"[1, 1, 1]",0.011905,292
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",8.704,2192,6083647127415.645,1,7,40,100,1437,7,kernel,0,"[512, 1, 1]",6.095238,295
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.696,0,6083647127427.581,1,7,18,19,1458,7,kernel,0,"[196, 1, 1]",2.333333,308
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.112,4224,6083647127430.109,1,7,38,22,1480,7,kernel,0,"[7, 16, 1]",1.333333,313
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.184,4224,6083647127433.469,1,7,38,100,1482,7,kernel,0,"[1, 16, 512]",97.523811,313
0,3.047619,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",38.496,100352,6083647127469.981,1,7,198,0,1488,7,kernel,0,"[8, 2, 4]",0.761905,313
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.464,4224,6083647127509.629,1,7,40,22,1491,7,kernel,0,"[7, 16, 1]",1.333333,313
0,18.666666,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.88,0,6083647127512.861,1,7,16,39,1499,7,kernel,0,"[392, 1, 1]",4.666667,316
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.568,0,6083647127516.541,1,7,24,0,1505,7,kernel,0,"[1, 1, 1]",0.011905,317
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",8.672,2192,6083647127518.909,1,7,40,100,1558,7,kernel,0,"[512, 1, 1]",6.095238,320
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.664,0,6083647127531.005,1,7,18,19,1579,7,kernel,0,"[196, 1, 1]",2.333333,333
0,9.333333,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",2.72,0,6083647127533.533,1,7,26,19,1598,7,kernel,0,"[98, 1, 1]",1.166667,336
0,48.761906,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,"[32, 4, 1]",692.991,528,6083647127537.117,1,7,159,25,1617,7,kernel,0,"[1024, 1, 1]",12.190476,342
0,1.52381,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.368,0,6083647128230.94,1,7,47,3,1648,7,kernel,0,"[16, 1, 1]",0.190476,344
0,24.380953,X,"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, false, true, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>, float, float)",0,"[128, 1, 1]",115.807,2560,6083647128234.14,1,7,58,51,1667,7,kernel,0,"[512, 1, 1]",6.095238,353
0,1.52381,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.265,0,6083647128350.779,1,7,47,3,1698,7,kernel,0,"[16, 1, 1]",0.190476,355
0,11.904762,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,"[32, 4, 1]",30.336,528,6083647128354.875,1,7,159,25,1717,7,kernel,0,"[250, 1, 1]",2.976191,364
