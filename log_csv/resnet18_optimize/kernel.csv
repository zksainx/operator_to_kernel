shared memory,pid,dur,stream,ts,est. achieved occupancy %,tid,cat,warps per SM,grid,registers per thread,correlation,ph,name,device,External id,queued,blocks per SM,context,block
0,0,1.312,7,6928969541349.881,0,7,kernel,0.047619,"[1, 1, 1]",16,11766,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,2054,0,0.011905,1,"[128, 1, 1]"
0,0,1.984,7,6928969542043.16,2,7,kernel,0.952381,"[20, 1, 1]",16,11792,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,2574,0,0.238095,1,"[128, 1, 1]"
25600,0,7.52,7,6928969542144.92,5,7,kernel,2.285714,"[4, 1, 12]",80,11810,X,void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_nn_align1>(cutlass_80_simt_sgemm_128x32_8x5_nn_align1::Params),0,2570,0,0.571429,1,"[128, 1, 1]"
0,0,1.888,7,6928969542160.664,6,7,kernel,3.047619,"[16, 1, 1]",44,11811,X,"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*, float const*, float*, void*, long, float*, int*)",0,2570,0,0.190476,1,"[32, 16, 1]"
0,0,1.696,7,6928969542241.912,2,7,kernel,0.952381,"[20, 1, 1]",16,11829,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})",0,2582,0,0.238095,1,"[128, 1, 1]"
16384,0,4.608,7,6928969542279.416,25,7,kernel,12.190476,"[16, 8, 1]",57,11842,X,ampere_sgemm_32x128_nn,0,2578,0,1.52381,1,"[256, 1, 1]"
16,0,2.912,7,6928969542344.696,1,7,kernel,0.380952,"[2, 1, 1]",32,11855,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)",0,2586,0,0.02381,1,"[128, 4, 1]"
0,0,2.239,7,6928969542615.0,49,7,kernel,23.333334,"[490, 1, 1]",16,11885,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",0,2610,0,5.833333,1,"[128, 1, 1]"
0,0,2.015,7,6928969542683.0,24,7,kernel,11.666667,"[245, 1, 1]",22,11899,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2613,0,2.916667,1,"[128, 1, 1]"
4368,0,9.696,7,6928969542857.527,67,7,kernel,97.523811,"[512, 1, 1]",45,11947,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2618,0,6.095238,1,"[512, 1, 1]"
4224,0,33.408,7,6928969543049.239,100,7,kernel,780.190491,"[1, 16, 512]",38,11978,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2634,0,97.523811,1,"[256, 1, 1]"
4224,0,4.192,7,6928969543083.415,32,7,kernel,15.238095,"[2, 16, 5]",38,11980,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2634,0,1.904762,1,"[256, 1, 1]"
65536,0,43.872,7,6928969543104.983,0,7,kernel,3.047619,"[4, 2, 8]",250,11986,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,2634,0,0.761905,1,"[128, 1, 1]"
4224,0,2.688,7,6928969543149.655,32,7,kernel,15.238095,"[2, 16, 5]",40,11989,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2634,0,1.904762,1,"[256, 1, 1]"
4224,0,3.936,7,6928969543174.391,32,7,kernel,15.238095,"[2, 16, 5]",38,12009,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2634,0,1.904762,1,"[256, 1, 1]"
4224,0,3.744,7,6928969543183.671,32,7,kernel,15.238095,"[2, 16, 5]",38,12011,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2634,0,1.904762,1,"[256, 1, 1]"
49152,0,38.336,7,6928969543200.311,14,7,kernel,6.857143,"[36, 4, 1]",230,12014,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,2634,0,1.714286,1,"[128, 1, 1]"
4224,0,34.4,7,6928969543239.447,100,7,kernel,780.190491,"[1, 16, 512]",40,12017,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2634,0,97.523811,1,"[256, 1, 1]"
0,0,4.288,7,6928969543321.495,24,7,kernel,11.666667,"[245, 1, 1]",22,12037,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2643,0,2.916667,1,"[128, 1, 1]"
4368,0,11.232,7,6928969543450.198,67,7,kernel,97.523811,"[512, 1, 1]",45,12081,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2646,0,6.095238,1,"[512, 1, 1]"
4224,0,33.312,7,6928969543603.83,100,7,kernel,780.190491,"[1, 16, 512]",38,12112,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2662,0,97.523811,1,"[256, 1, 1]"
4224,0,4.224,7,6928969543637.974,32,7,kernel,15.238095,"[2, 16, 5]",38,12114,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2662,0,1.904762,1,"[256, 1, 1]"
65536,0,43.84,7,6928969543644.982,0,7,kernel,3.047619,"[4, 2, 8]",250,12120,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,2662,0,0.761905,1,"[128, 1, 1]"
4224,0,2.656,7,6928969543689.654,32,7,kernel,15.238095,"[2, 16, 5]",40,12123,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2662,0,1.904762,1,"[256, 1, 1]"
4224,0,4.032,7,6928969543706.102,32,7,kernel,15.238095,"[2, 16, 5]",38,12143,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2662,0,1.904762,1,"[256, 1, 1]"
4224,0,3.648,7,6928969543715.894,32,7,kernel,15.238095,"[2, 16, 5]",38,12145,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2662,0,1.904762,1,"[256, 1, 1]"
49152,0,37.44,7,6928969543727.99,14,7,kernel,6.857143,"[36, 4, 1]",230,12148,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,2662,0,1.714286,1,"[128, 1, 1]"
4224,0,34.4,7,6928969543766.294,100,7,kernel,780.190491,"[1, 16, 512]",40,12151,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2662,0,97.523811,1,"[256, 1, 1]"
0,0,4.448,7,6928969543801.718,24,7,kernel,11.666667,"[245, 1, 1]",22,12160,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,2665,0,2.916667,1,"[128, 1, 1]"
0,0,3.296,7,6928969543878.102,24,7,kernel,11.666667,"[245, 1, 1]",22,12180,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2672,0,2.916667,1,"[128, 1, 1]"
4368,0,11.296,7,6928969544019.03,67,7,kernel,97.523811,"[512, 1, 1]",45,12228,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2677,0,6.095238,1,"[512, 1, 1]"
4224,0,11.904,7,6928969544170.805,100,7,kernel,390.095245,"[1, 8, 512]",38,12259,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2693,0,48.761906,1,"[256, 1, 1]"
4224,0,2.112,7,6928969544183.445,32,7,kernel,15.238095,"[2, 16, 5]",38,12261,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2693,0,1.904762,1,"[256, 1, 1]"
81920,0,12.416,7,6928969544201.429,0,7,kernel,3.047619,"[16, 4, 1]",128,12265,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2693,0,0.761905,1,"[128, 1, 1]"
4224,0,2.56,7,6928969544214.581,56,7,kernel,26.666666,"[7, 8, 5]",40,12269,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2693,0,3.333333,1,"[256, 1, 1]"
4224,0,4.288,7,6928969544261.941,56,7,kernel,26.666666,"[7, 8, 5]",38,12289,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2693,0,3.333333,1,"[256, 1, 1]"
4224,0,2.144,7,6928969544271.125,32,7,kernel,15.238095,"[2, 16, 5]",38,12291,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2693,0,1.904762,1,"[256, 1, 1]"
73728,0,12.288,7,6928969544299.701,0,7,kernel,1.52381,"[16, 1, 2]",166,12296,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,2693,0,0.380952,1,"[128, 1, 1]"
4368,0,10.784,7,6928969544453.429,67,7,kernel,97.523811,"[512, 1, 1]",45,12348,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2702,0,6.095238,1,"[512, 1, 1]"
4224,0,33.536,7,6928969544598.709,100,7,kernel,780.190491,"[1, 16, 512]",38,12379,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2718,0,97.523811,1,"[256, 1, 1]"
4224,0,4.288,7,6928969544633.045,32,7,kernel,15.238095,"[2, 16, 5]",38,12381,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2718,0,1.904762,1,"[256, 1, 1]"
65536,0,43.615,7,6928969544639.861,0,7,kernel,3.047619,"[4, 2, 8]",250,12387,X,sm80_xmma_dgrad_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,2718,0,0.761905,1,"[128, 1, 1]"
4224,0,2.624,7,6928969544684.245,32,7,kernel,15.238095,"[2, 16, 5]",40,12390,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2718,0,1.904762,1,"[256, 1, 1]"
4224,0,4.096,7,6928969544695.541,32,7,kernel,15.238095,"[2, 16, 5]",38,12410,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2718,0,1.904762,1,"[256, 1, 1]"
4224,0,3.295,7,6928969544705.205,32,7,kernel,15.238095,"[2, 16, 5]",38,12412,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2718,0,1.904762,1,"[256, 1, 1]"
49152,0,37.856,7,6928969544717.365,14,7,kernel,6.857143,"[36, 4, 1]",230,12415,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,2718,0,1.714286,1,"[128, 1, 1]"
4224,0,34.304,7,6928969544755.956,100,7,kernel,780.190491,"[1, 16, 512]",40,12418,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2718,0,97.523811,1,"[256, 1, 1]"
0,0,4.352,7,6928969544827.188,24,7,kernel,11.666667,"[245, 1, 1]",22,12438,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2727,0,2.916667,1,"[128, 1, 1]"
4368,0,11.2,7,6928969544946.804,67,7,kernel,97.523811,"[512, 1, 1]",45,12482,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2730,0,6.095238,1,"[512, 1, 1]"
4224,0,17.888,7,6928969545093.62,100,7,kernel,390.095245,"[1, 8, 512]",38,12513,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2746,0,48.761906,1,"[256, 1, 1]"
4224,0,3.936,7,6928969545112.34,32,7,kernel,15.238095,"[2, 16, 5]",38,12515,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2746,0,1.904762,1,"[256, 1, 1]"
81920,0,29.056,7,6928969545119.476,0,7,kernel,3.047619,"[16, 4, 1]",128,12519,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2746,0,0.761905,1,"[128, 1, 1]"
4224,0,2.656,7,6928969545149.236,56,7,kernel,26.666666,"[7, 8, 5]",40,12523,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2746,0,3.333333,1,"[256, 1, 1]"
4224,0,5.248,7,6928969545176.596,56,7,kernel,26.666666,"[7, 8, 5]",38,12543,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2746,0,3.333333,1,"[256, 1, 1]"
4224,0,3.84,7,6928969545185.396,32,7,kernel,15.238095,"[2, 16, 5]",38,12545,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2746,0,1.904762,1,"[256, 1, 1]"
81920,0,23.136,7,6928969545202.516,0,7,kernel,3.428571,"[8, 9, 1]",234,12549,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_256x64_16x4_nhwc_align4::Params),0,2746,0,0.857143,1,"[128, 1, 1]"
4224,0,14.656,7,6928969545226.452,100,7,kernel,390.095245,"[1, 8, 512]",40,12553,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2746,0,48.761906,1,"[256, 1, 1]"
0,0,7.136,7,6928969545259.732,49,7,kernel,23.333334,"[490, 1, 1]",22,12562,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,2749,0,5.833333,1,"[128, 1, 1]"
0,0,5.025,7,6928969545348.051,49,7,kernel,23.333334,"[490, 1, 1]",22,12582,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2756,0,5.833333,1,"[128, 1, 1]"
8464,0,8.352,7,6928969545485.843,67,7,kernel,48.761906,"[256, 1, 1]",45,12630,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2761,0,3.047619,1,"[512, 1, 1]"
4224,0,9.696,7,6928969545654.163,100,7,kernel,195.047623,"[1, 8, 256]",38,12661,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2777,0,24.380953,1,"[256, 1, 1]"
4224,0,4.064,7,6928969545665.235,56,7,kernel,26.666666,"[7, 8, 5]",38,12663,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2777,0,3.333333,1,"[256, 1, 1]"
81920,0,32.384,7,6928969545680.211,0,7,kernel,3.047619,"[16, 4, 1]",128,12667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2777,0,0.761905,1,"[128, 1, 1]"
4224,0,2.688,7,6928969545713.299,56,7,kernel,26.666666,"[7, 8, 5]",40,12671,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2777,0,3.333333,1,"[256, 1, 1]"
4224,0,4.384,7,6928969545737.715,56,7,kernel,26.666666,"[7, 8, 5]",38,12691,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2777,0,3.333333,1,"[256, 1, 1]"
4224,0,4.352,7,6928969545747.795,56,7,kernel,26.666666,"[7, 8, 5]",38,12693,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2777,0,3.333333,1,"[256, 1, 1]"
73728,0,36.864,7,6928969545760.243,0,7,kernel,3.809524,"[16, 5, 1]",166,12697,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,2777,0,0.952381,1,"[128, 1, 1]"
4224,0,6.72,7,6928969545797.843,100,7,kernel,195.047623,"[1, 8, 256]",40,12701,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2777,0,24.380953,1,"[256, 1, 1]"
0,0,6.688,7,6928969545866.899,49,7,kernel,23.333334,"[490, 1, 1]",22,12721,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2786,0,5.833333,1,"[128, 1, 1]"
8464,0,9.28,7,6928969545985.907,67,7,kernel,48.761906,"[256, 1, 1]",45,12765,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2789,0,3.047619,1,"[512, 1, 1]"
4224,0,9.632,7,6928969546127.859,100,7,kernel,195.047623,"[1, 8, 256]",38,12796,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2805,0,24.380953,1,"[256, 1, 1]"
4224,0,3.68,7,6928969546138.899,56,7,kernel,26.666666,"[7, 8, 5]",38,12798,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2805,0,3.333333,1,"[256, 1, 1]"
81920,0,32.351,7,6928969546152.019,0,7,kernel,3.047619,"[16, 4, 1]",128,12802,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2805,0,0.761905,1,"[128, 1, 1]"
4224,0,2.719,7,6928969546185.107,56,7,kernel,26.666666,"[7, 8, 5]",40,12806,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2805,0,3.333333,1,"[256, 1, 1]"
4224,0,5.152,7,6928969546206.739,56,7,kernel,26.666666,"[7, 8, 5]",38,12826,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2805,0,3.333333,1,"[256, 1, 1]"
4224,0,5.217,7,6928969546215.442,56,7,kernel,26.666666,"[7, 8, 5]",38,12828,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2805,0,3.333333,1,"[256, 1, 1]"
73728,0,36.513,7,6928969546227.378,0,7,kernel,3.809524,"[16, 5, 1]",166,12832,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,2805,0,0.952381,1,"[128, 1, 1]"
4224,0,6.753,7,6928969546264.594,100,7,kernel,195.047623,"[1, 8, 256]",40,12836,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2805,0,24.380953,1,"[256, 1, 1]"
0,0,6.848,7,6928969546281.843,49,7,kernel,23.333334,"[490, 1, 1]",22,12845,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,2808,0,5.833333,1,"[128, 1, 1]"
0,0,5.152,7,6928969546365.266,49,7,kernel,23.333334,"[490, 1, 1]",22,12865,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2815,0,5.833333,1,"[128, 1, 1]"
8464,0,8.416,7,6928969546501.33,67,7,kernel,48.761906,"[256, 1, 1]",45,12913,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2820,0,3.047619,1,"[512, 1, 1]"
4224,0,4.512,7,6928969546643.506,100,7,kernel,97.523811,"[1, 4, 256]",38,12944,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2836,0,12.190476,1,"[256, 1, 1]"
4224,0,2.56,7,6928969546653.458,56,7,kernel,26.666666,"[7, 8, 5]",38,12946,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2836,0,3.333333,1,"[256, 1, 1]"
81920,0,9.536,7,6928969546668.562,0,7,kernel,6.095238,"[64, 2, 1]",128,12950,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2836,0,1.52381,1,"[128, 1, 1]"
4224,0,2.976,7,6928969546679.794,99,7,kernel,47.619049,"[25, 4, 5]",40,12954,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2836,0,5.952381,1,"[256, 1, 1]"
10496,0,39.84,7,6928969546750.002,2,7,kernel,0.952381,"[2, 1, 5]",123,12975,X,"void wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",0,2836,0,0.119048,1,"[8, 32, 1]"
8464,0,10.336,7,6928969546902.417,67,7,kernel,48.761906,"[256, 1, 1]",45,13025,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2845,0,3.047619,1,"[512, 1, 1]"
4224,0,9.76,7,6928969547042.545,100,7,kernel,195.047623,"[1, 8, 256]",38,13056,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2861,0,24.380953,1,"[256, 1, 1]"
4224,0,3.84,7,6928969547053.041,56,7,kernel,26.666666,"[7, 8, 5]",38,13058,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2861,0,3.333333,1,"[256, 1, 1]"
81920,0,32.127,7,6928969547065.106,0,7,kernel,3.047619,"[16, 4, 1]",128,13062,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2861,0,0.761905,1,"[128, 1, 1]"
4224,0,2.72,7,6928969547098.033,56,7,kernel,26.666666,"[7, 8, 5]",40,13066,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2861,0,3.333333,1,"[256, 1, 1]"
4224,0,4.768,7,6928969547122.449,56,7,kernel,26.666666,"[7, 8, 5]",38,13086,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2861,0,3.333333,1,"[256, 1, 1]"
4224,0,4.96,7,6928969547132.049,56,7,kernel,26.666666,"[7, 8, 5]",38,13088,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2861,0,3.333333,1,"[256, 1, 1]"
73728,0,37.056,7,6928969547143.793,0,7,kernel,3.809524,"[16, 5, 1]",166,13092,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4>(cutlass_tensorop_s1688wgrad_optimized_tf32_64x128_32x3_nhwc_align4::Params),0,2861,0,0.952381,1,"[128, 1, 1]"
4224,0,6.752,7,6928969547181.585,100,7,kernel,195.047623,"[1, 8, 256]",40,13096,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2861,0,24.380953,1,"[256, 1, 1]"
0,0,6.88,7,6928969547250.001,49,7,kernel,23.333334,"[490, 1, 1]",22,13116,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2870,0,5.833333,1,"[128, 1, 1]"
8464,0,8.992,7,6928969547364.177,67,7,kernel,48.761906,"[256, 1, 1]",45,13160,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2873,0,3.047619,1,"[512, 1, 1]"
4224,0,6.08,7,6928969547506.897,100,7,kernel,97.523811,"[1, 4, 256]",38,13191,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2889,0,12.190476,1,"[256, 1, 1]"
4224,0,2.528,7,6928969547517.489,56,7,kernel,26.666666,"[7, 8, 5]",38,13193,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2889,0,3.333333,1,"[256, 1, 1]"
81920,0,22.752,7,6928969547531.121,0,7,kernel,6.095238,"[64, 2, 1]",128,13197,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,2889,0,1.52381,1,"[128, 1, 1]"
4224,0,3.008,7,6928969547554.641,99,7,kernel,47.619049,"[25, 4, 5]",40,13201,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2889,0,5.952381,1,"[256, 1, 1]"
4224,0,7.968,7,6928969547587.025,99,7,kernel,47.619049,"[25, 4, 5]",38,13221,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2889,0,5.952381,1,"[256, 1, 1]"
4224,0,5.056,7,6928969547596.657,56,7,kernel,26.666666,"[7, 8, 5]",38,13223,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2889,0,3.333333,1,"[256, 1, 1]"
81920,0,23.423,7,6928969547615.057,0,7,kernel,3.809524,"[16, 5, 1]",96,13227,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi64ELi64ELi32EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi64ELi32EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi64ELi32EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi32ELi64EEESC_SI_SK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESI_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi32ELi32ELi32EEESC_SQ_SC_SZ_fNSO_8RowMajorENS13_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S16_SC_NSO_11ColumnMajorEfS16_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1G_Li1EEELi5EbEENS_8epilogue11threadblock8EpilogueIS8_S1F_Li1ENS1K_22PredicatedTileIteratorINS1K_26OutputTileOptimalThreadMapINS1K_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1O_ILi1ELi4ELi1ELi1ELi4EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1J_4warp24FragmentIteratorTensorOpIS15_S19_fNS_5ArrayIfLi4ELb1EEES16_EENS1U_20TileIteratorTensorOpIS15_S19_fS16_EENS1K_18SharedLoadIteratorINS1R_18CompactedThreadMapEfLi16EEENS1J_6thread17LinearCombinationIfLi4EffLNS24_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS11_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,2889,0,0.952381,1,"[128, 1, 1]"
0,0,2.175,7,6928969547639.665,57,7,kernel,27.428572,"[64, 9, 1]",36,13230,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,2889,0,6.857143,1,"[32, 4, 1]"
4224,0,4.256,7,6928969547642.673,100,7,kernel,97.523811,"[1, 4, 256]",40,13234,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2889,0,12.190476,1,"[256, 1, 1]"
0,0,11.521,7,6928969547683.536,97,7,kernel,46.666668,"[980, 1, 1]",22,13243,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,2892,0,11.666667,1,"[128, 1, 1]"
0,0,7.264,7,6928969547769.648,97,7,kernel,46.666668,"[980, 1, 1]",22,13263,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2899,0,11.666667,1,"[128, 1, 1]"
33040,0,9.184,7,6928969547903.504,51,7,kernel,24.380953,"[128, 1, 1]",45,13311,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2904,0,1.52381,1,"[512, 1, 1]"
4224,0,4.256,7,6928969548047.248,100,7,kernel,48.761906,"[1, 4, 128]",38,13342,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2920,0,6.095238,1,"[256, 1, 1]"
4224,0,3.328,7,6928969548057.072,99,7,kernel,47.619049,"[25, 4, 5]",38,13344,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2920,0,5.952381,1,"[256, 1, 1]"
73728,0,27.136,7,6928969548074.064,0,7,kernel,2.952381,"[62, 1, 1]",161,13348,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,2920,0,0.738095,1,"[128, 1, 1]"
4224,0,2.816,7,6928969548101.936,99,7,kernel,47.619049,"[25, 4, 5]",40,13352,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2920,0,5.952381,1,"[256, 1, 1]"
4224,0,8.096,7,6928969548132.304,99,7,kernel,47.619049,"[25, 4, 5]",38,13372,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2920,0,5.952381,1,"[256, 1, 1]"
4224,0,8.192,7,6928969548142.0,99,7,kernel,47.619049,"[25, 4, 5]",38,13374,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2920,0,5.952381,1,"[256, 1, 1]"
73728,0,33.216,7,6928969548172.688,0,7,kernel,3.809524,"[4, 5, 4]",148,13379,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi16EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi16ELi64EEESC_NSE_INSF_ILi64ELi16EEELi128ESH_Li4EEESK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESY_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SQ_SC_S11_fNSO_8RowMajorENS15_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S18_SC_NSO_11ColumnMajorEfS18_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1I_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1H_Li1ENS1M_22PredicatedTileIteratorINS1M_26OutputTileOptimalThreadMapINS1M_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1Q_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1L_4warp24FragmentIteratorTensorOpIS17_S1B_fNS_5ArrayIfLi4ELb1EEES18_EENS1W_20TileIteratorTensorOpIS17_S1B_fS18_EENS1M_18SharedLoadIteratorINS1T_18CompactedThreadMapEfLi16EEENS1L_6thread17LinearCombinationIfLi4EffLNS26_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS13_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,2920,0,0.952381,1,"[128, 1, 1]"
0,0,2.784,7,6928969548206.704,29,7,kernel,13.714286,"[32, 9, 1]",36,13382,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,2920,0,3.428571,1,"[32, 4, 1]"
4224,0,3.136,7,6928969548210.224,100,7,kernel,48.761906,"[1, 4, 128]",40,13386,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2920,0,6.095238,1,"[256, 1, 1]"
0,0,11.552,7,6928969548291.536,97,7,kernel,46.666668,"[980, 1, 1]",22,13406,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2929,0,11.666667,1,"[128, 1, 1]"
33040,0,9.344,7,6928969548407.247,51,7,kernel,24.380953,"[128, 1, 1]",45,13450,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2932,0,1.52381,1,"[512, 1, 1]"
4224,0,4.192,7,6928969548549.327,100,7,kernel,48.761906,"[1, 4, 128]",38,13481,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2948,0,6.095238,1,"[256, 1, 1]"
4224,0,3.264,7,6928969548558.927,99,7,kernel,47.619049,"[25, 4, 5]",38,13483,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2948,0,5.952381,1,"[256, 1, 1]"
73728,0,26.72,7,6928969548573.103,0,7,kernel,2.952381,"[62, 1, 1]",161,13487,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,2948,0,0.738095,1,"[128, 1, 1]"
4224,0,2.848,7,6928969548600.655,99,7,kernel,47.619049,"[25, 4, 5]",40,13491,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2948,0,5.952381,1,"[256, 1, 1]"
4224,0,8.224,7,6928969548629.167,99,7,kernel,47.619049,"[25, 4, 5]",38,13511,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2948,0,5.952381,1,"[256, 1, 1]"
4224,0,8.48,7,6928969548638.127,99,7,kernel,47.619049,"[25, 4, 5]",38,13513,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2948,0,5.952381,1,"[256, 1, 1]"
73728,0,32.992,7,6928969548663.311,0,7,kernel,3.809524,"[4, 5, 4]",148,13518,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi16EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi16ELi64EEESC_NSE_INSF_ILi64ELi16EEELi128ESH_Li4EEESK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESY_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SQ_SC_S11_fNSO_8RowMajorENS15_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S18_SC_NSO_11ColumnMajorEfS18_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1I_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1H_Li1ENS1M_22PredicatedTileIteratorINS1M_26OutputTileOptimalThreadMapINS1M_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1Q_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1L_4warp24FragmentIteratorTensorOpIS17_S1B_fNS_5ArrayIfLi4ELb1EEES18_EENS1W_20TileIteratorTensorOpIS17_S1B_fS18_EENS1M_18SharedLoadIteratorINS1T_18CompactedThreadMapEfLi16EEENS1L_6thread17LinearCombinationIfLi4EffLNS26_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS13_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,2948,0,0.952381,1,"[128, 1, 1]"
0,0,2.784,7,6928969548697.135,29,7,kernel,13.714286,"[32, 9, 1]",36,13521,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,2948,0,3.428571,1,"[32, 4, 1]"
4224,0,3.104,7,6928969548700.687,100,7,kernel,48.761906,"[1, 4, 128]",40,13525,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,2948,0,6.095238,1,"[256, 1, 1]"
0,0,11.776,7,6928969548729.263,97,7,kernel,46.666668,"[980, 1, 1]",22,13534,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,2951,0,11.666667,1,"[128, 1, 1]"
0,0,7.552,7,6928969548816.399,97,7,kernel,46.666668,"[980, 1, 1]",22,13554,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,2958,0,11.666667,1,"[128, 1, 1]"
33040,0,9.088,7,6928969548952.047,51,7,kernel,24.380953,"[128, 1, 1]",45,13602,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2963,0,1.52381,1,"[512, 1, 1]"
0,0,7.167,7,6928969549098.159,100,7,kernel,373.333344,"[3920, 1, 1]",24,13633,X,"void cudnn::engines_precompiled::scalePackedTensor_kernel<float, float>(long, float*, float)",0,2979,0,46.666668,1,"[256, 1, 1]"
3328,0,16.991,7,6928969549112.271,6,7,kernel,2.976191,"[1, 25, 5]",96,13635,X,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)",0,2979,0,1.488095,1,"[8, 8, 1]"
4224,0,14.592,7,6928969549160.718,100,7,kernel,93.333336,"[98, 2, 5]",38,13655,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2979,0,11.666667,1,"[256, 1, 1]"
4224,0,8.512,7,6928969549176.142,99,7,kernel,47.619049,"[25, 4, 5]",38,13657,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,2979,0,5.952381,1,"[256, 1, 1]"
2048,0,14.336,7,6928969549198.798,20,7,kernel,9.523809,"[1, 8, 25]",108,13661,X,sm80_xmma_wgrad_implicit_gemm_indexed_wo_smem_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize16x64x64_stage1_warpsize1x4x1_g1_tensor16x8x8_aligna8_alignc8_execute_kernel__5x_cudnn,0,2979,0,2.380952,1,"[128, 1, 1]"
33040,0,12.64,7,6928969549352.11,51,7,kernel,24.380953,"[128, 1, 1]",45,13712,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,2988,0,1.52381,1,"[512, 1, 1]"
4224,0,4.32,7,6928969549491.662,100,7,kernel,48.761906,"[1, 4, 128]",38,13743,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3004,0,6.095238,1,"[256, 1, 1]"
4224,0,3.04,7,6928969549501.806,99,7,kernel,47.619049,"[25, 4, 5]",38,13745,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3004,0,5.952381,1,"[256, 1, 1]"
73728,0,27.168,7,6928969549515.758,0,7,kernel,2.952381,"[62, 1, 1]",161,13749,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_unity_stride_align4::Params),0,3004,0,0.738095,1,"[128, 1, 1]"
4224,0,3.008,7,6928969549543.758,99,7,kernel,47.619049,"[25, 4, 5]",40,13753,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3004,0,5.952381,1,"[256, 1, 1]"
4224,0,8.384,7,6928969549611.95,99,7,kernel,47.619049,"[25, 4, 5]",38,13773,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3004,0,5.952381,1,"[256, 1, 1]"
4224,0,8.512,7,6928969549622.062,99,7,kernel,47.619049,"[25, 4, 5]",38,13775,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3004,0,5.952381,1,"[256, 1, 1]"
73728,0,33.087,7,6928969549647.022,0,7,kernel,3.809524,"[4, 5, 4]",148,13780,X,_ZN17cutlass__5x_cudnn6KernelINS_4conv6kernel23ImplicitGemmConvolutionINS1_11threadblock22ImplicitGemmMultistageINS_4gemm9GemmShapeILi128ELi64ELi16EEENS4_52Conv2dWgradOutputGradientTileAccessIteratorOptimizedINS_11MatrixShapeILi128ELi16EEENS_10tfloat32_tENS_9transform29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi16EEELi128ENSF_ILi8ELi4EEELi4EEENS_12AlignedArrayISC_Li4ELi16EEEEENSD_11threadblock25RegularTileAccessIteratorISB_SC_NS_6layout40ColumnMajorTensorOpMultiplicandCongruousILi32ELi32EEELi1ESI_Li16EEELNS_4arch14CacheOperation4KindE0ENS4_48Conv2dWgradActivationTileAccessIteratorOptimizedINSA_ILi16ELi64EEESC_NSE_INSF_ILi64ELi16EEELi128ESH_Li4EEESK_EENSN_ISW_SC_NSO_37RowMajorTensorOpMultiplicandCongruousILi32ELi32EEELi0ESY_Li16EEELSU_0ENS6_11threadblock9MmaPolicyINS6_4warp11MmaTensorOpINS7_ILi64ELi32ELi16EEESC_SQ_SC_S11_fNSO_8RowMajorENS15_17MmaTensorOpPolicyINSS_3MmaINS7_ILi16ELi8ELi8EEELi32ESC_S18_SC_NSO_11ColumnMajorEfS18_NSS_13OpMultiplyAddEEENSA_ILi1ELi1EEEEELi1ELb0EbEENSA_ILi0ELi0EEES1I_Li1EEELi6EbEENS_8epilogue11threadblock8EpilogueIS8_S1H_Li1ENS1M_22PredicatedTileIteratorINS1M_26OutputTileOptimalThreadMapINS1M_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1Q_ILi1ELi8ELi1ELi1ELi8EEELi128ELi4ELi32EEEfLb0ENSO_9NoPermuteELb0EEENS1L_4warp24FragmentIteratorTensorOpIS17_S1B_fNS_5ArrayIfLi4ELb1EEES18_EENS1W_20TileIteratorTensorOpIS17_S1B_fS18_EENS1M_18SharedLoadIteratorINS1T_18CompactedThreadMapEfLi16EEENS1L_6thread17LinearCombinationIfLi4EffLNS26_9ScaleType4KindE0ELNS_15FloatRoundStyleE2EEENSA_ILi0ELi8EEELi2ELi1EEENS13_30GemmIdentityThreadblockSwizzleILi4EEELNS1_8OperatorE2ENS1_17Conv2dProblemSizeELNS1_9GroupModeE0EEEEEvNT_6ParamsE,0,3004,0,0.952381,1,"[128, 1, 1]"
0,0,2.751,7,6928969549680.974,29,7,kernel,13.714286,"[32, 9, 1]",36,13783,X,"void cutlass__5x_cudnn::Kernel<cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass__5x_cudnn::reduction::kernel::ReduceSplitK<cutlass__5x_cudnn::MatrixShape<4, 128>, cutlass__5x_cudnn::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass__5x_cudnn::epilogue::thread::ScaleType::Kind)0, (cutlass__5x_cudnn::FloatRoundStyle)2>, cutlass__5x_cudnn::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)",0,3004,0,3.428571,1,"[32, 4, 1]"
4224,0,2.911,7,6928969549684.462,100,7,kernel,48.761906,"[1, 4, 128]",40,13787,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3004,0,6.095238,1,"[256, 1, 1]"
0,0,11.809,7,6928969549779.373,97,7,kernel,46.666668,"[980, 1, 1]",22,13807,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,3013,0,11.666667,1,"[128, 1, 1]"
33040,0,9.472,7,6928969549900.333,51,7,kernel,24.380953,"[128, 1, 1]",45,13851,X,"void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_bw_1C11_args<float>)",0,3016,0,1.52381,1,"[512, 1, 1]"
4224,0,3.424,7,6928969550044.941,51,7,kernel,24.380953,"[1, 2, 128]",38,13882,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3032,0,3.047619,1,"[256, 1, 1]"
4224,0,3.328,7,6928969550054.669,99,7,kernel,47.619049,"[25, 4, 5]",38,13884,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3032,0,5.952381,1,"[256, 1, 1]"
73728,0,26.656,7,6928969550073.741,0,7,kernel,5.904762,"[124, 1, 1]",180,13888,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688dgrad_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,3032,0,1.47619,1,"[128, 1, 1]"
4224,0,9.216,7,6928969550101.229,100,7,kernel,93.333336,"[98, 2, 5]",40,13892,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3032,0,11.666667,1,"[256, 1, 1]"
4224,0,16.704,7,6928969550133.293,100,7,kernel,93.333336,"[98, 2, 5]",38,13912,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3032,0,11.666667,1,"[256, 1, 1]"
4224,0,8.64,7,6928969550150.733,99,7,kernel,47.619049,"[25, 4, 5]",38,13914,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3032,0,5.952381,1,"[256, 1, 1]"
98304,0,31.744,7,6928969550179.661,0,7,kernel,2.571429,"[9, 2, 3]",128,13922,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,3032,0,0.642857,1,"[128, 1, 1]"
4224,0,2.336,7,6928969550212.173,51,7,kernel,24.380953,"[1, 2, 128]",40,13925,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3032,0,3.047619,1,"[256, 1, 1]"
0,0,21.312,7,6928969550237.357,100,7,kernel,93.333336,"[1960, 1, 1]",22,13934,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,3035,0,23.333334,1,"[128, 1, 1]"
0,0,16.128,7,6928969550320.941,100,7,kernel,93.333336,"[1960, 1, 1]",22,13954,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,3042,0,23.333334,1,"[128, 1, 1]"
400,0,35.968,7,6928969550446.733,25,7,kernel,12.190476,"[64, 1, 1]",40,14001,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,3047,0,0.761905,1,"[512, 1, 1]"
8704,0,2.625,7,6928969550581.484,3,7,kernel,1.52381,"[2, 16, 1]",40,14032,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,3063,0,0.380952,1,"[32, 4, 1]"
49152,0,55.808,7,6928969550592.652,33,7,kernel,26.666666,"[10, 7, 4]",126,14034,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,3063,0,3.333333,1,"[256, 1, 1]"
4224,0,14.112,7,6928969550649.164,100,7,kernel,93.333336,"[98, 2, 5]",38,14054,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3063,0,11.666667,1,"[256, 1, 1]"
4224,0,16.128,7,6928969550663.98,100,7,kernel,93.333336,"[98, 2, 5]",38,14056,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3063,0,11.666667,1,"[256, 1, 1]"
98304,0,49.088,7,6928969550685.612,0,7,kernel,3.0,"[9, 1, 7]",128,14064,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,3063,0,0.75,1,"[128, 1, 1]"
4224,0,2.656,7,6928969550735.468,25,7,kernel,12.190476,"[1, 2, 64]",40,14067,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3063,0,1.52381,1,"[256, 1, 1]"
0,0,19.2,7,6928969550777.804,100,7,kernel,93.333336,"[1960, 1, 1]",22,14087,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,3072,0,23.333334,1,"[128, 1, 1]"
400,0,35.744,7,6928969550903.116,25,7,kernel,12.190476,"[64, 1, 1]",40,14130,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,3075,0,0.761905,1,"[512, 1, 1]"
8704,0,2.592,7,6928969551034.252,3,7,kernel,1.52381,"[2, 16, 1]",40,14161,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,3091,0,0.380952,1,"[32, 4, 1]"
49152,0,55.455,7,6928969551043.404,33,7,kernel,26.666666,"[10, 7, 4]",126,14163,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,3091,0,3.333333,1,"[256, 1, 1]"
4224,0,14.017,7,6928969551099.723,100,7,kernel,93.333336,"[98, 2, 5]",38,14183,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3091,0,11.666667,1,"[256, 1, 1]"
4224,0,15.999,7,6928969551114.54,100,7,kernel,93.333336,"[98, 2, 5]",38,14185,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3091,0,11.666667,1,"[256, 1, 1]"
98304,0,49.344,7,6928969551137.484,0,7,kernel,3.0,"[9, 1, 7]",128,14193,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,3091,0,0.75,1,"[128, 1, 1]"
4224,0,2.624,7,6928969551187.532,25,7,kernel,12.190476,"[1, 2, 64]",40,14196,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3091,0,1.52381,1,"[256, 1, 1]"
0,0,19.008,7,6928969551190.988,100,7,kernel,93.333336,"[1960, 1, 1]",22,14205,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,3094,0,23.333334,1,"[128, 1, 1]"
0,0,15.808,7,6928969551257.803,100,7,kernel,93.333336,"[1960, 1, 1]",22,14225,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,3101,0,23.333334,1,"[128, 1, 1]"
400,0,35.36,7,6928969551378.347,25,7,kernel,12.190476,"[64, 1, 1]",40,14272,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,3106,0,0.761905,1,"[512, 1, 1]"
8704,0,2.656,7,6928969551508.011,3,7,kernel,1.52381,"[2, 16, 1]",40,14303,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,3122,0,0.380952,1,"[32, 4, 1]"
49152,0,55.52,7,6928969551517.579,33,7,kernel,26.666666,"[10, 7, 4]",126,14305,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,3122,0,3.333333,1,"[256, 1, 1]"
4224,0,14.144,7,6928969551573.835,100,7,kernel,93.333336,"[98, 2, 5]",38,14325,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3122,0,11.666667,1,"[256, 1, 1]"
4224,0,16.64,7,6928969551588.747,100,7,kernel,93.333336,"[98, 2, 5]",38,14327,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3122,0,11.666667,1,"[256, 1, 1]"
98304,0,49.344,7,6928969551611.755,0,7,kernel,3.0,"[9, 1, 7]",128,14335,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,3122,0,0.75,1,"[128, 1, 1]"
4224,0,2.688,7,6928969551661.899,25,7,kernel,12.190476,"[1, 2, 64]",40,14338,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3122,0,1.52381,1,"[256, 1, 1]"
0,0,19.168,7,6928969551697.003,100,7,kernel,93.333336,"[1960, 1, 1]",22,14358,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,3131,0,23.333334,1,"[128, 1, 1]"
400,0,35.583,7,6928969551800.587,25,7,kernel,12.190476,"[64, 1, 1]",40,14401,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 128, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,3134,0,0.761905,1,"[512, 1, 1]"
8704,0,2.624,7,6928969551927.914,3,7,kernel,1.52381,"[2, 16, 1]",40,14432,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,3150,0,0.380952,1,"[32, 4, 1]"
49152,0,55.68,7,6928969551937.835,33,7,kernel,26.666666,"[10, 7, 4]",126,14434,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,3150,0,3.333333,1,"[256, 1, 1]"
4224,0,14.271,7,6928969551994.347,100,7,kernel,93.333336,"[98, 2, 5]",38,14454,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3150,0,11.666667,1,"[256, 1, 1]"
4224,0,16.096,7,6928969552009.418,100,7,kernel,93.333336,"[98, 2, 5]",38,14456,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,3150,0,11.666667,1,"[256, 1, 1]"
98304,0,49.184,7,6928969552031.21,0,7,kernel,3.0,"[9, 1, 7]",128,14464,X,sm86_xmma_wgrad_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,3150,0,0.75,1,"[128, 1, 1]"
4224,0,2.656,7,6928969552081.13,25,7,kernel,12.190476,"[1, 2, 64]",40,14467,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,3150,0,1.52381,1,"[256, 1, 1]"
0,0,19.168,7,6928969552084.49,100,7,kernel,93.333336,"[1960, 1, 1]",22,14476,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,3153,0,23.333334,1,"[128, 1, 1]"
0,0,28.512,7,6928969552166.538,100,7,kernel,373.333344,"[7840, 1, 1]",16,14498,X,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",0,3162,0,93.333336,1,"[128, 1, 1]"
0,0,96.864,7,6928969552195.818,100,7,kernel,1493.333374,"[49, 5, 64]",40,14507,X,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(float const*, long const*, int, long, long, long, int, int, int, int, int, int, int, int, int, int, float*)",0,3160,0,186.666672,1,"[256, 1, 1]"
0,0,85.024,7,6928969552293.386,100,7,kernel,373.333344,"[7840, 1, 1]",22,14521,X,"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::(anonymous namespace)::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}>, at::detail::Array<char*, 3>)",0,3165,0,93.333336,1,"[128, 1, 1]"
400,0,149.856,7,6928969552379.146,25,7,kernel,12.190476,"[64, 1, 1]",40,14564,X,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)",0,3168,0,0.761905,1,"[512, 1, 1]"
2304,0,142.559,7,6928969552532.49,50,7,kernel,29.761906,"[5, 2, 125]",80,14598,X,"void wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)",0,3184,0,14.880953,1,"[8, 8, 1]"
0,0,254.368,7,6928969587300.12,90,7,kernel,43.238094,"[227, 1, 1]",40,14612,X,"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)",0,2056,0,2.702381,1,"[512, 1, 1]"
