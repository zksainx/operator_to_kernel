shared memory,pid,dur,stream,ts,est. achieved occupancy %,tid,cat,warps per SM,grid,registers per thread,correlation,ph,name,device,External id,queued,blocks per SM,context,block
0,0,1.792,7,6928969211848.816,10,7,kernel,4.761905,"[50, 1, 1]",16,19,X,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",0,5,0,0.595238,1,"[256, 1, 1]"
16384,0,81.76,7,6928969211882.032,33,7,kernel,23.333334,"[490, 1, 1]",128,22,X,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,0,5,0,5.833333,1,"[128, 1, 1]"
0,0,1.824,7,6928969212151.791,0,7,kernel,0.047619,"[1, 1, 1]",24,30,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,6,0,0.011905,1,"[128, 1, 1]"
144,0,87.872,7,6928969212688.303,25,7,kernel,12.190476,"[64, 1, 1]",40,86,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,9,0,0.761905,1,"[512, 1, 1]"
0,0,57.536,7,6928969212858.382,100,7,kernel,373.333344,"[7840, 1, 1]",18,93,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,18,0,93.333336,1,"[128, 1, 1]"
0,0,54.176,7,6928969213230.99,100,7,kernel,373.333344,"[3920, 1, 1]",26,114,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,20,0,46.666668,1,"[256, 1, 1]"
4224,0,13.44,7,6928969213482.893,100,7,kernel,93.333336,"[98, 2, 5]",38,132,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,24,0,11.666667,1,"[256, 1, 1]"
4224,0,3.104,7,6928969213497.325,25,7,kernel,12.190476,"[1, 2, 64]",38,134,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,24,0,1.52381,1,"[256, 1, 1]"
98304,0,42.591,7,6928969213544.398,0,7,kernel,5.857143,"[1, 123, 1]",228,139,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,24,0,1.464286,1,"[128, 1, 1]"
0,0,1.824,7,6928969213677.549,0,7,kernel,0.047619,"[1, 1, 1]",24,148,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,25,0,0.011905,1,"[128, 1, 1]"
144,0,15.168,7,6928969213864.397,25,7,kernel,12.190476,"[64, 1, 1]",40,200,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,28,0,0.761905,1,"[512, 1, 1]"
0,0,4.159,7,6928969213940.077,100,7,kernel,93.333336,"[1960, 1, 1]",18,207,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,37,0,23.333334,1,"[128, 1, 1]"
4224,0,8.416,7,6928969214266.7,100,7,kernel,93.333336,"[98, 2, 5]",38,231,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,41,0,11.666667,1,"[256, 1, 1]"
4224,0,3.232,7,6928969214280.204,25,7,kernel,12.190476,"[1, 2, 64]",38,233,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,41,0,1.52381,1,"[256, 1, 1]"
98304,0,40.096,7,6928969214306.604,0,7,kernel,5.857143,"[1, 123, 1]",228,238,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,41,0,1.464286,1,"[128, 1, 1]"
0,0,1.792,7,6928969214440.396,0,7,kernel,0.047619,"[1, 1, 1]",24,247,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,42,0,0.011905,1,"[128, 1, 1]"
144,0,14.495,7,6928969214628.908,25,7,kernel,12.190476,"[64, 1, 1]",40,299,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,45,0,0.761905,1,"[512, 1, 1]"
0,0,14.816,7,6928969214677.676,100,7,kernel,93.333336,"[1960, 1, 1]",22,305,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,53,0,23.333334,1,"[128, 1, 1]"
0,0,4.032,7,6928969214736.14,100,7,kernel,93.333336,"[1960, 1, 1]",18,312,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,55,0,23.333334,1,"[128, 1, 1]"
4224,0,8.608,7,6928969214879.083,100,7,kernel,93.333336,"[98, 2, 5]",38,332,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,59,0,11.666667,1,"[256, 1, 1]"
4224,0,3.104,7,6928969214891.083,25,7,kernel,12.190476,"[1, 2, 64]",38,334,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,59,0,1.52381,1,"[256, 1, 1]"
98304,0,40.48,7,6928969214913.547,0,7,kernel,5.857143,"[1, 123, 1]",228,339,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,59,0,1.464286,1,"[128, 1, 1]"
0,0,1.76,7,6928969214997.259,0,7,kernel,0.047619,"[1, 1, 1]",24,348,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,60,0,0.011905,1,"[128, 1, 1]"
144,0,15.168,7,6928969215153.227,25,7,kernel,12.190476,"[64, 1, 1]",40,400,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,63,0,0.761905,1,"[512, 1, 1]"
0,0,4.064,7,6928969215225.451,100,7,kernel,93.333336,"[1960, 1, 1]",18,407,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,72,0,23.333334,1,"[128, 1, 1]"
4224,0,8.128,7,6928969215351.306,100,7,kernel,93.333336,"[98, 2, 5]",38,427,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,76,0,11.666667,1,"[256, 1, 1]"
4224,0,3.103,7,6928969215362.379,25,7,kernel,12.190476,"[1, 2, 64]",38,429,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,76,0,1.52381,1,"[256, 1, 1]"
98304,0,41.056,7,6928969215383.818,0,7,kernel,5.857143,"[1, 123, 1]",228,434,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,76,0,1.464286,1,"[128, 1, 1]"
0,0,1.759,7,6928969215461.803,0,7,kernel,0.047619,"[1, 1, 1]",24,443,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,77,0,0.011905,1,"[128, 1, 1]"
144,0,14.688,7,6928969215615.466,25,7,kernel,12.190476,"[64, 1, 1]",40,495,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 128, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,80,0,0.761905,1,"[512, 1, 1]"
0,0,14.624,7,6928969215653.45,100,7,kernel,93.333336,"[1960, 1, 1]",22,501,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,88,0,23.333334,1,"[128, 1, 1]"
0,0,4.064,7,6928969215703.306,100,7,kernel,93.333336,"[1960, 1, 1]",18,508,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,90,0,23.333334,1,"[128, 1, 1]"
4224,0,8.576,7,6928969216059.689,100,7,kernel,93.333336,"[98, 2, 5]",38,532,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,94,0,11.666667,1,"[256, 1, 1]"
4224,0,4.352,7,6928969216071.177,51,7,kernel,24.380953,"[1, 2, 128]",38,534,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,94,0,3.047619,1,"[256, 1, 1]"
73728,0,17.248,7,6928969216092.649,0,7,kernel,2.952381,"[62, 1, 1]",162,538,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,94,0,0.738095,1,"[128, 1, 1]"
4224,0,3.36,7,6928969216110.665,99,7,kernel,47.619049,"[25, 4, 5]",40,542,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,94,0,5.952381,1,"[256, 1, 1]"
0,0,1.728,7,6928969216231.081,0,7,kernel,0.047619,"[1, 1, 1]",24,550,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,95,0,0.011905,1,"[128, 1, 1]"
16528,0,6.304,7,6928969216414.025,51,7,kernel,24.380953,"[128, 1, 1]",40,603,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,98,0,1.52381,1,"[512, 1, 1]"
0,0,2.56,7,6928969216483.017,97,7,kernel,46.666668,"[980, 1, 1]",18,611,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,107,0,11.666667,1,"[128, 1, 1]"
4224,0,2.911,7,6928969216624.233,99,7,kernel,47.619049,"[25, 4, 5]",38,631,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,111,0,5.952381,1,"[256, 1, 1]"
4224,0,4.448,7,6928969216633.641,100,7,kernel,48.761906,"[1, 4, 128]",38,633,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,111,0,6.095238,1,"[256, 1, 1]"
65536,0,51.776,7,6928969216663.656,0,7,kernel,1.47619,"[1, 31, 1]",232,638,X,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,111,0,0.369048,1,"[128, 1, 1]"
0,0,1.567,7,6928969216748.265,0,7,kernel,0.047619,"[1, 1, 1]",24,647,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,112,0,0.011905,1,"[128, 1, 1]"
16528,0,6.048,7,6928969216907.432,51,7,kernel,24.380953,"[128, 1, 1]",40,700,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,115,0,1.52381,1,"[512, 1, 1]"
0,0,1.664,7,6928969217059.848,1,7,kernel,0.380952,"[4, 1, 1]",16,719,X,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",0,126,0,0.047619,1,"[256, 1, 1]"
16384,0,14.624,7,6928969217079.88,6,7,kernel,2.952381,"[31, 2, 1]",128,722,X,_5x_cudnn_ampere_scudnn_128x64_relu_interior_nn_v1,0,126,0,0.738095,1,"[128, 1, 1]"
0,0,1.407,7,6928969217158.248,0,7,kernel,0.047619,"[1, 1, 1]",24,730,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,127,0,0.011905,1,"[128, 1, 1]"
16528,0,6.015,7,6928969217310.152,51,7,kernel,24.380953,"[128, 1, 1]",40,783,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,130,0,1.52381,1,"[512, 1, 1]"
0,0,7.2,7,6928969217351.303,97,7,kernel,46.666668,"[980, 1, 1]",22,790,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,138,0,11.666667,1,"[128, 1, 1]"
0,0,2.784,7,6928969217410.055,97,7,kernel,46.666668,"[980, 1, 1]",18,797,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,140,0,11.666667,1,"[128, 1, 1]"
4224,0,3.232,7,6928969217588.039,99,7,kernel,47.619049,"[25, 4, 5]",38,817,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,144,0,5.952381,1,"[256, 1, 1]"
4224,0,4.48,7,6928969217599.207,100,7,kernel,48.761906,"[1, 4, 128]",38,819,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,144,0,6.095238,1,"[256, 1, 1]"
65536,0,51.008,7,6928969217625.575,0,7,kernel,1.47619,"[1, 31, 1]",232,824,X,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,144,0,0.369048,1,"[128, 1, 1]"
0,0,1.536,7,6928969217714.759,0,7,kernel,0.047619,"[1, 1, 1]",24,833,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,145,0,0.011905,1,"[128, 1, 1]"
16528,0,6.112,7,6928969217885.799,51,7,kernel,24.380953,"[128, 1, 1]",40,886,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,148,0,1.52381,1,"[512, 1, 1]"
0,0,2.56,7,6928969217948.135,97,7,kernel,46.666668,"[980, 1, 1]",18,894,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,157,0,11.666667,1,"[128, 1, 1]"
4224,0,3.04,7,6928969218078.118,99,7,kernel,47.619049,"[25, 4, 5]",38,914,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,161,0,5.952381,1,"[256, 1, 1]"
4224,0,4.416,7,6928969218090.15,100,7,kernel,48.761906,"[1, 4, 128]",38,916,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,161,0,6.095238,1,"[256, 1, 1]"
65536,0,50.592,7,6928969218113.51,0,7,kernel,1.47619,"[1, 31, 1]",232,921,X,sm80_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,161,0,0.369048,1,"[128, 1, 1]"
0,0,1.44,7,6928969218192.422,0,7,kernel,0.047619,"[1, 1, 1]",24,930,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,162,0,0.011905,1,"[128, 1, 1]"
16528,0,6.176,7,6928969218342.95,51,7,kernel,24.380953,"[128, 1, 1]",40,983,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,165,0,1.52381,1,"[512, 1, 1]"
0,0,5.504,7,6928969218380.486,97,7,kernel,46.666668,"[980, 1, 1]",22,990,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,173,0,11.666667,1,"[128, 1, 1]"
0,0,2.592,7,6928969218437.19,97,7,kernel,46.666668,"[980, 1, 1]",18,997,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,175,0,11.666667,1,"[128, 1, 1]"
4224,0,3.456,7,6928969218775.877,99,7,kernel,47.619049,"[25, 4, 5]",38,1021,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,179,0,5.952381,1,"[256, 1, 1]"
4224,0,6.432,7,6928969218786.565,100,7,kernel,97.523811,"[1, 4, 256]",38,1023,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,179,0,12.190476,1,"[256, 1, 1]"
81920,0,17.408,7,6928969218806.565,0,7,kernel,3.047619,"[64, 1, 1]",118,1027,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,179,0,0.761905,1,"[128, 1, 1]"
4224,0,3.072,7,6928969218824.677,56,7,kernel,26.666666,"[7, 8, 5]",40,1031,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,179,0,3.333333,1,"[256, 1, 1]"
0,0,1.536,7,6928969218944.357,0,7,kernel,0.047619,"[1, 1, 1]",24,1039,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,180,0,0.011905,1,"[128, 1, 1]"
4240,0,6.592,7,6928969219129.093,100,7,kernel,48.761906,"[256, 1, 1]",40,1092,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,183,0,3.047619,1,"[512, 1, 1]"
0,0,2.176,7,6928969219196.005,49,7,kernel,23.333334,"[490, 1, 1]",18,1100,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,192,0,5.833333,1,"[128, 1, 1]"
4224,0,2.464,7,6928969219520.964,56,7,kernel,26.666666,"[7, 8, 5]",38,1124,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,196,0,3.333333,1,"[256, 1, 1]"
4224,0,10.304,7,6928969219530.372,100,7,kernel,195.047623,"[1, 8, 256]",38,1126,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,196,0,24.380953,1,"[256, 1, 1]"
81920,0,27.072,7,6928969219548.164,0,7,kernel,3.047619,"[64, 1, 1]",118,1130,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,196,0,0.761905,1,"[128, 1, 1]"
4224,0,2.944,7,6928969219576.132,56,7,kernel,26.666666,"[7, 8, 5]",40,1134,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,196,0,3.333333,1,"[256, 1, 1]"
0,0,1.44,7,6928969219675.14,0,7,kernel,0.047619,"[1, 1, 1]",24,1142,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,197,0,0.011905,1,"[128, 1, 1]"
4240,0,6.719,7,6928969219852.036,100,7,kernel,48.761906,"[256, 1, 1]",40,1195,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,200,0,3.047619,1,"[512, 1, 1]"
2304,0,15.552,7,6928969220185.667,12,7,kernel,5.904762,"[31, 8, 1]",63,1218,X,"void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, false, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, bool, int, int)",0,211,0,2.952381,1,"[8, 8, 1]"
0,0,1.504,7,6928969220291.427,0,7,kernel,0.047619,"[1, 1, 1]",24,1226,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,212,0,0.011905,1,"[128, 1, 1]"
4240,0,6.56,7,6928969220485.539,100,7,kernel,48.761906,"[256, 1, 1]",40,1279,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,215,0,3.047619,1,"[512, 1, 1]"
0,0,2.401,7,6928969220530.562,49,7,kernel,23.333334,"[490, 1, 1]",22,1286,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,223,0,5.833333,1,"[128, 1, 1]"
0,0,2.049,7,6928969220587.394,49,7,kernel,23.333334,"[490, 1, 1]",18,1293,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,225,0,5.833333,1,"[128, 1, 1]"
4224,0,2.528,7,6928969220722.018,56,7,kernel,26.666666,"[7, 8, 5]",38,1313,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,229,0,3.333333,1,"[256, 1, 1]"
4224,0,10.144,7,6928969220730.818,100,7,kernel,195.047623,"[1, 8, 256]",38,1315,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,229,0,24.380953,1,"[256, 1, 1]"
81920,0,27.168,7,6928969220748.322,0,7,kernel,3.047619,"[64, 1, 1]",118,1319,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,229,0,0.761905,1,"[128, 1, 1]"
4224,0,2.656,7,6928969220776.322,56,7,kernel,26.666666,"[7, 8, 5]",40,1323,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,229,0,3.333333,1,"[256, 1, 1]"
0,0,1.44,7,6928969220837.698,0,7,kernel,0.047619,"[1, 1, 1]",24,1331,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,230,0,0.011905,1,"[128, 1, 1]"
4240,0,6.752,7,6928969221199.074,100,7,kernel,48.761906,"[256, 1, 1]",40,1388,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,233,0,3.047619,1,"[512, 1, 1]"
0,0,2.175,7,6928969221291.874,49,7,kernel,23.333334,"[490, 1, 1]",18,1396,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,242,0,5.833333,1,"[128, 1, 1]"
4224,0,2.528,7,6928969221447.041,56,7,kernel,26.666666,"[7, 8, 5]",38,1416,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,246,0,3.333333,1,"[256, 1, 1]"
4224,0,10.08,7,6928969221456.417,100,7,kernel,195.047623,"[1, 8, 256]",38,1418,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,246,0,24.380953,1,"[256, 1, 1]"
81920,0,26.848,7,6928969221472.289,0,7,kernel,3.047619,"[64, 1, 1]",118,1422,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_64x64_32x5_nhwc_align4::Params),0,246,0,0.761905,1,"[128, 1, 1]"
4224,0,2.592,7,6928969221500.001,56,7,kernel,26.666666,"[7, 8, 5]",40,1426,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,246,0,3.333333,1,"[256, 1, 1]"
0,0,1.568,7,6928969221577.569,0,7,kernel,0.047619,"[1, 1, 1]",24,1434,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,247,0,0.011905,1,"[128, 1, 1]"
4240,0,6.656,7,6928969221933.249,100,7,kernel,48.761906,"[256, 1, 1]",40,1491,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,250,0,3.047619,1,"[512, 1, 1]"
0,0,3.84,7,6928969221992.097,49,7,kernel,23.333334,"[490, 1, 1]",22,1498,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,258,0,5.833333,1,"[128, 1, 1]"
0,0,2.112,7,6928969222067.616,49,7,kernel,23.333334,"[490, 1, 1]",18,1505,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,260,0,5.833333,1,"[128, 1, 1]"
4224,0,2.496,7,6928969222236.16,56,7,kernel,26.666666,"[7, 8, 5]",38,1525,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,264,0,3.333333,1,"[256, 1, 1]"
4224,0,17.984,7,6928969222244.928,100,7,kernel,390.095245,"[1, 8, 512]",38,1527,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,264,0,48.761906,1,"[256, 1, 1]"
99328,0,34.944,7,6928969222292.64,0,7,kernel,6.095238,"[16, 4, 2]",122,1533,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize64x32x64_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,264,0,1.52381,1,"[128, 1, 1]"
0,0,1.856,7,6928969222383.392,0,7,kernel,0.047619,"[1, 1, 1]",24,1542,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,265,0,0.011905,1,"[128, 1, 1]"
2192,0,8.831,7,6928969222548.192,100,7,kernel,97.523811,"[512, 1, 1]",40,1595,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,268,0,6.095238,1,"[512, 1, 1]"
0,0,1.663,7,6928969222610.624,24,7,kernel,11.666667,"[245, 1, 1]",18,1603,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,277,0,2.916667,1,"[128, 1, 1]"
4224,0,2.144,7,6928969222740.767,32,7,kernel,15.238095,"[2, 16, 5]",38,1623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,281,0,1.904762,1,"[256, 1, 1]"
4224,0,33.44,7,6928969222750.623,100,7,kernel,780.190491,"[1, 16, 512]",38,1625,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,281,0,97.523811,1,"[256, 1, 1]"
100352,0,54.016,7,6928969222791.167,0,7,kernel,1.52381,"[8, 2, 2]",198,1631,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,281,0,0.380952,1,"[128, 1, 1]"
4224,0,2.624,7,6928969222846.047,32,7,kernel,15.238095,"[2, 16, 5]",40,1634,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,281,0,1.904762,1,"[256, 1, 1]"
0,0,1.792,7,6928969222887.935,0,7,kernel,0.047619,"[1, 1, 1]",24,1642,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,282,0,0.011905,1,"[128, 1, 1]"
2192,0,8.447,7,6928969223279.423,100,7,kernel,97.523811,"[512, 1, 1]",40,1699,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,285,0,6.095238,1,"[512, 1, 1]"
4224,0,4.128,7,6928969223505.598,56,7,kernel,26.666666,"[7, 8, 5]",38,1718,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,296,0,3.333333,1,"[256, 1, 1]"
4224,0,11.712,7,6928969223518.046,100,7,kernel,390.095245,"[1, 8, 512]",38,1720,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,296,0,48.761906,1,"[256, 1, 1]"
98304,0,8.192,7,6928969223554.526,0,7,kernel,1.52381,"[8, 4, 1]",148,1725,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,296,0,0.380952,1,"[128, 1, 1]"
4224,0,2.112,7,6928969223571.006,32,7,kernel,15.238095,"[2, 16, 5]",40,1728,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,296,0,1.904762,1,"[256, 1, 1]"
0,0,1.472,7,6928969223673.374,0,7,kernel,0.047619,"[1, 1, 1]",24,1736,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,297,0,0.011905,1,"[128, 1, 1]"
2192,0,8.544,7,6928969223863.421,100,7,kernel,97.523811,"[512, 1, 1]",40,1789,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,300,0,6.095238,1,"[512, 1, 1]"
0,0,2.112,7,6928969223912.221,24,7,kernel,11.666667,"[245, 1, 1]",22,1796,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,308,0,2.916667,1,"[128, 1, 1]"
0,0,1.696,7,6928969223974.141,24,7,kernel,11.666667,"[245, 1, 1]",18,1803,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,310,0,2.916667,1,"[128, 1, 1]"
4224,0,2.176,7,6928969224130.237,32,7,kernel,15.238095,"[2, 16, 5]",38,1823,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,314,0,1.904762,1,"[256, 1, 1]"
4224,0,33.856,7,6928969224141.373,100,7,kernel,780.190491,"[1, 16, 512]",38,1825,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,314,0,97.523811,1,"[256, 1, 1]"
100352,0,53.472,7,6928969224185.021,0,7,kernel,1.52381,"[8, 2, 2]",198,1831,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,314,0,0.380952,1,"[128, 1, 1]"
4224,0,2.624,7,6928969224239.325,32,7,kernel,15.238095,"[2, 16, 5]",40,1834,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,314,0,1.904762,1,"[256, 1, 1]"
0,0,1.792,7,6928969224283.933,0,7,kernel,0.047619,"[1, 1, 1]",24,1842,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,315,0,0.011905,1,"[128, 1, 1]"
2192,0,8.607,7,6928969224469.437,100,7,kernel,97.523811,"[512, 1, 1]",40,1895,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,318,0,6.095238,1,"[512, 1, 1]"
0,0,1.665,7,6928969224534.076,24,7,kernel,11.666667,"[245, 1, 1]",18,1903,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,327,0,2.916667,1,"[128, 1, 1]"
4224,0,2.144,7,6928969224891.196,32,7,kernel,15.238095,"[2, 16, 5]",38,1927,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,331,0,1.904762,1,"[256, 1, 1]"
4224,0,32.832,7,6928969224903.324,100,7,kernel,780.190491,"[1, 16, 512]",38,1929,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,331,0,97.523811,1,"[256, 1, 1]"
100352,0,53.024,7,6928969224942.812,0,7,kernel,1.52381,"[8, 2, 2]",198,1935,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,331,0,0.380952,1,"[128, 1, 1]"
4224,0,2.528,7,6928969224996.668,32,7,kernel,15.238095,"[2, 16, 5]",40,1938,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,331,0,1.904762,1,"[256, 1, 1]"
0,0,1.824,7,6928969225078.364,0,7,kernel,0.047619,"[1, 1, 1]",24,1946,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,332,0,0.011905,1,"[128, 1, 1]"
2192,0,8.447,7,6928969225285.564,100,7,kernel,97.523811,"[512, 1, 1]",40,1999,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,335,0,6.095238,1,"[512, 1, 1]"
0,0,2.304,7,6928969225336.379,24,7,kernel,11.666667,"[245, 1, 1]",22,2006,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)",0,343,0,2.916667,1,"[128, 1, 1]"
0,0,1.664,7,6928969225398.491,24,7,kernel,11.666667,"[245, 1, 1]",18,2013,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,345,0,2.916667,1,"[128, 1, 1]"
16,0,4.032,7,6928969225653.211,63,7,kernel,30.476191,"[160, 1, 1]",32,2029,X,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)",0,347,0,1.904762,1,"[32, 16, 1]"
10752,0,9.12,7,6928969225970.426,12,7,kernel,5.952381,"[125, 1, 1]",56,2048,X,"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 6, 7, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,354,0,1.488095,1,"[128, 1, 1]"
