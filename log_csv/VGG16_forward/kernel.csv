ph,shared memory,grid,correlation,block,blocks per SM,stream,name,context,queued,cat,pid,est. achieved occupancy %,registers per thread,ts,External id,dur,device,tid,warps per SM
X,0,"[197, 1, 1]",25849,"[256, 1, 1]",2.345238,7,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",1,0,kernel,0,39,16,6784356001453.298,3589,2.112,0,7,18.761906
X,16384,"[392, 1, 1]",25852,"[128, 1, 1]",4.666667,7,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,1,0,kernel,0,33,128,6784356001456.21,3589,39.68,0,7,18.666666
X,0,"[12544, 1, 1]",25860,"[128, 1, 1]",149.333328,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356001496.722,3592,45.92,0,7,597.333313
X,0,"[1, 1, 1]",25866,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356001543.474,3593,1.952,0,7,0.047619
X,144,"[64, 1, 1]",25922,"[512, 1, 1]",0.761905,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,25,40,6784356001546.226,3596,64.191,0,7,12.190476
X,0,"[6272, 1, 1]",25946,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356001658.065,3609,45.952,0,7,298.666656
X,8704,"[2, 16, 1]",25973,"[32, 4, 1]",0.380952,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",1,0,kernel,0,3,40,6784356001704.785,3614,2.912,0,7,1.52381
X,49152,"[2, 28, 14]",25975,"[256, 1, 1]",9.333333,7,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,1,0,kernel,0,33,126,6784356001708.433,3614,142.463,0,7,74.666664
X,0,"[12544, 1, 1]",25983,"[128, 1, 1]",149.333328,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356001851.633,3617,45.471,0,7,597.333313
X,0,"[1, 1, 1]",25989,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356001897.872,3618,1.984,0,7,0.047619
X,144,"[64, 1, 1]",26045,"[512, 1, 1]",0.761905,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,25,40,6784356004241.415,3621,70.879,0,7,12.190476
X,0,"[6272, 1, 1]",26069,"[128, 1, 1]",74.666664,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356004360.454,3634,46.272,0,7,298.666656
X,0,"[3136, 1, 1]",26088,"[256, 1, 1]",37.333332,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,100,26,6784356004407.494,3637,43.776,0,7,298.666656
X,4224,"[392, 2, 1]",26110,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356004451.974,3641,10.176,0,7,74.666664
X,4224,"[1, 2, 128]",26112,"[256, 1, 1]",3.047619,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,51,38,6784356004462.886,3641,3.616,0,7,24.380953
X,98304,"[1, 49, 1]",26117,"[256, 1, 1]",0.583333,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize256x128x32_stage2_warpsize4x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,0,254,6784356004474.054,3641,60.383,0,7,4.666667
X,0,"[6272, 1, 1]",26126,"[128, 1, 1]",74.666664,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356004535.301,3644,17.248,0,7,298.666656
X,0,"[1, 1, 1]",26132,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356004553.381,3645,1.984,0,7,0.047619
X,144,"[128, 1, 1]",26184,"[512, 1, 1]",1.52381,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,51,40,6784356004556.133,3648,21.888,0,7,24.380953
X,0,"[3136, 1, 1]",26204,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356004602.661,3661,23.296,0,7,149.333328
X,4224,"[392, 4, 1]",26230,"[256, 1, 1]",18.666666,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356004626.693,3666,21.056,0,7,149.333328
X,4224,"[1, 4, 128]",26232,"[256, 1, 1]",6.095238,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356004649.221,3666,4.832,0,7,48.761906
X,49152,"[1, 98, 2]",26236,"[128, 1, 1]",2.333333,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,17,230,6784356004656.517,3666,97.663,0,7,9.333333
X,0,"[6272, 1, 1]",26245,"[128, 1, 1]",74.666664,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356004754.948,3669,20.033,0,7,298.666656
X,0,"[1, 1, 1]",26251,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356004775.781,3670,2.047,0,7,0.047619
X,144,"[128, 1, 1]",26303,"[512, 1, 1]",1.52381,7,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",1,0,kernel,0,51,40,6784356004778.532,3673,21.44,0,7,24.380953
X,0,"[3136, 1, 1]",26323,"[128, 1, 1]",37.333332,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356004824.548,3686,23.264,0,7,149.333328
X,0,"[1568, 1, 1]",26346,"[256, 1, 1]",18.666666,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,100,26,6784356004848.58,3689,20.224,0,7,149.333328
X,4224,"[98, 4, 1]",26364,"[256, 1, 1]",4.666667,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,78,38,6784356007204.699,3693,6.527,0,7,37.333332
X,4224,"[1, 4, 256]",26366,"[256, 1, 1]",12.190476,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007211.898,3693,6.816,0,7,97.523811
X,49152,"[2, 25, 1]",26369,"[128, 1, 1]",0.595238,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,5,230,6784356007219.962,3693,52.288,0,7,2.380952
X,0,"[3136, 1, 1]",26378,"[128, 1, 1]",37.333332,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356007273.082,3696,6.144,0,7,149.333328
X,0,"[1, 1, 1]",26384,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356007280.058,3697,1.696,0,7,0.047619
X,14480,"[256, 1, 1]",26437,"[512, 1, 1]",3.047619,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356007282.458,3700,10.08,0,7,48.761906
X,0,"[1568, 1, 1]",26458,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356007302.65,3713,5.984,0,7,74.666664
X,4224,"[98, 8, 1]",26484,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007309.338,3718,6.272,0,7,74.666664
X,4224,"[1, 8, 256]",26486,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007316.346,3718,10.816,0,7,195.047623
X,49152,"[2, 25, 8]",26490,"[128, 1, 1]",4.761905,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,17,230,6784356007333.274,3718,79.872,0,7,19.047619
X,0,"[3136, 1, 1]",26499,"[128, 1, 1]",37.333332,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356007413.913,3721,7.2,0,7,149.333328
X,0,"[1, 1, 1]",26505,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356007421.817,3722,1.952,0,7,0.047619
X,14480,"[256, 1, 1]",26558,"[512, 1, 1]",3.047619,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356007424.506,3725,9.152,0,7,48.761906
X,0,"[1568, 1, 1]",26579,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356007443.545,3738,6.496,0,7,74.666664
X,4224,"[98, 8, 1]",26601,"[256, 1, 1]",9.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007450.873,3743,6.784,0,7,74.666664
X,4224,"[1, 8, 256]",26603,"[256, 1, 1]",24.380953,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007458.457,3743,10.72,0,7,195.047623
X,49152,"[2, 25, 8]",26607,"[128, 1, 1]",4.761905,7,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,1,0,kernel,0,17,230,6784356007473.401,3743,80.672,0,7,19.047619
X,0,"[3136, 1, 1]",26616,"[128, 1, 1]",37.333332,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356007554.905,3746,6.848,0,7,149.333328
X,0,"[1, 1, 1]",26622,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356007562.489,3747,1.792,0,7,0.047619
X,14480,"[256, 1, 1]",26675,"[512, 1, 1]",3.047619,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356007565.049,3750,10.624,0,7,48.761906
X,0,"[1568, 1, 1]",26696,"[128, 1, 1]",18.666666,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,100,18,6784356007585.817,3763,6.688,0,7,74.666664
X,0,"[784, 1, 1]",26715,"[256, 1, 1]",9.333333,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,100,26,6784356007593.305,3766,6.464,0,7,74.666664
X,4224,"[25, 8, 1]",26733,"[256, 1, 1]",2.380952,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,40,38,6784356007600.537,3770,2.304,0,7,19.047619
X,4224,"[1, 8, 512]",26735,"[256, 1, 1]",48.761906,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007603.544,3770,18.433,0,7,390.095245
X,73728,"[28, 2, 1]",26739,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),1,0,kernel,0,0,162,6784356007622.713,3770,49.375,0,7,2.666667
X,4224,"[25, 16, 1]",26743,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6784356007672.792,3770,3.392,0,7,38.095238
X,0,"[1568, 1, 1]",26751,"[128, 1, 1]",18.666666,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356007676.921,3773,4.256,0,7,74.666664
X,0,"[1, 1, 1]",26757,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356007681.944,3774,1.504,0,7,0.047619
X,4240,"[512, 1, 1]",26810,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356007684.216,3777,9.504,0,7,97.523811
X,0,"[784, 1, 1]",26831,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,78,18,6784356007697.528,3790,2.368,0,7,37.333332
X,4224,"[25, 16, 1]",26857,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784356007700.568,3795,3.041,0,7,38.095238
X,4224,"[1, 16, 512]",26859,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356007705.016,3795,33.728,0,7,780.190491
X,73728,"[28, 2, 1]",26863,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),1,0,kernel,0,0,168,6784356007739.512,3795,92.256,0,7,2.666667
X,4224,"[25, 16, 1]",26867,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6784356007833.72,3795,3.168,0,7,38.095238
X,0,"[1568, 1, 1]",26875,"[128, 1, 1]",18.666666,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356007837.72,3798,3.968,0,7,74.666664
X,0,"[1, 1, 1]",26881,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356007842.488,3799,1.472,0,7,0.047619
X,4240,"[512, 1, 1]",26934,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356010239.438,3802,12.384,0,7,97.523811
X,0,"[784, 1, 1]",26955,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,78,18,6784356010256.398,3815,2.4,0,7,37.333332
X,4224,"[25, 16, 1]",26977,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,79,38,6784356010259.502,3820,3.424,0,7,38.095238
X,4224,"[1, 16, 512]",26979,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356010263.662,3820,34.144,0,7,780.190491
X,73728,"[28, 2, 1]",26983,"[128, 1, 1]",0.666667,7,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),1,0,kernel,0,0,168,6784356010298.574,3820,92.543,0,7,2.666667
X,4224,"[25, 16, 1]",26987,"[256, 1, 1]",4.761905,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,79,40,6784356010392.173,3820,3.296,0,7,38.095238
X,0,"[1568, 1, 1]",26995,"[128, 1, 1]",18.666666,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,100,16,6784356010396.173,3823,4.224,0,7,74.666664
X,0,"[1, 1, 1]",27001,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356010401.101,3824,1.536,0,7,0.047619
X,4240,"[512, 1, 1]",27054,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356010403.341,3827,9.536,0,7,97.523811
X,0,"[784, 1, 1]",27075,"[128, 1, 1]",9.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,78,18,6784356010416.909,3840,2.304,0,7,37.333332
X,0,"[392, 1, 1]",27094,"[256, 1, 1]",4.666667,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,78,26,6784356010419.949,3843,3.936,0,7,37.333332
X,4224,"[7, 16, 1]",27112,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784356010424.845,3847,2.112,0,7,10.666667
X,4224,"[1, 16, 512]",27114,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356010427.693,3847,33.728,0,7,780.190491
X,100352,"[8, 2, 4]",27120,"[128, 1, 1]",0.761905,7,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,198,6784356010465.101,3847,37.472,0,7,3.047619
X,4224,"[7, 16, 1]",27123,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6784356010503.341,3847,2.592,0,7,10.666667
X,0,"[392, 1, 1]",27131,"[128, 1, 1]",4.666667,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,39,16,6784356010506.765,3850,2.688,0,7,18.666666
X,0,"[1, 1, 1]",27137,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356010510.285,3851,1.472,0,7,0.047619
X,2192,"[512, 1, 1]",27190,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356010512.525,3854,8.448,0,7,97.523811
X,0,"[196, 1, 1]",27211,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,19,18,6784356010524.237,3867,1.632,0,7,9.333333
X,4224,"[7, 16, 1]",27233,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784356010526.669,3872,1.984,0,7,10.666667
X,4224,"[1, 16, 512]",27235,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356010529.357,3872,33.056,0,7,780.190491
X,100352,"[8, 2, 4]",27241,"[128, 1, 1]",0.761905,7,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,198,6784356010566.285,3872,37.311,0,7,3.047619
X,4224,"[7, 16, 1]",27244,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6784356010604.332,3872,2.464,0,7,10.666667
X,0,"[392, 1, 1]",27252,"[128, 1, 1]",4.666667,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,39,16,6784356010607.532,3875,2.721,0,7,18.666666
X,0,"[1, 1, 1]",27258,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356010611.052,3876,1.44,0,7,0.047619
X,2192,"[512, 1, 1]",27311,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356010613.292,3879,8.416,0,7,97.523811
X,0,"[196, 1, 1]",27332,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,19,18,6784356010624.876,3892,1.664,0,7,9.333333
X,4224,"[7, 16, 1]",27354,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,22,38,6784356010627.308,3897,2.08,0,7,10.666667
X,4224,"[1, 16, 512]",27356,"[256, 1, 1]",97.523811,7,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",1,0,kernel,0,100,38,6784356010630.636,3897,33.088,0,7,780.190491
X,100352,"[8, 2, 4]",27362,"[128, 1, 1]",0.761905,7,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,1,0,kernel,0,0,198,6784356010666.22,3897,36.704,0,7,3.047619
X,4224,"[7, 16, 1]",27365,"[256, 1, 1]",1.333333,7,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",1,0,kernel,0,22,40,6784356010703.724,3897,2.496,0,7,10.666667
X,0,"[392, 1, 1]",27373,"[128, 1, 1]",4.666667,7,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",1,0,kernel,0,39,16,6784356010706.956,3900,2.656,0,7,18.666666
X,0,"[1, 1, 1]",27379,"[128, 1, 1]",0.011905,7,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",1,0,kernel,0,0,24,6784356010710.348,3901,1.44,0,7,0.047619
X,2192,"[512, 1, 1]",27432,"[512, 1, 1]",6.095238,7,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",1,0,kernel,0,100,40,6784356010712.492,3904,8.32,0,7,97.523811
X,0,"[196, 1, 1]",27453,"[128, 1, 1]",2.333333,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",1,0,kernel,0,19,18,6784356013035.362,3917,2.497,0,7,9.333333
X,0,"[98, 1, 1]",27472,"[256, 1, 1]",1.166667,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",1,0,kernel,0,19,26,6784356013038.626,3920,2.912,0,7,9.333333
X,528,"[1024, 1, 1]",27491,"[32, 4, 1]",12.190476,7,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,kernel,0,25,159,6784356013042.53,3926,691.869,0,7,48.761906
X,0,"[16, 1, 1]",27522,"[256, 1, 1]",0.190476,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",1,0,kernel,0,3,47,6784356013735.136,3928,2.303,0,7,1.52381
X,2560,"[512, 1, 1]",27541,"[128, 1, 1]",6.095238,7,"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, false, true, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>, float, float)",1,0,kernel,0,51,58,6784356013738.207,3937,115.776,0,7,24.380953
X,0,"[16, 1, 1]",27572,"[256, 1, 1]",0.190476,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",1,0,kernel,0,3,47,6784356013854.815,3939,2.976,0,7,1.52381
X,528,"[250, 1, 1]",27591,"[32, 4, 1]",2.976191,7,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",1,0,kernel,0,25,159,6784356013858.559,3948,30.112,0,7,11.904762
