pid,warps per SM,ph,name,device,block,dur,shared memory,ts,context,stream,registers per thread,est. achieved occupancy %,correlation,tid,cat,queued,grid,blocks per SM,External id
0,18.761906,X,"void cask__5x_cudnn::computeOffsetsKernel<false, false>(cask__5x_cudnn::ComputeOffsetsParams)",0,"[256, 1, 1]",2.304,0,6936340602978.124,1,7,16,39,15,7,kernel,0,"[197, 1, 1]",2.345238,5
0,18.666666,X,_5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1,0,"[128, 1, 1]",38.784,16384,6936340602981.164,1,7,128,33,18,7,kernel,0,"[392, 1, 1]",4.666667,5
0,597.333313,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",45.632,0,6936340603020.78,1,7,16,100,26,7,kernel,0,"[12544, 1, 1]",149.333328,8
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.048,0,6936340603067.212,1,7,24,0,32,7,kernel,0,"[1, 1, 1]",0.011905,9
0,12.190476,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",71.168,144,6936340607575.076,1,7,40,25,88,7,kernel,0,"[64, 1, 1]",0.761905,12
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",46.271,0,6936340607694.66,1,7,18,100,112,7,kernel,0,"[6272, 1, 1]",74.666664,25
0,1.52381,X,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,"[32, 4, 1]",3.232,8704,6936340607741.668,1,7,40,3,139,7,kernel,0,"[2, 16, 1]",0.380952,30
0,74.666664,X,_5x_cudnn_ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,"[256, 1, 1]",144.831,49152,6936340607746.02,1,7,126,33,141,7,kernel,0,"[2, 28, 14]",9.333333,30
0,597.333313,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",45.824,0,6936340607891.715,1,7,16,100,149,7,kernel,0,"[12544, 1, 1]",149.333328,33
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.08,0,6936340607938.371,1,7,24,0,155,7,kernel,0,"[1, 1, 1]",0.011905,34
0,12.190476,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",64.704,144,6936340607941.315,1,7,40,25,211,7,kernel,0,"[64, 1, 1]",0.761905,37
0,298.666656,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",46.528,0,6936340608053.731,1,7,18,100,235,7,kernel,0,"[6272, 1, 1]",74.666664,50
0,298.666656,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",44.224,0,6936340608101.091,1,7,26,100,258,7,kernel,0,"[3136, 1, 1]",37.333332,53
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",10.272,4224,6936340608146.147,1,7,38,100,276,7,kernel,0,"[392, 2, 1]",9.333333,57
0,24.380953,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.352,4224,6936340608157.507,1,7,38,51,278,7,kernel,0,"[1, 2, 128]",3.047619,57
0,4.666667,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize256x128x32_stage2_warpsize4x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[256, 1, 1]",63.008,98304,6936340608162.723,1,7,254,0,283,7,kernel,0,"[1, 49, 1]",0.583333,57
0,298.666656,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",17.248,0,6936340608226.915,1,7,16,100,292,7,kernel,0,"[6272, 1, 1]",74.666664,60
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.048,0,6936340608244.963,1,7,24,0,298,7,kernel,0,"[1, 1, 1]",0.011905,61
0,24.380953,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",22.624,144,6936340608247.747,1,7,40,51,354,7,kernel,0,"[128, 1, 1]",1.52381,64
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",23.295,0,6936340608295.299,1,7,18,100,374,7,kernel,0,"[3136, 1, 1]",37.333332,77
0,149.333328,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",21.183,4224,6936340608319.427,1,7,38,100,400,7,kernel,0,"[392, 4, 1]",18.666666,82
0,48.761906,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.896,4224,6936340608341.443,1,7,38,100,402,7,kernel,0,"[1, 4, 128]",6.095238,82
0,9.333333,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",101.665,49152,6936340608350.05,1,7,230,17,406,7,kernel,0,"[1, 98, 2]",2.333333,82
0,298.666656,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",19.936,0,6936340608452.866,1,7,16,100,415,7,kernel,0,"[6272, 1, 1]",74.666664,85
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.857,0,6936340608473.57,1,7,24,0,421,7,kernel,0,"[1, 1, 1]",0.011905,86
0,24.380953,X,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int, 512, true, 1, true>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)",0,"[512, 1, 1]",21.664,144,6936340608476.162,1,7,40,51,473,7,kernel,0,"[128, 1, 1]",1.52381,89
0,149.333328,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",23.201,0,6936340608521.922,1,7,18,100,493,7,kernel,0,"[3136, 1, 1]",37.333332,102
0,149.333328,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",19.776,0,6936340608545.954,1,7,26,100,512,7,kernel,0,"[1568, 1, 1]",18.666666,105
0,37.333332,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",4.352,4224,6936340608566.562,1,7,38,78,534,7,kernel,0,"[98, 4, 1]",4.666667,109
0,97.523811,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.784,4224,6936340608571.65,1,7,38,100,536,7,kernel,0,"[1, 4, 256]",12.190476,109
0,2.380952,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",53.76,49152,6936340608579.266,1,7,230,5,539,7,kernel,0,"[2, 25, 1]",0.595238,109
0,149.333328,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",6.912,0,6936340608633.922,1,7,16,100,548,7,kernel,0,"[3136, 1, 1]",37.333332,112
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.568,0,6936340608641.634,1,7,24,0,554,7,kernel,0,"[1, 1, 1]",0.011905,113
0,48.761906,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",10.144,14480,6936340608643.938,1,7,40,100,607,7,kernel,0,"[256, 1, 1]",3.047619,116
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",6.944,0,6936340608664.578,1,7,18,100,628,7,kernel,0,"[1568, 1, 1]",18.666666,129
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.432,4224,6936340608672.322,1,7,38,100,654,7,kernel,0,"[98, 8, 1]",9.333333,134
0,195.047623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",11.04,4224,6936340608679.586,1,7,38,100,656,7,kernel,0,"[1, 8, 256]",24.380953,134
0,19.047619,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",84.224,49152,6936340608693.698,1,7,230,17,660,7,kernel,0,"[2, 25, 8]",4.761905,134
0,149.333328,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",6.848,0,6936340608778.722,1,7,16,100,669,7,kernel,0,"[3136, 1, 1]",37.333332,137
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.856,0,6936340608786.434,1,7,24,0,675,7,kernel,0,"[1, 1, 1]",0.011905,138
0,48.761906,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.344,14480,6936340608789.058,1,7,40,100,728,7,kernel,0,"[256, 1, 1]",3.047619,141
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",6.208,0,6936340608808.738,1,7,18,100,749,7,kernel,0,"[1568, 1, 1]",18.666666,154
0,74.666664,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",7.296,4224,6936340608815.746,1,7,38,100,771,7,kernel,0,"[98, 8, 1]",9.333333,159
0,195.047623,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",10.912,4224,6936340608823.81,1,7,38,100,773,7,kernel,0,"[1, 8, 256]",24.380953,159
0,19.047619,X,sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage3_warpsize2x2x1_g1_tensor16x8x8_alignc4_execute_kernel__5x_cudnn,0,"[128, 1, 1]",84.224,49152,6936340608837.57,1,7,230,17,777,7,kernel,0,"[2, 25, 8]",4.761905,159
0,149.333328,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",7.488,0,6936340608922.658,1,7,16,100,786,7,kernel,0,"[3136, 1, 1]",37.333332,162
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.92,0,6936340608930.882,1,7,24,0,792,7,kernel,0,"[1, 1, 1]",0.011905,163
0,48.761906,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",10.528,14480,6936340608933.538,1,7,40,100,845,7,kernel,0,"[256, 1, 1]",3.047619,166
0,74.666664,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",6.56,0,6936340608954.754,1,7,18,100,866,7,kernel,0,"[1568, 1, 1]",18.666666,179
0,74.666664,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",6.753,0,6936340608962.113,1,7,26,100,885,7,kernel,0,"[784, 1, 1]",9.333333,182
0,19.047619,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.464,4224,6936340608969.634,1,7,38,40,903,7,kernel,0,"[25, 8, 1]",2.380952,186
0,390.095245,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",18.241,4224,6936340608972.833,1,7,38,100,905,7,kernel,0,"[1, 8, 512]",48.761906,186
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_16x6_nhwc_align4::Params),0,"[128, 1, 1]",51.391,73728,6936340608991.778,1,7,162,0,909,7,kernel,0,"[28, 2, 1]",0.666667,186
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.392,4224,6936340609043.969,1,7,40,79,913,7,kernel,0,"[25, 16, 1]",4.761905,186
0,74.666664,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",4.352,0,6936340609048.13,1,7,16,100,921,7,kernel,0,"[1568, 1, 1]",18.666666,189
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.567,0,6936340609053.282,1,7,24,0,927,7,kernel,0,"[1, 1, 1]",0.011905,190
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.919,4240,6936340609055.618,1,7,40,100,980,7,kernel,0,"[512, 1, 1]",6.095238,193
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.433,0,6936340609069.473,1,7,18,78,1001,7,kernel,0,"[784, 1, 1]",9.333333,206
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",6.976,4224,6936340613538.778,1,7,38,79,1027,7,kernel,0,"[25, 16, 1]",4.761905,211
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",34.592,4224,6936340613546.586,1,7,38,100,1029,7,kernel,0,"[1, 16, 512]",97.523811,211
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),0,"[128, 1, 1]",96.0,73728,6936340613581.914,1,7,168,0,1033,7,kernel,0,"[28, 2, 1]",0.666667,211
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.232,4224,6936340613678.746,1,7,40,79,1037,7,kernel,0,"[25, 16, 1]",4.761905,211
0,74.666664,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",4.352,0,6936340613682.81,1,7,16,100,1045,7,kernel,0,"[1568, 1, 1]",18.666666,214
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.6,0,6936340613687.994,1,7,24,0,1051,7,kernel,0,"[1, 1, 1]",0.011905,215
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",10.272,4240,6936340613690.458,1,7,40,100,1104,7,kernel,0,"[512, 1, 1]",6.095238,218
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.496,0,6936340613704.826,1,7,18,78,1125,7,kernel,0,"[784, 1, 1]",9.333333,231
0,38.095238,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.944,4224,6936340613708.186,1,7,38,79,1147,7,kernel,0,"[25, 16, 1]",4.761905,236
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",34.048,4224,6936340613711.93,1,7,38,100,1149,7,kernel,0,"[1, 16, 512]",97.523811,236
0,2.666667,X,void cutlass__5x_cudnn::Kernel<cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4>(cutlass_tensorop_s1688fprop_optimized_tf32_128x64_32x3_nhwc_align4::Params),0,"[128, 1, 1]",95.328,73728,6936340613746.714,1,7,168,0,1153,7,kernel,0,"[28, 2, 1]",0.666667,236
0,38.095238,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",3.296,4224,6936340613842.81,1,7,40,79,1157,7,kernel,0,"[25, 16, 1]",4.761905,236
0,74.666664,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",4.127,0,6936340613846.906,1,7,16,100,1165,7,kernel,0,"[1568, 1, 1]",18.666666,239
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.504,0,6936340613851.897,1,7,24,0,1171,7,kernel,0,"[1, 1, 1]",0.011905,240
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",9.824,4240,6936340613854.17,1,7,40,100,1224,7,kernel,0,"[512, 1, 1]",6.095238,243
0,37.333332,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",2.367,0,6936340613868.122,1,7,18,78,1245,7,kernel,0,"[784, 1, 1]",9.333333,256
0,37.333332,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",4.064,0,6936340613871.353,1,7,26,78,1264,7,kernel,0,"[392, 1, 1]",4.666667,259
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.177,4224,6936340613876.153,1,7,38,22,1282,7,kernel,0,"[7, 16, 1]",1.333333,263
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.855,4224,6936340613879.642,1,7,38,100,1284,7,kernel,0,"[1, 16, 512]",97.523811,263
0,3.047619,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",39.04,100352,6936340613917.081,1,7,198,0,1290,7,kernel,0,"[8, 2, 4]",0.761905,263
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.721,4224,6936340613956.857,1,7,40,22,1293,7,kernel,0,"[7, 16, 1]",1.333333,263
0,18.666666,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.784,0,6936340613960.409,1,7,16,39,1301,7,kernel,0,"[392, 1, 1]",4.666667,266
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.568,0,6936340613963.929,1,7,24,0,1307,7,kernel,0,"[1, 1, 1]",0.011905,267
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",8.8,2192,6936340613966.233,1,7,40,100,1364,7,kernel,0,"[512, 1, 1]",6.095238,270
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.696,0,6936340613978.361,1,7,18,19,1385,7,kernel,0,"[196, 1, 1]",2.333333,283
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.144,4224,6936340613980.921,1,7,38,22,1407,7,kernel,0,"[7, 16, 1]",1.333333,288
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.376,4224,6936340613983.865,1,7,38,100,1409,7,kernel,0,"[1, 16, 512]",97.523811,288
0,3.047619,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",38.656,100352,6936340614020.473,1,7,198,0,1415,7,kernel,0,"[8, 2, 4]",0.761905,288
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.592,4224,6936340614059.961,1,7,40,22,1418,7,kernel,0,"[7, 16, 1]",1.333333,288
0,18.666666,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.816,0,6936340614063.353,1,7,16,39,1426,7,kernel,0,"[392, 1, 1]",4.666667,291
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.6,0,6936340614066.937,1,7,24,0,1432,7,kernel,0,"[1, 1, 1]",0.011905,292
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",8.736,2192,6936340614069.369,1,7,40,100,1485,7,kernel,0,"[512, 1, 1]",6.095238,295
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.696,0,6936340614081.337,1,7,18,19,1506,7,kernel,0,"[196, 1, 1]",2.333333,308
0,10.666667,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.08,4224,6936340614083.865,1,7,38,22,1532,7,kernel,0,"[7, 16, 1]",1.333333,313
0,780.190491,X,"void cudnn::engines_precompiled::nchwToNhwcKernel<float, float, float, false, true, (cudnnKernelDataType_t)2>(cudnn::engines_precompiled::nchw2nhwc_params_t<float>, float const*, float*)",0,"[256, 1, 1]",33.024,4224,6936340614086.745,1,7,38,100,1534,7,kernel,0,"[1, 16, 512]",97.523811,313
0,3.047619,X,sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage4_warpsize2x2x1_g1_tensor16x8x8_execute_kernel__5x_cudnn,0,"[128, 1, 1]",38.56,100352,6936340614122.649,1,7,198,0,1540,7,kernel,0,"[8, 2, 4]",0.761905,313
0,10.666667,X,"void cudnn::engines_precompiled::nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(cudnn::engines_precompiled::nhwc2nchw_params_t<float>, float const*, float*)",0,"[256, 1, 1]",2.368,4224,6936340614162.393,1,7,40,22,1543,7,kernel,0,"[7, 16, 1]",1.333333,313
0,18.666666,X,"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})",0,"[128, 1, 1]",2.784,0,6936340614165.529,1,7,16,39,1551,7,kernel,0,"[392, 1, 1]",4.666667,316
0,0.047619,X,"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.536,0,6936340614169.049,1,7,24,0,1557,7,kernel,0,"[1, 1, 1]",0.011905,317
0,97.523811,X,"void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnn::bn_fw_tr_1C11_args<float>)",0,"[512, 1, 1]",8.704,2192,6936340614171.289,1,7,40,100,1610,7,kernel,0,"[512, 1, 1]",6.095238,320
0,9.333333,X,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)",0,"[128, 1, 1]",1.696,0,6936340614183.353,1,7,18,19,1631,7,kernel,0,"[196, 1, 1]",2.333333,333
0,9.333333,X,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float>(int, float const*, long, long, long, int, int, int, int, int, int, int, int, int, int, float*, long*)",0,"[256, 1, 1]",2.688,0,6936340614185.817,1,7,26,19,1650,7,kernel,0,"[98, 1, 1]",1.166667,336
0,48.761906,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,"[32, 4, 1]",690.143,528,6936340614189.337,1,7,159,25,1673,7,kernel,0,"[1024, 1, 1]",12.190476,342
0,1.52381,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",2.304,0,6936340614880.28,1,7,47,3,1704,7,kernel,0,"[16, 1, 1]",0.190476,344
0,24.380953,X,"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, false, true, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>, float, float)",0,"[128, 1, 1]",115.968,2560,6936340614883.448,1,7,58,51,1723,7,kernel,0,"[512, 1, 1]",6.095238,353
0,1.52381,X,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)",0,"[256, 1, 1]",3.136,0,6936340615000.28,1,7,47,3,1754,7,kernel,0,"[16, 1, 1]",0.190476,355
0,11.904762,X,"std::enable_if<!(false), void>::type internal::gemvx::kernel<int, int, float, float, float, float, false, true, true, false, 7, false, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)",0,"[32, 4, 1]",30.4,528,6936340615004.504,1,7,159,25,1773,7,kernel,0,"[250, 1, 1]",2.976191,364
