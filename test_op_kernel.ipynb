{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.fx as fx\n",
    "import os\n",
    "\n",
    "from model_static_graph import extract_graph, draw_graph\n",
    "from pytorch_tracing import py_tracing_forward, py_tracing_backward, py_tracing_optimize\n",
    "from op_kernel_dict import get_op_kernel\n",
    "from convert_json_to_csv import convert_json_to_csv\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/profiler/profiler.py:445: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling completed. Trace log saved to './log/resnet18_forward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/resnet18_backward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/resnet18_optimize.json'\n",
      "CSV files saved to 'log_csv'\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = torchvision.models.resnet18().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "input_data = torch.randn(5, 3, 224, 224).cuda()\n",
    "model_name='resnet18'\n",
    "\n",
    "#静态图\n",
    "# static_graph,name_module,adj=extract_graph(model)\n",
    "# draw_graph(adj,name_module, model_name=model_name)\n",
    "#draw_graph(adj,name_module, model_name=model_name,t=1)\n",
    "\n",
    "#pytorch_tracing\n",
    "py_tracing_forward(model, input_data, model_name=model_name)\n",
    "py_tracing_backward(model, input_data, model_name=model_name)\n",
    "py_tracing_optimize(model, input_data, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/profiler/profiler.py:445: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling completed. Trace log saved to './log/VGG16_forward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/VGG16_backward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/VGG16_optimize.json'\n",
      "CSV files saved to 'log_csv'\n"
     ]
    }
   ],
   "source": [
    "from VGG import VGG16\n",
    "\n",
    "model = VGG16().cuda()\n",
    "input_data = torch.randn(1, 3, 224, 224).cuda()\n",
    "model_name='VGG16'\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "py_tracing_forward(model, input_data, model_name=model_name)\n",
    "py_tracing_backward(model, input_data, model_name=model_name)\n",
    "py_tracing_optimize(model, input_data, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#decoder only transformer\n",
    "from gpt import GPT\n",
    "\n",
    "x=torch.randint(0,5000,(5,30)).cuda()\n",
    "padding=torch.zeros(5,30).cuda()\n",
    "model_name='GPT'\n",
    "    \n",
    "# GPT模型\n",
    "model=GPT(d_model=64,nhead=2,feedforward=128,vocab_size=5000,seq_max_len=50).cuda()\n",
    "y=model(x,padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/profiler/profiler.py:445: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling completed. Trace log saved to './log/transformer_forward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/transformer_backward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/transformer_optimize.json'\n",
      "CSV files saved to 'log_csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer import Transformer\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "max_seq_length = 512\n",
    "batch_size = 1\n",
    "src_seq_length = 50\n",
    "tgt_seq_length = 50\n",
    "\n",
    "# 输入数据\n",
    "src = torch.randint(0, vocab_size, (batch_size, src_seq_length)).cuda()  # Source input tokens\n",
    "tgt = torch.randint(0, vocab_size, (batch_size, tgt_seq_length)).cuda()  # Target input tokens\n",
    "model = Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "                    num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, \n",
    "                    vocab_size=vocab_size, max_seq_length=max_seq_length).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "py_tracing_forward(model, src, model_name='transformer',input_data_2=tgt)\n",
    "py_tracing_backward(model, src, model_name='transformer', input_data_2=tgt)\n",
    "py_tracing_optimize(model, src, optimizer, model_name='transformer', input_data_2=tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/profiler/profiler.py:445: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling completed. Trace log saved to './log/LSTM_forward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/LSTM_backward.json'\n",
      "CSV files saved to 'log_csv'\n",
      "Profiling completed. Trace log saved to './log/LSTM_optimize.json'\n",
      "CSV files saved to 'log_csv'\n",
      "所有文件转换完成。\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "from LSTM import SimpleLSTM\n",
    "\n",
    "# 参数设置\n",
    "input_size = 10\n",
    "hidden_size = 50\n",
    "num_layers = 10\n",
    "num_classes = 15\n",
    "sequence_length = 1000\n",
    "batch_size = 300\n",
    "\n",
    "model_name='LSTM'\n",
    "model = SimpleLSTM(input_size, hidden_size, num_layers, num_classes).cuda()\n",
    "input_data = torch.randn(batch_size, sequence_length, input_size).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "py_tracing_forward(model, input_data, model_name=model_name)\n",
    "py_tracing_backward(model, input_data, model_name=model_name)\n",
    "py_tracing_optimize(model, input_data, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件转换完成。\n"
     ]
    }
   ],
   "source": [
    "#log 转化为 csv\n",
    "log_directory = 'log'\n",
    "output_directory = 'log_csv'\n",
    "convert_json_to_csv(output_directory, log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件转换完成。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aten::copy_': {'void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})'},\n",
       " 'aten::_cudnn_rnn': {'ampere_sgemm_32x128_tn',\n",
       "  'void RNN_blockPersist_fp_LSTM<float, float, float, 64>(float const*, float*, float const*, float*, float const*, float*, float*, float const*, float const*, float*, int, int, int, int, int, int, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)'},\n",
       " 'aten::addmm': {'ampere_sgemm_32x32_sliced1x4_tn'},\n",
       " 'aten::sum': {'void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)'},\n",
       " 'aten::fill_': {'void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)'},\n",
       " 'aten::mm': {'ampere_sgemm_32x128_nn',\n",
       "  'void gemmSN_NN_kernel<float, 256, 4, 2, 8, 3, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)'},\n",
       " 'aten::_cudnn_rnn_backward': {'ampere_sgemm_32x32_sliced1x4_nt',\n",
       "  'void GENERIC_elementWise_bp2<float, float, float, 4, (cudnnRNNBiasMode_t)2>(int, int, float*, float*, cudnn::reduced_divisor, float*)',\n",
       "  'void LSTM_elementWise_bp1<float, float, float>(int, int, float*, float*, float*, float*, float*, float*, float*, float*, float*, int, int, cudnnRNNClipMode_t, cudnnNanPropagation_t, float, float)',\n",
       "  'void RNN_blockPersist_bp_LSTM_FMA<float, float, float, 64>(block_bp_args_lstm<float, float>)'},\n",
       " 'aten::_foreach_add_': {'void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float, 2, 2, 0>, std::plus<float>, float)'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from op_kernel_dict import get_op_kernel\n",
    "\n",
    "\n",
    "Type = ['forward','backward','optimize']\n",
    "model_list=['resnet18','VGG16','LSTM']\n",
    "op_kernel={model_name: {} for model_name in model_list}\n",
    "for model in model_list:\n",
    "    for tp in Type:\n",
    "        op_tmp=get_op_kernel(tp, model)\n",
    "        op_kernel[model].update(op_tmp)\n",
    "\n",
    "op_kernel['LSTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#比较op_kernel里每个key的set是否有交集\n",
    "# for key1 in op_kernel:\n",
    "#     for key2 in op_kernel:\n",
    "#         if key1!=key2:\n",
    "#             if len(op_kernel[key1]&op_kernel[key2])>0:\n",
    "#                 print(key1,key2)\n",
    "#                 print(op_kernel[key1]-op_kernel[key2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
