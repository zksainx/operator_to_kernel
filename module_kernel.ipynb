{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.profiler\n",
    "import torch.fx as fx\n",
    "import pandas as pd\n",
    "import pygraphviz as pgv\n",
    "from VGG import VGG16\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "# model设置\n",
    "model = VGG16().cuda()\n",
    "input_data = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取计算图并可视化\n",
    "model_name='VGG16'\n",
    "tracer = fx.Tracer()\n",
    "graph = tracer.trace(model)\n",
    "\n",
    "# 创建 GraphModule\n",
    "graph_module = fx.GraphModule(model, graph)\n",
    "\n",
    "\n",
    "data = []\n",
    "adj={}\n",
    "for node in graph.nodes:\n",
    "    op_type = node.op\n",
    "    name = node.name\n",
    "    num_downstream = len(node.users)\n",
    "    num_upstream = len(node.all_input_nodes)\n",
    "    downstream = [user.name for user in node.users]\n",
    "    upstream = [input_node.name for input_node in node.all_input_nodes]\n",
    "    target = node.target\n",
    "    args = str(node.args)\n",
    "    #kwargs = str(node.kwargs)\n",
    "    module_qualname = \"\"\n",
    "    detailed_op = \"\"\n",
    "    #构建邻接表\n",
    "    if name not in adj:\n",
    "        adj[name]=[]\n",
    "        for i in range(len(downstream)):\n",
    "            adj[name].append(downstream[i])\n",
    "    else:\n",
    "        for i in range(len(downstream)):\n",
    "            adj[name].append(downstream[i])\n",
    "\n",
    "    if op_type == \"call_module\":\n",
    "        module = dict(graph_module.named_modules())[target]\n",
    "        module_qualname = target\n",
    "        detailed_op = str(module)\n",
    "\n",
    "    data.append([\n",
    "        op_type, name, num_downstream, num_upstream, downstream, upstream,\n",
    "        target, args, module_qualname, detailed_op\n",
    "    ])\n",
    "\n",
    "\n",
    "static_graph = pd.DataFrame(data, columns=[\n",
    "    \"op_type\", \"name\", \"num_downstream\", \"num_upstream\", \"downstream\", \"upstream\",\n",
    "    \"target\", \"args\", \"module_qualname\", \"detailed_op\"\n",
    "])\n",
    "op_type={}\n",
    "name_module = {}\n",
    "for i in range(len(static_graph)):\n",
    "    if static_graph.loc[i,'detailed_op'] != \"\":\n",
    "        key = static_graph.iloc[i]['detailed_op'].split(\"(\")[0]\n",
    "        if key not in op_type:\n",
    "            op_type[key] = 0\n",
    "        module_name='nn.Module: '+key+'_'+str(op_type[key])\n",
    "        op_type[key] += 1\n",
    "        static_graph.loc[i,'module']=module_name\n",
    "        name_module[static_graph.iloc[i]['name']]=[static_graph.iloc[i]['detailed_op'],module_name]\n",
    "        #name_module[static_graph.iloc[i]['name']]=module_name\n",
    "    else:\n",
    "        static_graph.loc[i,'module']=static_graph.iloc[i]['name']\n",
    "        name_module[static_graph.iloc[i]['name']]=[static_graph.iloc[i]['name'],static_graph.iloc[i]['name']]\n",
    "\n",
    "\n",
    "#用module名称替换name\n",
    "adj_module={}\n",
    "for key in adj:\n",
    "    adj_module[name_module[key][1]]=[]\n",
    "    for neighbor in adj[key]:\n",
    "        adj_module[name_module[key][1]].append(name_module[neighbor][1])\n",
    "\n",
    "#print(dict(graph_module.named_modules()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化计算图\n",
    "def draw_graph(adj, name_module, start_node='x', output_file='graph.png',t=0):\n",
    "    def draw(node, G, visited):\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            G.add_node(node, label=name_module[node][t])\n",
    "            if node in adj:\n",
    "                for neighbor in adj[node]:\n",
    "                    G.add_node(neighbor, label=name_module[neighbor][t])\n",
    "                    G.add_edge(node, neighbor, arrowsize=0.6)\n",
    "                    draw(neighbor, G, visited)\n",
    "\n",
    "    G = pgv.AGraph(strict=True, directed=True)\n",
    "    visited = set()\n",
    "    draw(start_node, G, visited)\n",
    "    G.graph_attr['splines'] = 'true'\n",
    "    G.graph_attr['rankdir'] = 'TB'  # 从上到下\n",
    "    G.node_attr['shape'] = 'box'\n",
    "    G.node_attr['style'] = 'filled'\n",
    "    G.node_attr['fillcolor'] = 'lightblue'\n",
    "    G.node_attr['fontname'] = 'Consolas'\n",
    "    G.node_attr['fontsize'] = 15\n",
    "    G.layout(prog='dot')\n",
    "    G.draw(output_file)\n",
    "\n",
    "draw_graph(adj, name_module, output_file='graph_1.png',t=1)\n",
    "draw_graph(adj, name_module, output_file='graph_0.png',t=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k8smaster/miniconda3/envs/k8s/lib/python3.10/site-packages/torch/profiler/profiler.py:445: UserWarning: Profiler won't be using warmup, this can skew profiler results\n",
      "  warn(\"Profiler won't be using warmup, this can skew profiler results\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理文件 VGG16.json...\n",
      "文件 VGG16.json 已成功转化为 log_csv/VGG16 目录下的csv\n",
      "所有文件转换完成。\n"
     ]
    }
   ],
   "source": [
    "# 使用 PyTorch Profiler 捕获跟踪日志\n",
    "Wait=2\n",
    "Warmup=0\n",
    "Active=1\n",
    "Repeat=1\n",
    "total=(Wait+Warmup+Active)*Repeat\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA\n",
    "    ],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=Wait,  # 等待周期\n",
    "        warmup=Warmup,  # 预热周期\n",
    "        active=Active,  # 活动周期\n",
    "        repeat=Repeat   # 重复次数\n",
    "    ),\n",
    "    #on_trace_ready=torch.profiler.tensorboard_trace_handler(dir_name='./log',worker_name=model_name),  # 保存跟踪日志\n",
    "    record_shapes=True,  # 记录输入形状\n",
    "    with_stack=True  # 记录堆栈跟踪\n",
    ") as prof:\n",
    "    for _ in range(total):  # 示例在多个迭代中进行分析\n",
    "        output = model(input_data)\n",
    "        prof.step()\n",
    "\n",
    "# 指定路径和名字保存json\n",
    "log_dir = './log'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "json_path = os.path.join(log_dir, f'{model_name}.json')\n",
    "prof.export_chrome_trace(json_path)\n",
    "\n",
    "#json to csv\n",
    "from convert_json_to_csv import convert_json_to_csv\n",
    "log_directory='log'\n",
    "output_directory='log_csv'\n",
    "convert_json_to_csv(output_directory,log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_function=pd.read_csv(os.path.join(output_directory,model_name)+'/python_function.csv')\n",
    "cuda_runtime=pd.read_csv(os.path.join(output_directory,model_name)+'/cuda_runtime.csv')\n",
    "kernel=pd.read_csv(os.path.join(output_directory,model_name)+'/kernel.csv')\n",
    "\n",
    "#遍历static_graph，找到每个module对应的kernel列表，存放进module_kernel里\n",
    "module_kernel={}\n",
    "kernel_module={}\n",
    "for i in range(len(static_graph)):\n",
    "    module_kernel[static_graph.iloc[i]['module']]=[]\n",
    "    df=python_function[python_function['name']==static_graph.iloc[i]['module']].head(1)\n",
    "    if len(df)>0:\n",
    "        start=df['ts'].values[0]\n",
    "        end=start+df['dur'].values[0]\n",
    "        launch=cuda_runtime[(cuda_runtime['ts']>=start) & (cuda_runtime['ts']+cuda_runtime['dur']<=end) & (cuda_runtime['name'].str.contains('cudaLaunchKernel'))]\n",
    "        tmp_kernel=kernel[kernel['correlation'].isin(launch['correlation'])]\n",
    "        if len(tmp_kernel)>0:\n",
    "            #把kernel的(name，correlation)提取成元组，放入对应module的kernel list里\n",
    "                module_kernel[static_graph.iloc[i]['module']]=[(tmp_kernel.iloc[j]['name'],tmp_kernel.iloc[j]['correlation']) for j in range(len(tmp_kernel))]\n",
    "                for j in range(len(tmp_kernel)):\n",
    "                    if tmp_kernel.iloc[j]['name'] not in kernel_module:\n",
    "                        kernel_module[tmp_kernel.iloc[j]['name']]=[]\n",
    "                    kernel_module[tmp_kernel.iloc[j]['name']].append(static_graph.iloc[i]['module'])\n",
    "#module_list\n",
    "module_list=list(module_kernel.keys())\n",
    "#kernel_list\n",
    "kernel_list=list(kernel_module.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_module_kernel(adj_module, module_kernel, output_file='module_kernel',module_edge=0,mangle=0):\n",
    "    G = pgv.AGraph(strict=True, directed=True)\n",
    "    \n",
    "    # 添加 module 节点\n",
    "    for module in module_kernel:\n",
    "        G.add_node(module, shape='box', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    if module_edge:\n",
    "        for module in adj_module:\n",
    "            for neighbor in adj_module[module]:\n",
    "                G.add_edge(module, neighbor, arrowsize=0.5, color='red')\n",
    "    \n",
    "    for module in module_kernel:\n",
    "        for kernel in module_kernel[module]:\n",
    "            kernel_label = '\\n'.join([kernel[0][i:i+25] for i in range(0, len(kernel[0]), 25)]) #每25个字符换行\n",
    "            G.add_node(kernel[0], label=kernel_label,shape='ellipse', style='filled', fillcolor='lightgreen')\n",
    "            G.add_edge(module, kernel[0], arrowsize=0.6)\n",
    "    \n",
    "\n",
    "    \n",
    "    G.graph_attr['splines'] = 'true'\n",
    "    G.graph_attr['rankdir'] = 'LR' \n",
    "    G.node_attr['fontname'] = 'Consolas'\n",
    "    G.node_attr['fontsize'] = 15\n",
    "    G.layout(prog='dot')\n",
    "    '''\n",
    "    dot:层次布局,适用于有向图。\n",
    "    neato:力导向布局,适用于无向图。\n",
    "    fdp:力导向布局,适用于无向图。\n",
    "    sfdp:多尺度力导向布局,适用于大规模图。\n",
    "    twopi:径向布局,适用于环形图。\n",
    "    circo:环形布局,适用于环形图。\n",
    "    '''\n",
    "    G.draw(output_file+str(module_edge)+'_'+str(mangle)+'.png')\n",
    "\n",
    "# draw_module_kernel(adj_module,module_kernel,module_edge=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cupti——pytorch profiler 的kernel对应关系\n",
    "import pandas as pd\n",
    "import json\n",
    "with open('demangled_symbols_1.json','r') as f:\n",
    "    dic=json.load(f)\n",
    "\n",
    "cupti_kernel=pd.read_csv('/data/zkx/cupti_to_csv/trans_to_csv/trace_no_profiler_con_res/conc_kernel.csv')\n",
    "py_kernel=pd.read_csv('/data/zkx/operator_to_kernel/log_csv/VGG16/kernel.csv')\n",
    "\n",
    "cupti_kernel=cupti_kernel.sort_values(by='start')\n",
    "py_kernel=py_kernel.sort_values(by='ts')\n",
    "\n",
    "#cupti_kernel和py_kernel 从前往后顺序name一一对应，存入kernel_dict\n",
    "kernel_dict={}\n",
    "assert len(cupti_kernel)==len(py_kernel)\n",
    "for i in range(len(cupti_kernel)):\n",
    "    if cupti_kernel.iloc[i]['name'] not in kernel_dict:\n",
    "        kernel_dict[cupti_kernel.iloc[i]['name']]=py_kernel.iloc[i]['name']\n",
    "    else:\n",
    "        tmp=kernel_dict[cupti_kernel.iloc[i]['name']]\n",
    "        assert tmp==py_kernel.iloc[i]['name']\n",
    "\n",
    "#建立一个逆转kernel_dict key和value的字典\n",
    "reverse_kernel_dict={}\n",
    "for key,value in kernel_dict.items():\n",
    "    reverse_kernel_dict[value]=key\n",
    "\n",
    "'''\n",
    "def draw_module_kernel_1(adj_module, module_kernel, output_file='module_kernel',module_edge=0):\n",
    "    G = pgv.AGraph(strict=True, directed=True)\n",
    "    \n",
    "    # 添加 module 节点\n",
    "    for module in module_kernel:\n",
    "        G.add_node(module, shape='box', style='filled', fillcolor='lightblue')\n",
    "    \n",
    "    if module_edge:\n",
    "        for module in adj_module:\n",
    "            for neighbor in adj_module[module]:\n",
    "                G.add_edge(module, neighbor, arrowsize=0.5, color='red')\n",
    "    \n",
    "    for module in module_kernel:\n",
    "        for kernel in module_kernel[module]:\n",
    "            k=reverse_kernel_dict[kernel[0]]\n",
    "            k=dic[k]['short_name']\n",
    "            kernel_label = '\\n'.join([k[i:i+25] for i in range(0, len(k), 25)]) #每25个字符换行\n",
    "            G.add_node(kernel[0], label=kernel_label,shape='ellipse', style='filled', fillcolor='lightgreen')\n",
    "            G.add_edge(module, kernel[0], arrowsize=0.6)\n",
    "    \n",
    "\n",
    "    \n",
    "    G.graph_attr['splines'] = 'true'\n",
    "    G.graph_attr['rankdir'] = 'LR' \n",
    "    G.node_attr['fontname'] = 'Consolas'\n",
    "    G.node_attr['fontsize'] = 15\n",
    "    G.layout(prog='dot')\n",
    "    G.draw(output_file+str(module_edge)+'_2'+'.png')\n",
    "\n",
    "draw_module_kernel_1(adj_module,module_kernel,module_edge=0)\n",
    "'''\n",
    "\n",
    "\n",
    "import cxxfilt\n",
    "\n",
    "def demangle_with_cxxfilt(symbol):\n",
    "    try:\n",
    "        return cxxfilt.demangle(symbol)\n",
    "    except cxxfilt.InvalidName:\n",
    "        return symbol  \n",
    "\n",
    "\n",
    "#解析kernel_dict 的key 然后 与 value 对比\n",
    "# for key,value in kernel_dict.items():\n",
    "#     if demangle_with_cxxfilt(key)!=value:\n",
    "#         print('py_name:',value)\n",
    "#         print('cupti_name:',demangle_with_cxxfilt(key))\n",
    "#         print('-----------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Conv2d': 13,\n",
       " 'BatchNorm2d': 13,\n",
       " 'ReLU6': 13,\n",
       " 'MaxPool2d': 5,\n",
       " 'Linear': 3,\n",
       " 'Dropout': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aten::conv2d',\n",
       " 'aten::convolution',\n",
       " 'aten::_convolution',\n",
       " 'aten::cudnn_convolution',\n",
       " 'aten::reshape',\n",
       " 'aten::view',\n",
       " 'aten::add_',\n",
       " 'aten::batch_norm',\n",
       " 'aten::_batch_norm_impl_index',\n",
       " 'aten::cudnn_batch_norm',\n",
       " 'aten::empty_like',\n",
       " 'aten::empty',\n",
       " 'aten::hardtanh_',\n",
       " 'aten::clone',\n",
       " 'aten::empty_strided',\n",
       " 'aten::copy_',\n",
       " 'aten::hardtanh',\n",
       " 'aten::clamp',\n",
       " 'aten::to',\n",
       " 'aten::max_pool2d',\n",
       " 'aten::max_pool2d_with_indices',\n",
       " 'aten::linear',\n",
       " 'aten::t',\n",
       " 'aten::transpose',\n",
       " 'aten::as_strided',\n",
       " 'aten::addmm',\n",
       " 'aten::dropout',\n",
       " 'aten::native_dropout']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "item in prof.key_averages() parameters:\n",
    "[\n",
    " 'add',\n",
    " 'count',\n",
    " 'cpu_children',\n",
    " 'cpu_memory_usage',\n",
    " 'cpu_parent',\n",
    " 'cpu_time',\n",
    " 'cpu_time_str',\n",
    " 'cpu_time_total',\n",
    " 'cpu_time_total_str',\n",
    " 'cuda_time',\n",
    " 'device_memory_usage',\n",
    " 'device_time',\n",
    " 'device_time_str',\n",
    " 'device_time_total',\n",
    " 'device_time_total_str',\n",
    " 'device_type',\n",
    " 'flops',\n",
    " 'input_shapes',\n",
    " 'is_async',\n",
    " 'is_legacy',\n",
    " 'is_remote',\n",
    " 'is_user_annotation',\n",
    " 'key',\n",
    " 'node_id',\n",
    " 'scope',\n",
    " 'self_cpu_memory_usage',\n",
    " 'self_cpu_time_total',\n",
    " 'self_cpu_time_total_str',\n",
    " 'self_device_memory_usage',\n",
    " 'self_device_time_total',\n",
    " 'self_device_time_total_str',\n",
    " 'stack',\n",
    " 'use_device']\n",
    "'''\n",
    "data = []\n",
    "for item in prof.key_averages():\n",
    "    data.append({\n",
    "        \"Name\": item.key,\n",
    "        #\"Self CPU total\": item.self_cpu_time_total,\n",
    "        # \"CPU total\": item.cpu_time_total,\n",
    "        # \"Self CPU total\": item.self_cpu_time_total,\n",
    "        #\"CPU time avg\": item.cpu_time,\n",
    "        \"GPU total\": item.device_time_total,\n",
    "        \"Self GPU total\": item.self_device_time_total,\n",
    "        #\"CUDA time avg\": item.device_time\n",
    "        \"Calls\": item.count,\n",
    "\n",
    "    })\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "\n",
    "aten=df[df['Name'].str.contains('aten')]['Name'].to_list()\n",
    "kernel=df[df['Self GPU total']>0] \n",
    "kernel=kernel[~kernel['Name'].str.contains('aten')]\n",
    "kernel=kernel[~kernel['Name'].str.contains('Mem')]\n",
    "kernel=kernel[~kernel['Name'].str.contains('Profiler')]\n",
    "kernel=kernel.reset_index(drop=True)\n",
    "py_kernel=kernel['Name'].unique().tolist()\n",
    "aten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
